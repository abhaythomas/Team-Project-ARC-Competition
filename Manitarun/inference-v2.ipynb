{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":67357,"databundleVersionId":8951125,"sourceType":"competition"},{"sourceId":8622192,"sourceType":"datasetVersion","datasetId":5123959},{"sourceId":167742,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":142702,"modelId":165284}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"deps_path = '/kaggle/input/llama-3-arc-deps'\n! pip install --no-index --find-links {deps_path} --requirement {deps_path}/requirements.txt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-18T10:39:13.463841Z","iopub.execute_input":"2025-03-18T10:39:13.464030Z","iopub.status.idle":"2025-03-18T10:39:22.741432Z","shell.execute_reply.started":"2025-03-18T10:39:13.464011Z","shell.execute_reply":"2025-03-18T10:39:22.740375Z"}},"outputs":[{"name":"stdout","text":"Looking in links: /kaggle/input/llama-3-arc-deps\nProcessing /kaggle/input/llama-3-arc-deps/trl-0.9.3-py3-none-any.whl (from -r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1))\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from -r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (0.14.0)\nProcessing /kaggle/input/llama-3-arc-deps/bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (from -r /kaggle/input/llama-3-arc-deps/requirements.txt (line 4))\nRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2.5.1+cu121)\nRequirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (4.47.0)\nRequirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (1.2.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (3.3.1)\nProcessing /kaggle/input/llama-3-arc-deps/tyro-0.8.4-py3-none-any.whl (from trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1))\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (6.0.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (4.67.1)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (0.4.5)\nRequirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (0.29.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (2024.12.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.18.2->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.4.0->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (0.21.0)\nRequirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (13.9.4)\nProcessing /kaggle/input/llama-3-arc-deps/shtab-1.7.1-py3-none-any.whl (from tyro>=0.5.11->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1))\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (3.11.12)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (1.18.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 2)) (2025.1.31)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.2->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.18.2->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.2->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.18.2->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2025.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.18.2->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl->-r /kaggle/input/llama-3-arc-deps/requirements.txt (line 1)) (1.17.0)\nInstalling collected packages: shtab, tyro, trl, bitsandbytes\nSuccessfully installed bitsandbytes-0.43.1 shtab-1.7.1 trl-0.9.3 tyro-0.8.4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# For dataset\nimport pandas as pd\nimport json\nimport os\nimport ast\nimport re\nimport numpy as np\nfrom datasets import Dataset\n\n# For LLM\nfrom peft import LoraConfig, PeftModel\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    set_seed,\n    pipeline\n)\nfrom trl import setup_chat_format\n\nimport torch\nfrom time import time\n\n# Set seed\nset_seed(42)\n\nprint('Done')\n\n'''Summary of the Code:\nImports necessary libraries\n\npandas, json, os, numpy, and datasets.Dataset for data processing.\ntransformers, peft, and trl for LLM fine-tuning and inference.\ntorch for GPU-accelerated computations.\ntime for performance measurement.\nSets a fixed random seed (set_seed(42))\n\nEnsures reproducibility in model training and inference.'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T10:52:47.637325Z","iopub.execute_input":"2025-03-18T10:52:47.637649Z","iopub.status.idle":"2025-03-18T10:52:47.645101Z","shell.execute_reply.started":"2025-03-18T10:52:47.637620Z","shell.execute_reply":"2025-03-18T10:52:47.644211Z"}},"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Define a template for formatting chat messages with the Llama 3 model\n# This is model specific. Change it if you e.g. use Google's Gemma instead of Llama\n#LLAMA_3_CHAT_TEMPLATE = \"\"\"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\"\"\"\n\n# Set the data type for computations to float16, bfloat16 not supported on T4/P100\ncompute_dtype = getattr(torch, \"float16\")\n\n# Configure the BitsAndBytes settings for 4-bit quantization to reduce memory usage\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,  # Enable 4-bit quantization\n    bnb_4bit_use_double_quant=True,  # Use double quantization for improved precision\n    bnb_4bit_quant_type=\"nf4\",  # Specify the quantization type\n    bnb_4bit_compute_dtype=compute_dtype,  # Set the computation data type\n)\n\n# Specify the model ID for loading the fine-tuned Llama 3 model\n# You can also test other models by replacing this line.\n# For the original non-finetuned model use\n# model_id = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\nmodel_id = \"/kaggle/input/3.1-8b_instruct/transformers/default/1\"\n\n# Record the start time to measure the loading duratio\ntime_start = time()\nprint(\"Loading model\")\n# Load the pre-trained model with specified configurations\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    trust_remote_code=True, # Allow the model to use custom code from the repository\n    quantization_config=bnb_config, # Apply the 4-bit quantization configuration\n    attn_implementation='sdpa', # Use scaled-dot product attention for better performance\n    torch_dtype=compute_dtype, # Set the data type for the model\n    use_cache=False, # Disable caching to save memory\n    device_map='auto', # Automatically map the model to available devices (e.g., GPUs)\n)\n\n# Load the tokenizer associated with the model\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n#tokenizer.chat_template = LLAMA_3_CHAT_TEMPLATE # Apply the chat message template\n\n# Record the end time and print the duration for preparing the model and tokenizer\ntime_end = time()\nprint(f\"Prepare model, tokenizer: {round(time_end-time_start, 3)} sec.\")\n\n'''\nSummary\n✔ Uses 4-bit quantization for efficiency.\n✔ Loads a fine-tuned Llama 3 model from Kaggle.\n✔ Uses Scaled-Dot Product Attention for better performance.\n✔ Tracks loading time for optimization.\n✔ Tokenizer is initialized but chat formatting is disabled (commented out).\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T10:53:29.432325Z","iopub.execute_input":"2025-03-18T10:53:29.432642Z","iopub.status.idle":"2025-03-18T10:55:19.377357Z","shell.execute_reply.started":"2025-03-18T10:53:29.432617Z","shell.execute_reply":"2025-03-18T10:55:19.376452Z"}},"outputs":[{"name":"stdout","text":"Loading model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b2a52f2091248f2a0bc5195b3744ef0"}},"metadata":{}},{"name":"stdout","text":"Prepare model, tokenizer: 109.937 sec.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import json\n\n# Load the files\nwith open('/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json', 'r') as f:\n    challenges = json.load(f)\n\nwith open('/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json', 'r') as f:\n    solutions = json.load(f)\n\n# Displaying the first few entries from challenges\n#print(\"Challenges - First few entries:\")\n#for idx, (key, value) in enumerate(challenges.items()):\n#    print(f\"Key: {key}, Value (truncated): {str(value)[:500]}...\")  # Adjust truncation as needed\n#    if idx >= 2:  # Limiting to first few examples for brevity\n#        break\n\n# Displaying the first few entries from solutions\n#print(\"\\nSolutions - First few entries:\")\n#for idx, (key, value) in enumerate(solutions.items()):\n#    print(f\"Key: {key}, Solution: {value}\")\n#    if idx >= 2:\n#        break\n\nprint('Done')\n'''Summary of the Code:\nThis script loads two JSON files containing data from the ARC Prize 2024 competition:\n\nLoading JSON Files:\n\nIt loads evaluation challenges from arc-agi_evaluation_challenges.json and solutions from arc-agi_evaluation_solutions.json using Python's json module.\nDisplaying Data (Commented Out):\n\nIt is set up to display the first few entries from both the challenges and solutions by iterating over them and truncating values for readability.'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T11:07:18.804881Z","iopub.execute_input":"2025-03-18T11:07:18.805219Z","iopub.status.idle":"2025-03-18T11:07:18.890813Z","shell.execute_reply.started":"2025-03-18T11:07:18.805191Z","shell.execute_reply":"2025-03-18T11:07:18.890164Z"}},"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"\"Summary of the Code:\\nThis script loads two JSON files containing data from the ARC Prize 2024 competition:\\n\\nLoading JSON Files:\\n\\nIt loads evaluation challenges from arc-agi_evaluation_challenges.json and solutions from arc-agi_evaluation_solutions.json using Python's json module.\\nDisplaying Data (Commented Out):\\n\\nIt is set up to display the first few entries from both the challenges and solutions by iterating over them and truncating values for readability.\""},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import torch\n\ndef evaluate_single_example_with_reasoning(model, tokenizer, challenges, solutions, key):\n    # Determine the device the model is already on\n    device = next(model.parameters()).device\n\n    # Retrieve the specified challenge data\n    if key not in challenges:\n        print(f\"Key {key} not found in challenges.\")\n        return\n\n    challenge_data = challenges[key]\n    test_inputs = [test_case['input'] for test_case in challenge_data['test']]\n    training_examples = challenge_data['train']\n\n    # Generate model output for each test input, while including previous examples for reasoning\n    model_outputs = []\n    for input_data in test_inputs:\n        # Format the training examples into a chain of thought\n        examples = \"\"\n        for example in training_examples:\n            input_example = example['input']\n            output_example = example['output']\n            # Format the example input and output with reasoning prompt\n            examples += f\"Example Input: {input_example}\\nExample Output: {output_example}\\n\\n\"\n        \n        # Add the test input with an instruction for the model to apply the same transformation\n        input_text = f\"Given the previous examples, please apply the same transformation rule to the following input:\\nTest Input: {input_data}\\nTransformation Result (Complete the full matrix):\"\n\n        # Combine the training examples and the test input into one prompt\n        full_prompt = examples + input_text\n\n        # Tokenize the prompt and move it to the model's device\n        inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n\n        # Remove 'token_type_ids' if present, as LLaMA models do not use it\n        if 'token_type_ids' in inputs:\n            del inputs['token_type_ids']\n\n        # Generate model output with more tokens to ensure full matrix is generated\n        with torch.no_grad():\n            output_ids = model.generate(\n                **inputs, \n                max_new_tokens=300,  # Increased limit to allow for a larger output\n                temperature=0.7,    # Control randomness\n                top_p=0.9,          # Nucleus sampling\n                do_sample=False     # Use greedy decoding to reduce randomness\n            )\n        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n        model_outputs.append(output_text)\n    \n    # Retrieve the expected solution\n    expected_solution = solutions.get(key)\n    \n    # Display results\n    print(f\"Key: {key}\")\n    print(f\"Test Inputs: {test_inputs}\")\n    print(f\"Model Outputs: {model_outputs}\")\n    print(f\"Expected Solution: {expected_solution}\")\n\n    # Compare model output with expected solution (adjust comparison logic as needed)\n    if model_outputs == expected_solution:\n        print(\"Result: Match\")\n    else:\n        print(\"Result: No Match\")\n\n# Example usage with a specific key (replace '00576224' with your desired key)\nevaluate_single_example_with_reasoning(model, tokenizer, challenges, solutions, '00576224')\n\n\n'''Summary of the Code:\nThis function evaluates a single challenge example with reasoning by using a pre-trained model to generate outputs and compare them to the expected solutions.\n\nKey Steps:\nModel and Tokenizer Setup:\n\nRetrieves the device (GPU/CPU) where the model is located.\nChallenge Data Retrieval:\n\nThe function retrieves test inputs and training examples for a given challenge key from the challenges dictionary.\nPrompt Construction:\n\nFor each test input:\nTraining examples are formatted as a chain of thought for reasoning.\nThe test input is then formatted with an instruction to apply the same transformation rule.\nThe full prompt (training examples + test input) is created for the model.\nModel Output Generation:\n\nThe prompt is tokenized and moved to the appropriate device.\nThe model generates a transformation output for each test input using greedy decoding (no randomness).\nOutput Comparison:\n\nThe model outputs are compared to the expected solution from the solutions dictionary.\nDisplay Results:\n\nPrints:\nTest Inputs\nModel Outputs\nExpected Solution\nCompares and prints whether the model's output matches the expected solution.\nPurpose:\nThis function is designed to evaluate the model’s ability to generate the correct transformation for a given challenge, using previous examples for reasoning.\nIt compares the generated output to the expected solution to assess accuracy.'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T11:09:26.656980Z","iopub.execute_input":"2025-03-18T11:09:26.657346Z","iopub.status.idle":"2025-03-18T11:09:43.436620Z","shell.execute_reply.started":"2025-03-18T11:09:26.657316Z","shell.execute_reply":"2025-03-18T11:09:43.435763Z"}},"outputs":[{"name":"stdout","text":"Key: 00576224\nTest Inputs: [[[3, 2], [7, 8]]]\nModel Outputs: ['Example Input: [[8, 6], [6, 4]]\\nExample Output: [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]\\n\\nExample Input: [[7, 9], [4, 3]]\\nExample Output: [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]\\n\\nGiven the previous examples, please apply the same transformation rule to the following input:\\nTest Input: [[3, 2], [7, 8]]\\nTransformation Result (Complete the full matrix): [[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]\\nSolution to input1:\\n        [[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]\\n        ']\nExpected Solution: [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\nResult: No Match\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import torch\n\ndef extract_matrix_from_output(output_text):\n    # This function extracts the matrix from the model's output by cutting off unwanted parts.\n    \n    # Find the portion of the output after \"Solution to input1:\" and clean it up.\n    if \"Solution to input1:\" in output_text:\n        matrix_text = output_text.split(\"Solution to input1:\")[-1]  # Get the part after \"Solution to input1:\"\n    else:\n        matrix_text = output_text  # If the string isn't found, use the full output\n    \n    # Clean up the string by removing extra spaces and newlines\n    matrix_text = matrix_text.strip()\n    matrix_text = matrix_text.replace(\"\\n\", \" \")  # Replace line breaks with spaces\n    matrix_text = matrix_text.replace(\"        \", \"\")  # Remove excess spaces (indentation)\n    \n    # Try to convert the cleaned-up string to a list (matrix form)\n    try:\n        matrix = eval(matrix_text)  # Convert the string representation of a list to a Python list\n    except Exception as e:\n        print(f\"Error parsing matrix: {e}\")\n        matrix = None\n    \n    return matrix\n\ndef evaluate_single_example_with_reasoning(model, tokenizer, challenges, solutions, key):\n    # Determine the device the model is already on\n    device = next(model.parameters()).device\n\n    # Retrieve the specified challenge data\n    if key not in challenges:\n        print(f\"Key {key} not found in challenges.\")\n        return\n\n    challenge_data = challenges[key]\n    test_inputs = [test_case['input'] for test_case in challenge_data['test']]\n    training_examples = challenge_data['train']\n\n    # Generate model output for each test input, while including previous examples for reasoning\n    model_outputs = []\n    for input_data in test_inputs:\n        # Format the training examples into a chain of thought\n        examples = \"\"\n        for example in training_examples:\n            input_example = example['input']\n            output_example = example['output']\n            # Format the example input and output with reasoning prompt\n            examples += f\"Example Input: {input_example}\\nExample Output: {output_example}\\n\\n\"\n        \n        # Add the test input with an instruction for the model to apply the same transformation\n        input_text = f\"Given the previous examples, please apply the same transformation rule to the following input:\\nTest Input: {input_data}\\nTransformation Result (Complete the full matrix):\"\n\n        # Combine the training examples and the test input into one prompt\n        full_prompt = examples + input_text\n\n        # Tokenize the prompt and move it to the model's device\n        inputs = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n\n        # Remove 'token_type_ids' if present, as LLaMA models do not use it\n        if 'token_type_ids' in inputs:\n            del inputs['token_type_ids']\n\n        # Generate model output with more tokens to ensure full matrix is generated\n        with torch.no_grad():\n            output_ids = model.generate(\n                **inputs, \n                #max_new_tokens=300,  # Increased limit to allow for a larger output\n                temperature=0.7,    # Control randomness\n                top_p=0.9,          # Nucleus sampling\n                do_sample=False     # Use greedy decoding to reduce randomness\n            )\n        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\n        # Extract the matrix from the model's output\n        extracted_matrix = extract_matrix_from_output(output_text)\n        \n        if extracted_matrix is not None:\n            model_outputs.append(extracted_matrix)\n    \n    # Retrieve the expected solution\n    expected_solution = solutions.get(key)\n    \n    # Display results\n    print(f\"Key: {key}\")\n    print(f\"Test Inputs: {test_inputs}\")\n    print(f\"Model Outputs: {model_outputs}\")\n    print(f\"Expected Solution: {expected_solution}\")\n\n    # Compare the extracted model output with the expected solution (matrix only)\n    if model_outputs == expected_solution:\n        print(\"Result: Match\")\n    else:\n        print(\"Result: No Match\")\n\nprint('Done')\n\n'''Summary of the Code:\nThis script evaluates a single challenge example with reasoning, extracts a matrix from the model's output, and compares it with the expected solution.\n\nKey Functions:\nextract_matrix_from_output(output_text):\n\nExtracts and cleans the matrix from the model's output text.\nSearches for the phrase \"Solution to input1:\" and isolates the matrix portion.\nCleans up unwanted spaces and newlines, then attempts to convert the string representation of the matrix into a Python list using eval().\nevaluate_single_example_with_reasoning(model, tokenizer, challenges, solutions, key):\n\nModel Setup: Determines the device (GPU/CPU) the model is using.\nChallenge Data Retrieval: Gets the test inputs and training examples for the specific challenge (key).\nPrompt Creation: Constructs a prompt by formatting previous training examples and including the test input with instructions.\nModel Output Generation: Uses the tokenizer to prepare the input and the model to generate a prediction for the test input.\nMatrix Extraction: The extract_matrix_from_output() function is called to extract the matrix from the model’s output.\nSolution Comparison: Compares the extracted matrix with the expected solution from the solutions dictionary.\nPurpose:\nEvaluate the model's ability to generate the correct transformation of a matrix for a given challenge using previous examples for reasoning.\nExtracts the matrix from the model output and compares it with the expected solution.\nOutcome:\nDisplays whether the model's output matches the expected solution or not.\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T11:11:06.106602Z","iopub.execute_input":"2025-03-18T11:11:06.106898Z","iopub.status.idle":"2025-03-18T11:11:06.115998Z","shell.execute_reply.started":"2025-03-18T11:11:06.106874Z","shell.execute_reply":"2025-03-18T11:11:06.115110Z"}},"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"evaluate_single_example_with_reasoning(model, tokenizer, challenges, solutions, '00576224')\n'''\nThe function will output:\nTest Inputs for the challenge.\nModel Outputs for the generated transformation.\nExpected Solution.\nA comparison between the generated output and the expected solution.\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T11:11:53.148788Z","iopub.execute_input":"2025-03-18T11:11:53.149091Z","iopub.status.idle":"2025-03-18T11:12:10.027442Z","shell.execute_reply.started":"2025-03-18T11:11:53.149068Z","shell.execute_reply":"2025-03-18T11:12:10.026544Z"}},"outputs":[{"name":"stdout","text":"Key: 00576224\nTest Inputs: [[[3, 2], [7, 8]]]\nModel Outputs: [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\nExpected Solution: [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\nResult: Match\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import random\nimport json\n\n# Load the challenge dataset\nwith open(\"/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\", \"r\") as f:\n    examples = json.load(f)\n\n# Randomly select 50 keys from the dataset\nrandom_keys = random.sample(list(examples.keys()), 50)\n\n# Print the selected keys\nfor key in random_keys:\n    print(key)\n\n\n'''Summary of the Code:\nThe script performs the following tasks:\n\nImports Libraries:\n\nrandom: For random selection.\njson: To load the challenge dataset from a JSON file.\nLoad the Dataset:\n\nThe challenge data is loaded from arc-agi_evaluation_challenges.json.\nRandom Selection:\n\n50 random keys are selected from the dataset using random.sample(). This ensures that the selection is without duplication.\nOutput:\n\nThe randomly selected keys (representing individual challenges) are printed to the console.\nPurpose:\nTo randomly sample a subset of keys (50 in this case) from the challenge dataset for further analysis, processing, or evaluation.\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T11:13:04.469344Z","iopub.execute_input":"2025-03-18T11:13:04.469686Z","iopub.status.idle":"2025-03-18T11:13:04.864983Z","shell.execute_reply.started":"2025-03-18T11:13:04.469659Z","shell.execute_reply":"2025-03-18T11:13:04.864162Z"}},"outputs":[{"name":"stdout","text":"d56f2372\n212895b5\n0a2355a6\nf21745ec\n5af49b42\n516b51b7\n4c177718\n2a5f8217\nf0afb749\n1e97544e\ne41c6fd3\nb942fd60\n1acc24af\nc7d4e6ad\n903d1b4a\n0c786b71\n0becf7df\n1c56ad9f\n4aab4007\n4ff4c9da\naab50785\nca8f78db\n0b17323b\nbd14c3bf\n42a15761\ne99362f0\nda515329\ne78887d1\n8fbca751\n4acc7107\n96a8c0cd\nc6e1b8da\n5b692c0f\n03560426\nf83cb3f6\n32e9702f\ne760a62e\n72207abc\n31adaf00\n48f8583b\nf9a67cb5\n705a3229\n817e6c09\n1d398264\n79369cc6\n73182012\ncad67732\n5833af48\n11e1fe23\necaa0ec1\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import torch\n\ndef extract_matrix_from_output(output_text):\n    # Extracts the matrix from the model's output by cutting off unwanted parts.\n    if \"Solution to input1:\" in output_text:\n        matrix_text = output_text.split(\"Solution to input1:\")[-1]\n    else:\n        matrix_text = output_text\n    matrix_text = matrix_text.strip().replace(\"\\n\", \" \").replace(\"        \", \"\")\n    try:\n        import ast\n        matrix = ast.literal_eval(matrix_text)\n    except Exception as e:\n        print(f\"Error parsing matrix: {e}\")\n        matrix = None\n    return matrix\n\ndef evaluate_single_example_with_reasoning(model, tokenizer, challenges, solutions, key):\n    print(f\"Evaluating key: {key}...\")\n    \n    device = next(model.parameters()).device\n    if key not in challenges:\n        print(f\"Key {key} not found in challenges.\")\n        return\n    \n    challenge_data = challenges[key]\n    test_inputs = [test_case['input'] for test_case in challenge_data['test']]\n    training_examples = challenge_data['train']\n    \n    model_outputs = []\n    for input_data in test_inputs:\n        examples = \"\"\n        for example in training_examples:\n            input_example = example['input']\n            output_example = example['output']\n            examples += f\"Example Input: {input_example}\\nExample Output: {output_example}\\n\\n\"\n        \n        input_text = f\"Given the previous examples, please apply the same transformation rule to the following input:\\nTest Input: {input_data}\\nTransformation Result (Complete the full matrix):\"\n        full_prompt = examples + input_text\n        \n        # Tokenize input with a higher max_length setting\n        max_input_length = 2048  # Match with fine-tuning context length\n        inputs = tokenizer(full_prompt, return_tensors=\"pt\", truncation=True, max_length=max_input_length).to(device)\n        \n        if 'token_type_ids' in inputs:\n            del inputs['token_type_ids']\n        \n        print(\"Generating output...\")\n        with torch.no_grad():\n            try:\n                output_ids = model.generate(\n                    **inputs,\n                    max_new_tokens=2048,  # Adjust this value if needed\n                    temperature=0.7,\n                    top_p=0.9,\n                    do_sample=False\n                )\n            except Exception as e:\n                print(f\"Error during generation: {e}\")\n                continue  # Skip to the next test input if generation fails\n        \n        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n        print(f\"Decoded output text: {output_text}\")\n        \n        extracted_matrix = extract_matrix_from_output(output_text)\n        \n        if extracted_matrix is not None:\n            model_outputs.append(extracted_matrix)\n    \n    expected_solution = solutions.get(key)\n    \n    print(f\"Key: {key}\")\n    print(f\"Test Inputs: {test_inputs}\")\n    print(f\"Model Outputs: {output_text}\")\n    print(f\"Expected Solution: {expected_solution}\")\n\n    if model_outputs == expected_solution:\n        print(\"Result: Match\")\n    else:\n        print(\"Result: No Match\")\n\n# Example usage with a specific key\nevaluate_single_example_with_reasoning(model, tokenizer, challenges, solutions, '00576224')\n\n'''Summary of the Code:\nThe code defines and executes a process for evaluating a specific challenge from a dataset using a model. Here are the steps involved:\n\nFunction: extract_matrix_from_output:\n\nPurpose: This function extracts a matrix from the model’s output by removing unnecessary parts and converting the remaining string into a Python list.\nProcess:\nSearches for the substring \"Solution to input1:\" to identify the relevant portion of the output.\nCleans up the text (removes extra spaces, newlines, and indentation).\nAttempts to parse the cleaned string as a Python list using ast.literal_eval().\nFunction: evaluate_single_example_with_reasoning:\n\nPurpose: This function evaluates a single example using the model, generating outputs based on the given challenge, and compares them to the expected solution.\nSteps:\nData Retrieval: Retrieves the relevant challenge data based on the provided key from the challenges dictionary.\nInput Preparation: Formats the training examples into a prompt and combines it with the test input.\nTokenization: Tokenizes the prompt, ensuring it fits within the model's input length limits (max 2048 tokens).\nModel Generation: Uses the model to generate an output based on the formatted prompt.\nMatrix Extraction: Extracts the matrix (output) from the model's response.\nComparison: Compares the generated matrix with the expected solution from the solutions dictionary.\nResults: Prints the results, indicating whether the model's output matches the expected solution.\nExample Usage:\n\nThe function is called with a specific challenge key (in this case, '00576224'), and the model is used to evaluate the challenge. The function prints the inputs, model's output, and expected solution for comparison.\nOutput:\nFor each challenge key, the function prints:\nTest Inputs\nModel Outputs\nExpected Solution\nResult (whether the output matches the expected solution)\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T11:15:32.515191Z","iopub.execute_input":"2025-03-18T11:15:32.515483Z","iopub.status.idle":"2025-03-18T11:15:49.321487Z","shell.execute_reply.started":"2025-03-18T11:15:32.515462Z","shell.execute_reply":"2025-03-18T11:15:49.320556Z"}},"outputs":[{"name":"stdout","text":"Evaluating key: 00576224...\nGenerating output...\nDecoded output text: Example Input: [[8, 6], [6, 4]]\nExample Output: [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]\n\nExample Input: [[7, 9], [4, 3]]\nExample Output: [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]\n\nGiven the previous examples, please apply the same transformation rule to the following input:\nTest Input: [[3, 2], [7, 8]]\nTransformation Result (Complete the full matrix): [[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]\nSolution to input1:\n        [[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]\n        \nKey: 00576224\nTest Inputs: [[[3, 2], [7, 8]]]\nModel Outputs: Example Input: [[8, 6], [6, 4]]\nExample Output: [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]\n\nExample Input: [[7, 9], [4, 3]]\nExample Output: [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]\n\nGiven the previous examples, please apply the same transformation rule to the following input:\nTest Input: [[3, 2], [7, 8]]\nTransformation Result (Complete the full matrix): [[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]\nSolution to input1:\n        [[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]\n        \nExpected Solution: [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\nResult: Match\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"evaluate_single_example_with_reasoning(model, tokenizer, challenges, solutions, 'e0fb7511')\n'''Expected Output:\n\nThe function prints the following for the key 'e0fb7511':\nTest Inputs: The input data for the challenge.\nModel Outputs: The output generated by the model.\nExpected Solution: The ground truth solution for the challenge.\nResult: Whether the model's output matches the expected solution.\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T11:16:02.931661Z","iopub.execute_input":"2025-03-18T11:16:02.931955Z","iopub.status.idle":"2025-03-18T11:19:02.737422Z","shell.execute_reply.started":"2025-03-18T11:16:02.931932Z","shell.execute_reply":"2025-03-18T11:19:02.736498Z"}},"outputs":[{"name":"stdout","text":"Evaluating key: e0fb7511...\nGenerating output...\nDecoded output text: Example Input: [[1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0], [1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], [0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1], [1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]]\nExample Output: [[1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 8, 8, 8, 1, 1, 8, 1, 1, 0], [1, 1, 8, 8, 1, 1, 8, 1, 1, 8, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], [0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1], [1, 0, 1, 1, 1, 1, 8, 8, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 8, 1, 1]]\n\nExample Input: [[1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1], [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1], [1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1], [1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1], [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0], [1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1], [0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1], [1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1]]\nExample Output: [[1, 1, 1, 8, 8, 1, 1, 1, 8, 1, 0, 1, 1], [1, 1, 0, 1, 1, 1, 1, 1, 8, 8, 1, 0, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1], [1, 1, 8, 8, 1, 0, 1, 1, 0, 1, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 0, 1, 1, 1, 0, 1, 8, 1, 1, 1], [1, 8, 8, 1, 1, 1, 0, 1, 1, 8, 8, 1, 1], [1, 8, 8, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0], [1, 8, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1], [8, 8, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], [8, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 8, 1], [1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 8, 8, 1]]\n\nExample Input: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\nError parsing matrix: invalid syntax (<unknown>, line 1)\nKey: e0fb7511\nTest Inputs: [[[1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1], [0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0], [0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1], [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0], [1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0], [1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0], [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0], [1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1], [0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1], [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0], [1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1]]]\nModel Outputs: Example Input: [[1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0], [1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], [0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1], [1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]]\nExample Output: [[1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 8, 8, 8, 1, 1, 8, 1, 1, 0], [1, 1, 8, 8, 1, 1, 8, 1, 1, 8, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], [0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1], [1, 0, 1, 1, 1, 1, 8, 8, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 8, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 8, 8, 1, 1]]\n\nExample Input: [[1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1], [1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1], [1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1], [1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1], [1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0], [1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1], [0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1], [1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1]]\nExample Output: [[1, 1, 1, 8, 8, 1, 1, 1, 8, 1, 0, 1, 1], [1, 1, 0, 1, 1, 1, 1, 1, 8, 8, 1, 0, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1], [1, 1, 8, 8, 1, 0, 1, 1, 0, 1, 1, 1, 1], [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [1, 1, 1, 0, 1, 1, 1, 0, 1, 8, 1, 1, 1], [1, 8, 8, 1, 1, 1, 0, 1, 1, 8, 8, 1, 1], [1, 8, 8, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0], [1, 8, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1], [8, 8, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1], [8, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1], [1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 8, 1], [1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 8, 8, 1]]\n\nExample Input: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\nExpected Solution: [[[1, 1, 1, 8, 8, 1, 1, 1, 1, 1, 8, 8, 1], [0, 1, 1, 1, 8, 1, 1, 1, 1, 1, 1, 8, 8], [1, 1, 8, 8, 8, 1, 1, 0, 1, 1, 0, 1, 8], [0, 1, 1, 8, 1, 1, 1, 1, 1, 0, 1, 0, 1], [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1], [1, 8, 1, 0, 1, 1, 8, 1, 1, 1, 0, 1, 8], [1, 8, 8, 1, 0, 1, 8, 1, 1, 1, 1, 1, 8], [1, 8, 1, 0, 1, 1, 1, 1, 8, 8, 8, 1, 8], [1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 8, 1, 8], [1, 0, 1, 8, 8, 1, 1, 1, 1, 8, 8, 1, 1], [0, 1, 1, 8, 1, 1, 1, 1, 0, 1, 8, 1, 1], [1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 8, 1, 0], [1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1]]]\nResult: No Match\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"evaluate_single_example_with_reasoning(model, tokenizer, challenges, solutions, '414297c0')\n\n'''Expected Output:\nTest Inputs: The inputs provided to the model for evaluation.\nModel Outputs: The generated output by the model after applying the transformation rules.\nExpected Solution: The solution from the dataset corresponding to the key '414297c0'.\nResult: A statement showing whether the model's output matches the expected solution.'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T11:19:07.710800Z","iopub.execute_input":"2025-03-18T11:19:07.711195Z","iopub.status.idle":"2025-03-18T11:22:07.256186Z","shell.execute_reply.started":"2025-03-18T11:19:07.711156Z","shell.execute_reply":"2025-03-18T11:22:07.255043Z"}},"outputs":[{"name":"stdout","text":"Evaluating key: 414297c0...\nGenerating output...\nDecoded output text: Example Input: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 2, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 7, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 2, 4, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 2, 8, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 0], [0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 8, 1, 1, 1, 1, 7, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\nExample Output: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 2, 3, 2, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1], [1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1], [1, 1, 1, 2, 4, 2, 1, 1, 1, 1, 1], [1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1], [1, 2, 8, 2, 1, 1, 2, 7, 2, 1, 1], [1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n\nExample Input: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0,\nError parsing matrix: invalid syntax (<unknown>, line 1)\nKey: 414297c0\nTest Inputs: [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 7, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 2, 2, 0, 0, 0], [0, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 0, 0, 0, 0, 8, 2, 0, 0], [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 2, 2, 0, 0], [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 4, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]\nModel Outputs: Example Input: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 2, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 7, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 2, 4, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 2, 8, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 0], [0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 8, 1, 1, 1, 1, 7, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\nExample Output: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 2, 3, 2, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1], [1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1], [1, 1, 1, 2, 4, 2, 1, 1, 1, 1, 1], [1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1], [1, 2, 8, 2, 1, 1, 2, 7, 2, 1, 1], [1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n\nExample Input: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0], [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0,\nExpected Solution: [[[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], [4, 4, 2, 1, 2, 4, 4, 4, 4, 4, 4, 2, 7, 2, 4], [4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4], [4, 4, 4, 4, 4, 4, 4, 4, 2, 6, 4, 4, 4, 4, 4], [4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 2, 2, 4], [2, 3, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 2], [2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2]]]\nResult: No Match\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"\"Expected Output:\\nTest Inputs: The inputs provided to the model for evaluation.\\nModel Outputs: The generated output by the model after applying the transformation rules.\\nExpected Solution: The solution from the dataset corresponding to the key '414297c0'.\\nResult: A statement showing whether the model's output matches the expected solution.\""},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"challenges['414297c0']","metadata":{"trusted":true},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'test': [{'input': [[0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 2, 7, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 2, 2, 0, 0, 0],\n    [0, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 7, 4, 4, 0, 0, 0, 0, 8, 2, 0, 0],\n    [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 2, 2, 0, 0],\n    [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 2, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0]]}],\n 'train': [{'input': [[0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0,\n     0],\n    [0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 2, 0, 0, 0, 2, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 2, 7, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n    [0, 0, 0, 0, 2, 4, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n    [0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n    [0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n    [0, 2, 8, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 0],\n    [0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 8, 1, 1, 1, 1, 7, 1, 1, 1, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n   'output': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 2, 3, 2, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1],\n    [1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1],\n    [1, 1, 1, 2, 4, 2, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n    [1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1],\n    [1, 2, 8, 2, 1, 1, 2, 7, 2, 1, 1],\n    [1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1],\n    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]},\n  {'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0],\n    [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0],\n    [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 8, 1, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0],\n    [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 4, 2, 0, 0, 0, 0, 0, 0],\n    [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0],\n    [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 8, 8, 8, 4, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 8, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n   'output': [[8, 8, 8, 8, 8, 8],\n    [8, 2, 8, 8, 8, 8],\n    [2, 1, 2, 8, 8, 8],\n    [2, 8, 8, 8, 8, 8],\n    [8, 8, 8, 8, 8, 8],\n    [8, 8, 8, 8, 8, 8],\n    [8, 8, 2, 8, 2, 8],\n    [8, 8, 8, 4, 2, 8],\n    [8, 8, 2, 2, 2, 8]]},\n  {'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0],\n    [0, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0],\n    [0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0],\n    [0, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0],\n    [0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 0, 0, 0, 0, 0],\n    [0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0],\n    [0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 2, 8, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n   'output': [[3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3],\n    [3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3],\n    [3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3],\n    [3, 2, 1, 2, 3, 3, 3, 3, 2, 2, 3, 3],\n    [3, 3, 2, 3, 3, 3, 3, 3, 2, 8, 3, 3],\n    [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3]]}]}"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"def evaluate_single_example_with_reasoning(model, tokenizer, challenges, solutions, key):\n    print(f\"Evaluating key: {key}...\")\n    \n    device = next(model.parameters()).device\n    if key not in challenges:\n        print(f\"Key {key} not found in challenges.\")\n        return\n    \n    challenge_data = challenges[key]\n    test_inputs = [test_case['input'] for test_case in challenge_data['test']]\n    training_examples = challenge_data['train']\n    \n    model_outputs = []\n    for input_data in test_inputs:\n        examples = \"\"\n        for example in training_examples:\n            input_example = example['input']\n            output_example = example['output']\n            examples += f\"Example Input: {input_example}\\nExample Output: {output_example}\\n\\n\"\n        \n        input_text = f\"Given the previous examples, please apply the same transformation rule to the following input:\\nTest Input: {input_data}\\nTransformation Result (Complete the full matrix):\"\n        full_prompt = examples + input_text\n        \n        # Tokenization length check before generating output\n        inputs = tokenize_and_check_length(full_prompt, tokenizer)\n        if inputs is None:\n            print(\"Skipping input due to excessive token length.\")\n            continue\n        \n        inputs = inputs.to(device)\n        if 'token_type_ids' in inputs:\n            del inputs['token_type_ids']\n        \n        print(\"Generating output...\")\n        with torch.no_grad():\n            try:\n                output_ids = model.generate(\n                    **inputs,\n                    max_new_tokens=2048,  # Adjust this value if needed\n                    temperature=0.7,\n                    top_p=0.9,\n                    do_sample=False\n                )\n            except Exception as e:\n                print(f\"Error during generation: {e}\")\n                continue  # Skip to the next test input if generation fails\n        \n        output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n        print(f\"Decoded output text: {output_text}\")\n        \n        extracted_matrix = extract_matrix_from_output(output_text)\n        \n        if extracted_matrix is not None:\n            model_outputs.append(extracted_matrix)\n    \n    expected_solution = solutions.get(key)\n    \n    print(f\"Key: {key}\")\n    print(f\"Test Inputs: {test_inputs}\")\n    print(f\"Model Outputs: {model_outputs}\")\n    print(f\"Expected Solution: {expected_solution}\")\n\n    if model_outputs == expected_solution:\n        print(\"Result: Match\")\n    else:\n        print(\"Result: No Match\")\n\nprint('Done')\n'''\nThe function evaluate_single_example_with_reasoning() evaluates a specific challenge from a dataset by performing the following steps:\n\nRetrieve Data: \nIt checks if the given key exists in the challenges dictionary and extracts the corresponding challenge data, including test inputs and training examples.\n\nGenerate Model Output: \nFor each test input, the function formats the training examples into a chain of thought, creates a new prompt, and passes it to the model to generate an output.\n\nTokenization and Length Check: \nThe input is tokenized, ensuring that the prompt's token length does not exceed the model's input capacity.\n\nModel Output Generation: \nThe model generates an output using greedy decoding with specified parameters for randomness control.\n\nMatrix Extraction: \nAfter generating the output, the function extracts relevant information (e.g., a matrix) from the model's response using extract_matrix_from_output().\n\nSolution Comparison: \nIt compares the extracted output with the expected solution from the solutions dataset, printing the results and whether the output matches the expected solution.'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T11:24:12.370109Z","iopub.execute_input":"2025-03-18T11:24:12.370452Z","iopub.status.idle":"2025-03-18T11:24:12.381585Z","shell.execute_reply.started":"2025-03-18T11:24:12.370426Z","shell.execute_reply":"2025-03-18T11:24:12.380666Z"}},"outputs":[{"name":"stdout","text":"Done\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"\"\\nThe function evaluate_single_example_with_reasoning() evaluates a specific challenge from a dataset by performing the following steps:\\n\\nRetrieve Data: \\nIt checks if the given key exists in the challenges dictionary and extracts the corresponding challenge data, including test inputs and training examples.\\n\\nGenerate Model Output: \\nFor each test input, the function formats the training examples into a chain of thought, creates a new prompt, and passes it to the model to generate an output.\\n\\nTokenization and Length Check: \\nThe input is tokenized, ensuring that the prompt's token length does not exceed the model's input capacity.\\n\\nModel Output Generation: \\nThe model generates an output using greedy decoding with specified parameters for randomness control.\\n\\nMatrix Extraction: \\nAfter generating the output, the function extracts relevant information (e.g., a matrix) from the model's response using extract_matrix_from_output().\\n\\nSolution Comparison: \\nIt compares the extracted output with the expected solution from the solutions dataset, printing the results and whether the output matches the expected solution.\""},"metadata":{}}],"execution_count":26}]}