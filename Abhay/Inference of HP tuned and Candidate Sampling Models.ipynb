{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ac34ae-e8b6-4959-b693-5790d53ed7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Environment Reset & Libraries Loaded!\n"
     ]
    }
   ],
   "source": [
    "# ✅ Import Required Libraries\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# ✅ Clear GPU memory before starting fresh\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n✅ Environment Reset & Libraries Loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f088f3a5-5b47-455a-b304-ce32275584a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Loaded 200 filtered JSON files for evaluation.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the filtered 200 shortest JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(filtered_files)} filtered JSON files for evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca01a1fc-9576-49b5-9335-e4d145c6200f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ `construct_fixed_prompt` function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# ✅ Function to construct a well-formatted prompt from JSON files\n",
    "def construct_fixed_prompt(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # ✅ Extract training & test examples\n",
    "    training_examples = data.get(\"train\", [])\n",
    "    test_examples = data.get(\"test\", [])\n",
    "\n",
    "    if not test_examples or not training_examples:\n",
    "        return None  # Skip if missing data\n",
    "\n",
    "    test_input = test_examples[0][\"input\"]\n",
    "    \n",
    "    # ✅ Build a strong prompt\n",
    "    prompt = \"Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\\n\\n\"\n",
    "\n",
    "    for ex in training_examples:\n",
    "        prompt += f\"Input: {ex['input']}\\n\"\n",
    "        prompt += f\"Output: {ex['output']}\\n\\n\"\n",
    "\n",
    "    prompt += f\"Test Input Matrix:\\n{test_input}\\n\\n\"\n",
    "    prompt += \"**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "print(\"\\n✅ `construct_fixed_prompt` function defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913b9e46-cd5a-4848-b1d2-12b717cd34bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ `extract_final_matrix` function updated: Now returns `None` when no matrix is found.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ✅ Function to extract matrix after instruction text and stop at first `]]`\n",
    "def extract_final_matrix(generated_text):\n",
    "    instruction_text = \"Provide ONLY the final output matrix for the test input. Do NOT include any other text.\"\n",
    "    \n",
    "    # ✅ Find where the instruction appears\n",
    "    start_idx = generated_text.find(instruction_text)\n",
    "    if start_idx == -1:\n",
    "        return None  # ✅ Return None instead of an alert\n",
    "\n",
    "    # ✅ Extract everything after the instruction\n",
    "    output_after_instruction = generated_text[start_idx + len(instruction_text):].strip()\n",
    "\n",
    "    # ✅ Use regex to find the first valid matrix **after the instruction text**\n",
    "    matrix_match = re.search(r\"\\[\\[.*?\\]\\]\", output_after_instruction, re.DOTALL)\n",
    "    \n",
    "    if matrix_match:\n",
    "        return matrix_match.group(0)  # ✅ Return the extracted matrix\n",
    "    else:\n",
    "        return None  # ✅ Return None if no valid matrix is found\n",
    "\n",
    "print(\"\\n✅ `extract_final_matrix` function updated: Now returns `None` when no matrix is found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd10c32-b22e-4bcd-9941-ad051180a584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running Model on CUDA:0 for 200 Examples...\n",
      "\n",
      "\n",
      "🚀 Running Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1 on cuda:0 for 200 datapoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 01:55:07.923845: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 01:55:08.169534: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-10 01:55:08.169563: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-10 01:55:08.169587: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 01:55:08.616425: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-10 01:55:23.048425: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8adfff655842858544777954796191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 2/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 3/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 4/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 5/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 6/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8e2edd66.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 7/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ad7e01d0.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 8/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fc754716.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 9/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27f8ce4f.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 10/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/59341089.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 11/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/833dafe3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 12/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed98d772.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 13/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d4b1c2b1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 14/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48131b3c.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 15/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0692e18c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 16/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8b28cd80.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 17/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/32e9702f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 18/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8719f442.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 19/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2072aba6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 20/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ea4a07e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 21/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48f8583b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 22/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/695367ec.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 23/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/15696249.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 24/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c92b942c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 25/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27a77e38.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 26/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60c09cac.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 27/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ccd554ac.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 28/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c786b71.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 29/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c1990cce.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 30/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7953d61e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 31/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66e6c45b.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 32/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5b6cbef5.json\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 31.73 GiB of which 1.56 GiB is free. Process 539717 has 7.63 GiB memory in use. Process 559429 has 13.25 GiB memory in use. Including non-PyTorch memory, this process has 9.28 GiB memory in use. Of the allocated memory 6.74 GiB is allocated by PyTorch, and 2.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 143\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# ✅ Run inference on all 200 examples\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🚀 Running Model on CUDA:0 for 200 Examples...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 143\u001b[0m \u001b[43mrun_inference_for_200_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ **Completed inference for 200 examples!** 🚀\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 93\u001b[0m, in \u001b[0;36mrun_inference_for_200_examples\u001b[0;34m(model_name, device)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# ✅ Run inference with safe parameters\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 93\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# ✅ Decode full output\u001b[39;00m\n\u001b[1;32m    104\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1190\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:945\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    933\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    934\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    935\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m         position_embeddings,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 945\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:676\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:373\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m+\u001b[39m causal_mask\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# upcast attention to fp32\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(query_states\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    374\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(attn_weights, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    375\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attn_weights, value_states)\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/functional.py:1858\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1856\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.10 GiB. GPU 0 has a total capacty of 31.73 GiB of which 1.56 GiB is free. Process 539717 has 7.63 GiB memory in use. Process 559429 has 13.25 GiB memory in use. Including non-PyTorch memory, this process has 9.28 GiB memory in use. Of the allocated memory 6.74 GiB is allocated by PyTorch, and 2.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the 200 filtered JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "# ✅ Use all 200 files\n",
    "num_samples = 200\n",
    "test_files = filtered_files[:num_samples]\n",
    "\n",
    "# ✅ Define model & assigned GPU\n",
    "model_name = \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "# ✅ Function to load ground truth matrix\n",
    "def load_ground_truth_matrix(json_file):\n",
    "    file_path = os.path.join(dataset_folder, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None\n",
    "\n",
    "    return test_examples[0][\"output\"]\n",
    "\n",
    "# ✅ Function to compare matrices\n",
    "def compare_matrices(predicted_matrix, ground_truth):\n",
    "    if predicted_matrix is None:\n",
    "        return \"⚠️ Invalid Output\"\n",
    "\n",
    "    try:\n",
    "        predicted_np = np.array(eval(predicted_matrix), dtype=int)\n",
    "        ground_truth_np = np.array(ground_truth, dtype=int)\n",
    "\n",
    "        if np.array_equal(predicted_np, ground_truth_np):\n",
    "            return \"✅ Correct\"\n",
    "        else:\n",
    "            return \"❌ Incorrect\"\n",
    "    except Exception as e:\n",
    "        return \"⚠️ Error in matrix comparison: \" + str(e)\n",
    "\n",
    "# ✅ Function to run inference for 200 examples (same logic as 10-example version)\n",
    "def run_inference_for_200_examples(model_name, device):\n",
    "    print(f\"\\n🚀 Running Model: {model_name} on {device} for {num_samples} datapoints\")\n",
    "\n",
    "    # ✅ Load Model on Assigned GPU\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map={\"\" : device}\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with safe parameters\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Compare extracted matrix with ground truth\n",
    "        result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "        # ✅ Store the result\n",
    "        results.append({\n",
    "            \"file\": file,\n",
    "            \"extracted_matrix\": extracted_matrix,\n",
    "            \"ground_truth\": ground_truth_matrix,\n",
    "            \"comparison_result\": result\n",
    "        })\n",
    "\n",
    "        print(f\"\\n📊 **Comparison Result:** {result}\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "        # ✅ Clear memory after every 50 examples\n",
    "        if (idx + 1) % 50 == 0:\n",
    "            save_path = f\"./{model_name.replace('/', '_')}_results_batch_{idx + 1}.json\"\n",
    "            with open(save_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            print(f\"\\n💾 Saved batch {idx + 1} results for {model_name}\")\n",
    "\n",
    "            # ✅ Clear memory\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n✅ Completed inference for {model_name}!\")\n",
    "\n",
    "# ✅ Run inference on all 200 examples\n",
    "print(\"\\n🚀 Running Model on CUDA:0 for 200 Examples...\\n\")\n",
    "run_inference_for_200_examples(model_name, device)\n",
    "\n",
    "print(\"\\n✅ **Completed inference for 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e43be78-bf66-4f3c-a9c4-7e3ce66ce484",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running Model across GPUs for remaining 168 Examples...\n",
      "\n",
      "\n",
      "🚀 Running Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1 across both GPUs for 168 remaining datapoints\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4f3d7d17dd4344b53876ffa730f56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 33/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bc4146bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 34/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4cd1b7b2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 35/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e133d23d.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 36/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e6de6e8f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 37/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/be03b35f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 38/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12422b43.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 39/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b15fca0b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 40/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ca8de6ea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 41/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7b06bea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 42/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f0afb749.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 43/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3979b1a8.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 44/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d017b73f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 45/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/17cae0c1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 46/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62b74c02.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 47/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31d5ba1a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 48/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e345f17b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 49/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa18de87.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 50/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73c3b0d8.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 50 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\n",
      "\n",
      "🚀 Running inference 51/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c074846d.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 52/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cad67732.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 53/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fb791726.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 54/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ba14f53.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 55/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5790162.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 56/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bbb1b8b6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 57/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2a5f8217.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 58/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5783df64.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 59/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b1fc8b8e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 60/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a8610ef7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 61/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/770cc55f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 62/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/68b67ca3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 63/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/67c52801.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 64/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c56f360.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 65/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/34b99a2b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 66/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed74f2f2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 67/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/506d28a5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 68/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/22a4bbc2.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 69/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d19f7514.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 70/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00dbd492.json\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacty of 31.73 GiB of which 103.44 MiB is free. Process 539717 has 7.63 GiB memory in use. Process 559429 has 13.25 GiB memory in use. Including non-PyTorch memory, this process has 10.74 GiB memory in use. Of the allocated memory 9.21 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 144\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# ✅ Run inference for remaining 168 datapoints using both GPUs\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🚀 Running Model across GPUs for remaining 168 Examples...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 144\u001b[0m \u001b[43mrun_inference_on_both_gpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ **Completed inference for all 200 examples!** 🚀\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 94\u001b[0m, in \u001b[0;36mrun_inference_on_both_gpus\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# ✅ Run inference with safe parameters\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 94\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# ✅ Decode full output\u001b[39;00m\n\u001b[1;32m    105\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1190\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:945\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    933\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    934\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    935\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m         position_embeddings,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 945\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:676\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:366\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m key_states \u001b[38;5;241m=\u001b[39m repeat_kv(key_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n\u001b[1;32m    365\u001b[0m value_states \u001b[38;5;241m=\u001b[39m repeat_kv(value_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n\u001b[0;32m--> 366\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# no matter the length, we just slice it\u001b[39;00m\n\u001b[1;32m    369\u001b[0m     causal_mask \u001b[38;5;241m=\u001b[39m attention_mask[:, :, :, : key_states\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.16 GiB. GPU 0 has a total capacty of 31.73 GiB of which 103.44 MiB is free. Process 539717 has 7.63 GiB memory in use. Process 559429 has 13.25 GiB memory in use. Including non-PyTorch memory, this process has 10.74 GiB memory in use. Of the allocated memory 9.21 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the 200 filtered JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "# ✅ Resume from Datapoint 32\n",
    "num_samples = 200\n",
    "start_from = 32\n",
    "test_files = filtered_files[start_from:num_samples]  # ✅ Skip first 31 files\n",
    "\n",
    "# ✅ Define model & assigned GPUs\n",
    "model_name = \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\"\n",
    "device_map = \"auto\"  # ✅ Auto-distributes across both GPUs\n",
    "\n",
    "# ✅ Function to load ground truth matrix\n",
    "def load_ground_truth_matrix(json_file):\n",
    "    file_path = os.path.join(dataset_folder, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None\n",
    "\n",
    "    return test_examples[0][\"output\"]\n",
    "\n",
    "# ✅ Function to compare matrices\n",
    "def compare_matrices(predicted_matrix, ground_truth):\n",
    "    if predicted_matrix is None:\n",
    "        return \"⚠️ Invalid Output\"\n",
    "\n",
    "    try:\n",
    "        predicted_np = np.array(eval(predicted_matrix), dtype=int)\n",
    "        ground_truth_np = np.array(ground_truth, dtype=int)\n",
    "\n",
    "        if np.array_equal(predicted_np, ground_truth_np):\n",
    "            return \"✅ Correct\"\n",
    "        else:\n",
    "            return \"❌ Incorrect\"\n",
    "    except Exception as e:\n",
    "        return \"⚠️ Error in matrix comparison: \" + str(e)\n",
    "\n",
    "# ✅ Function to run inference for remaining examples across both GPUs\n",
    "def run_inference_on_both_gpus(model_name):\n",
    "    print(f\"\\n🚀 Running Model: {model_name} across both GPUs for {num_samples - start_from} remaining datapoints\")\n",
    "\n",
    "    # ✅ Load Model across both GPUs\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"  # ✅ Distributes model across GPUs\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {start_from + idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")  # ✅ Auto-assigns to available GPU\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with safe parameters\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Compare extracted matrix with ground truth\n",
    "        result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "        # ✅ Store the result\n",
    "        results.append({\n",
    "            \"file\": file,\n",
    "            \"extracted_matrix\": extracted_matrix,\n",
    "            \"ground_truth\": ground_truth_matrix,\n",
    "            \"comparison_result\": result\n",
    "        })\n",
    "\n",
    "        print(f\"\\n📊 **Comparison Result:** {result}\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "        # ✅ Save every 50 datapoints to prevent progress loss\n",
    "        if (start_from + idx + 1) % 50 == 0:\n",
    "            save_path = f\"./{model_name.replace('/', '_')}_results_batch_{start_from + idx + 1}.json\"\n",
    "            with open(save_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            print(f\"\\n💾 Saved batch {start_from + idx + 1} results for {model_name}\")\n",
    "\n",
    "            # ✅ Clear memory\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n✅ Completed inference for {model_name} across both GPUs!\")\n",
    "\n",
    "# ✅ Run inference for remaining 168 datapoints using both GPUs\n",
    "print(\"\\n🚀 Running Model across GPUs for remaining 168 Examples...\\n\")\n",
    "run_inference_on_both_gpus(model_name)\n",
    "\n",
    "print(\"\\n✅ **Completed inference for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59835226-c695-4e2d-b087-9d148811ccd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running Model across GPUs for remaining 168 Examples...\n",
      "\n",
      "\n",
      "🚀 Running Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1 across both GPUs for 130 remaining datapoints\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9926c4c47ef24895811b29c155683149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 71/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7dd8335.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 72/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c8b7cc0f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 73/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/332efdb3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 74/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3b4c2228.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 75/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/626c0bcc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 76/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9110e3c5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 77/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6f473927.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 78/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c9aba6e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 79/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5d2a5c43.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 80/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12eac192.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 81/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66f2d22f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 82/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ad5bdfd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 83/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9bebae7a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 84/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/90347967.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 85/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d2acf2cb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 86/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2697da3f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 87/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d931c21c.json\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.78 GiB. GPU 1 has a total capacty of 31.73 GiB of which 3.94 GiB is free. Process 539717 has 6.58 GiB memory in use. Process 559429 has 396.00 MiB memory in use. Including non-PyTorch memory, this process has 20.81 GiB memory in use. Of the allocated memory 13.60 GiB is allocated by PyTorch, and 6.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 144\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# ✅ Run inference for remaining 168 datapoints using both GPUs\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🚀 Running Model across GPUs for remaining 168 Examples...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 144\u001b[0m \u001b[43mrun_inference_on_both_gpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ **Completed inference for all 200 examples!** 🚀\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 94\u001b[0m, in \u001b[0;36mrun_inference_on_both_gpus\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# ✅ Run inference with safe parameters\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 94\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# ✅ Decode full output\u001b[39;00m\n\u001b[1;32m    105\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1190\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:945\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    933\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    934\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    935\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m         position_embeddings,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 945\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:676\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:373\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m+\u001b[39m causal_mask\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# upcast attention to fp32\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(query_states\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    374\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(attn_weights, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_dropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    375\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attn_weights, value_states)\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/functional.py:1858\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1856\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.78 GiB. GPU 1 has a total capacty of 31.73 GiB of which 3.94 GiB is free. Process 539717 has 6.58 GiB memory in use. Process 559429 has 396.00 MiB memory in use. Including non-PyTorch memory, this process has 20.81 GiB memory in use. Of the allocated memory 13.60 GiB is allocated by PyTorch, and 6.84 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the 200 filtered JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "# ✅ Resume from Datapoint 32\n",
    "num_samples = 200\n",
    "start_from = 70\n",
    "test_files = filtered_files[start_from:num_samples]  # ✅ Skip first 31 files\n",
    "\n",
    "# ✅ Define model & assigned GPUs\n",
    "model_name = \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\"\n",
    "device_map = \"auto\"  # ✅ Auto-distributes across both GPUs\n",
    "\n",
    "# ✅ Function to load ground truth matrix\n",
    "def load_ground_truth_matrix(json_file):\n",
    "    file_path = os.path.join(dataset_folder, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None\n",
    "\n",
    "    return test_examples[0][\"output\"]\n",
    "\n",
    "# ✅ Function to compare matrices\n",
    "def compare_matrices(predicted_matrix, ground_truth):\n",
    "    if predicted_matrix is None:\n",
    "        return \"⚠️ Invalid Output\"\n",
    "\n",
    "    try:\n",
    "        predicted_np = np.array(eval(predicted_matrix), dtype=int)\n",
    "        ground_truth_np = np.array(ground_truth, dtype=int)\n",
    "\n",
    "        if np.array_equal(predicted_np, ground_truth_np):\n",
    "            return \"✅ Correct\"\n",
    "        else:\n",
    "            return \"❌ Incorrect\"\n",
    "    except Exception as e:\n",
    "        return \"⚠️ Error in matrix comparison: \" + str(e)\n",
    "\n",
    "# ✅ Function to run inference for remaining examples across both GPUs\n",
    "def run_inference_on_both_gpus(model_name):\n",
    "    print(f\"\\n🚀 Running Model: {model_name} across both GPUs for {num_samples - start_from} remaining datapoints\")\n",
    "\n",
    "    # ✅ Load Model across both GPUs\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"  # ✅ Distributes model across GPUs\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {start_from + idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")  # ✅ Auto-assigns to available GPU\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with safe parameters\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Compare extracted matrix with ground truth\n",
    "        result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "        # ✅ Store the result\n",
    "        results.append({\n",
    "            \"file\": file,\n",
    "            \"extracted_matrix\": extracted_matrix,\n",
    "            \"ground_truth\": ground_truth_matrix,\n",
    "            \"comparison_result\": result\n",
    "        })\n",
    "\n",
    "        print(f\"\\n📊 **Comparison Result:** {result}\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "        # ✅ Save every 50 datapoints to prevent progress loss\n",
    "        if (start_from + idx + 1) % 50 == 0:\n",
    "            save_path = f\"./{model_name.replace('/', '_')}_results_batch_{start_from + idx + 1}.json\"\n",
    "            with open(save_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            print(f\"\\n💾 Saved batch {start_from + idx + 1} results for {model_name}\")\n",
    "\n",
    "            # ✅ Clear memory\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n✅ Completed inference for {model_name} across both GPUs!\")\n",
    "\n",
    "# ✅ Run inference for remaining 168 datapoints using both GPUs\n",
    "print(\"\\n🚀 Running Model across GPUs for remaining 168 Examples...\\n\")\n",
    "run_inference_on_both_gpus(model_name)\n",
    "\n",
    "print(\"\\n✅ **Completed inference for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83baa9-9580-4524-965e-014b7805fd47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running Model across GPUs for remaining 168 Examples...\n",
      "\n",
      "\n",
      "🚀 Running Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1 across both GPUs for 113 remaining datapoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 03:47:34.124815: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 03:47:34.736442: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-10 03:47:34.736478: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-10 03:47:34.736506: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 03:47:35.054276: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-10 03:47:55.018761: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321c50c9dc224c2e803638129dfbf5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 88/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50a16a69.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 89/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1c0d0a4b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 90/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/195ba7dc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 91/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3d31c5b3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 92/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62ab2642.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 93/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6a11f6da.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 94/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/281123b4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 95/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ef26cbf6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 96/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/42a15761.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 97/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b4a43f3b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 98/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ae58858e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 99/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e69241bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 100/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/85fa5666.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 100 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\n",
      "\n",
      "🚀 Running inference 101/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8597cfd7.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the 200 filtered JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "# ✅ Resume from Datapoint 32\n",
    "num_samples = 200\n",
    "start_from = 87\n",
    "test_files = filtered_files[start_from:num_samples]  # ✅ Skip first 31 files\n",
    "\n",
    "# ✅ Define model & assigned GPUs\n",
    "model_name = \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\"\n",
    "device_map = \"auto\"  # ✅ Auto-distributes across both GPUs\n",
    "\n",
    "# ✅ Function to load ground truth matrix\n",
    "def load_ground_truth_matrix(json_file):\n",
    "    file_path = os.path.join(dataset_folder, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None\n",
    "\n",
    "    return test_examples[0][\"output\"]\n",
    "\n",
    "# ✅ Function to compare matrices\n",
    "def compare_matrices(predicted_matrix, ground_truth):\n",
    "    if predicted_matrix is None:\n",
    "        return \"⚠️ Invalid Output\"\n",
    "\n",
    "    try:\n",
    "        predicted_np = np.array(eval(predicted_matrix), dtype=int)\n",
    "        ground_truth_np = np.array(ground_truth, dtype=int)\n",
    "\n",
    "        if np.array_equal(predicted_np, ground_truth_np):\n",
    "            return \"✅ Correct\"\n",
    "        else:\n",
    "            return \"❌ Incorrect\"\n",
    "    except Exception as e:\n",
    "        return \"⚠️ Error in matrix comparison: \" + str(e)\n",
    "\n",
    "# ✅ Function to run inference for remaining examples across both GPUs\n",
    "def run_inference_on_both_gpus(model_name):\n",
    "    print(f\"\\n🚀 Running Model: {model_name} across both GPUs for {num_samples - start_from} remaining datapoints\")\n",
    "\n",
    "    # ✅ Load Model across both GPUs\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"  # ✅ Distributes model across GPUs\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {start_from + idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")  # ✅ Auto-assigns to available GPU\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with safe parameters\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Compare extracted matrix with ground truth\n",
    "        result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "        # ✅ Store the result\n",
    "        results.append({\n",
    "            \"file\": file,\n",
    "            \"extracted_matrix\": extracted_matrix,\n",
    "            \"ground_truth\": ground_truth_matrix,\n",
    "            \"comparison_result\": result\n",
    "        })\n",
    "\n",
    "        print(f\"\\n📊 **Comparison Result:** {result}\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "        # ✅ Save every 50 datapoints to prevent progress loss\n",
    "        if (start_from + idx + 1) % 50 == 0:\n",
    "            save_path = f\"./{model_name.replace('/', '_')}_results_batch_{start_from + idx + 1}.json\"\n",
    "            with open(save_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            print(f\"\\n💾 Saved batch {start_from + idx + 1} results for {model_name}\")\n",
    "\n",
    "            # ✅ Clear memory\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n✅ Completed inference for {model_name} across both GPUs!\")\n",
    "\n",
    "# ✅ Run inference for remaining 168 datapoints using both GPUs\n",
    "print(\"\\n🚀 Running Model across GPUs for remaining 168 Examples...\\n\")\n",
    "run_inference_on_both_gpus(model_name)\n",
    "\n",
    "print(\"\\n✅ **Completed inference for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8bd310-e7c7-4f2e-978c-5c067b0fa109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running Model across GPUs for remaining 168 Examples...\n",
      "\n",
      "\n",
      "🚀 Running Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1 across both GPUs for 99 remaining datapoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 04:26:54.485391: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 04:26:55.216206: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-10 04:26:55.216243: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-10 04:26:55.216273: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 04:26:55.258253: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-10 04:27:13.106363: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24da27eaabd7478abeacad5b156fc0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 102/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4852f2fa.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 103/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55783887.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 104/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72207abc.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 105/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d37a1ef5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 106/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/af24b4cc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 107/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c87289bb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 108/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1a2e2828.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 109/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8fbca751.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 110/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5207a7b5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 111/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0722778.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 112/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0a2355a6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 113/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0f4d537.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 114/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e99362f0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 115/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c35c1b4c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 116/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f45f5ca7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 117/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/64a7c07e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 118/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac3e2b04.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 119/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c7d4e6ad.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 120/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/84db8fc4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 121/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce039d91.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 122/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/99306f82.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 123/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2685904e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 124/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4acc7107.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 125/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4e469f39.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 126/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bf32578f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 127/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa300dc3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 128/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/137f0df0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 129/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/03560426.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 130/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/69889d6e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 131/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e9ac8c9e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 132/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cfb2ce5a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 133/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/da2b0fe3.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 134/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6df30ad6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 135/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3cdc58f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 136/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/58743b76.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 137/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a406ac07.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 138/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/94414823.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 139/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/575b1a71.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 140/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3e62deb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 141/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ea9794b1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 142/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31adaf00.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 143/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c1e755f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 144/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac605cbb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 145/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7c8af763.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 146/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7ee1c6ea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 147/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b942fd60.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 148/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/782b5218.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 149/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0becf7df.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 150/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/136b0064.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (18,) + inhomogeneous part.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 150 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\n",
      "\n",
      "🚀 Running inference 151/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dd2401ed.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 152/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50aad11f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 153/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2b01abd0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 154/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/292dd178.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 155/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce8d95cc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 156/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/423a55dc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 157/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/817e6c09.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 158/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/11e1fe23.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 159/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2c737e39.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 160/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ff72ca3e.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 161/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/93b4f4b3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 162/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fe9372f3.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 163/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ecaa0ec1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 164/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cd3c21df.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 165/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/08573cc6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 166/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/963f59bc.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 167/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dc2aa30b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 168/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9ddd00f0.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (14,) + inhomogeneous part.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 169/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5c44e8f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 170/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b7cb93ac.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 171/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f5aa3634.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 172/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72a961c9.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 173/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/45737921.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 174/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5ffb2104.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 175/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/516b51b7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 176/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/baf41dbf.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 177/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55059096.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 178/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/762cd429.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 179/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e78887d1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 180/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ee62060.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 181/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e872b94a.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 182/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/705a3229.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 183/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1acc24af.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 184/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/917bccba.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 185/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7e02026e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 186/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73182012.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 187/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9f27f097.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 188/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60a26a3e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 189/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3391f8c0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 190/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/505fff84.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 191/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12997ef3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 192/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/642248e4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 193/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/896d5239.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 194/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0bb8deee.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 195/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/992798f6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 196/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/712bf12e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 197/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9b365c51.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 198/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5af49b42.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 199/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c658a4bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 200/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/84f2aca1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 200 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\n",
      "\n",
      "✅ Completed inference for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1 across both GPUs!\n",
      "\n",
      "✅ **Completed inference for all 200 examples!** 🚀\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the 200 filtered JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "# ✅ Resume from Datapoint 32\n",
    "num_samples = 200\n",
    "start_from = 101\n",
    "test_files = filtered_files[start_from:num_samples]  # ✅ Skip first 31 files\n",
    "\n",
    "# ✅ Define model & assigned GPUs\n",
    "model_name = \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\"\n",
    "device_map = \"auto\"  # ✅ Auto-distributes across both GPUs\n",
    "\n",
    "# ✅ Function to load ground truth matrix\n",
    "def load_ground_truth_matrix(json_file):\n",
    "    file_path = os.path.join(dataset_folder, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None\n",
    "\n",
    "    return test_examples[0][\"output\"]\n",
    "\n",
    "# ✅ Function to compare matrices\n",
    "def compare_matrices(predicted_matrix, ground_truth):\n",
    "    if predicted_matrix is None:\n",
    "        return \"⚠️ Invalid Output\"\n",
    "\n",
    "    try:\n",
    "        predicted_np = np.array(eval(predicted_matrix), dtype=int)\n",
    "        ground_truth_np = np.array(ground_truth, dtype=int)\n",
    "\n",
    "        if np.array_equal(predicted_np, ground_truth_np):\n",
    "            return \"✅ Correct\"\n",
    "        else:\n",
    "            return \"❌ Incorrect\"\n",
    "    except Exception as e:\n",
    "        return \"⚠️ Error in matrix comparison: \" + str(e)\n",
    "\n",
    "# ✅ Function to run inference for remaining examples across both GPUs\n",
    "def run_inference_on_both_gpus(model_name):\n",
    "    print(f\"\\n🚀 Running Model: {model_name} across both GPUs for {num_samples - start_from} remaining datapoints\")\n",
    "\n",
    "    # ✅ Load Model across both GPUs\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"  # ✅ Distributes model across GPUs\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {start_from + idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")  # ✅ Auto-assigns to available GPU\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with safe parameters\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Compare extracted matrix with ground truth\n",
    "        result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "        # ✅ Store the result\n",
    "        results.append({\n",
    "            \"file\": file,\n",
    "            \"extracted_matrix\": extracted_matrix,\n",
    "            \"ground_truth\": ground_truth_matrix,\n",
    "            \"comparison_result\": result\n",
    "        })\n",
    "\n",
    "        print(f\"\\n📊 **Comparison Result:** {result}\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "        # ✅ Save every 50 datapoints to prevent progress loss\n",
    "        if (start_from + idx + 1) % 50 == 0:\n",
    "            save_path = f\"./{model_name.replace('/', '_')}_results_batch_{start_from + idx + 1}.json\"\n",
    "            with open(save_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            print(f\"\\n💾 Saved batch {start_from + idx + 1} results for {model_name}\")\n",
    "\n",
    "            # ✅ Clear memory\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n✅ Completed inference for {model_name} across both GPUs!\")\n",
    "\n",
    "# ✅ Run inference for remaining 168 datapoints using both GPUs\n",
    "print(\"\\n🚀 Running Model across GPUs for remaining 168 Examples...\\n\")\n",
    "run_inference_on_both_gpus(model_name)\n",
    "\n",
    "print(\"\\n✅ **Completed inference for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefab120-998b-4704-826b-8289f1ce104d",
   "metadata": {},
   "source": [
    "phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ba9e65-19b7-40ac-9991-7d7cc215935a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running Model across GPUs for remaining 168 Examples...\n",
      "\n",
      "\n",
      "🚀 Running Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings across both GPUs for 200 remaining datapoints\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ee7a53ede645fe95f5a19f5e5c02e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 2/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 3/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 4/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 5/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 6/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8e2edd66.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 7/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ad7e01d0.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 8/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fc754716.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 9/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27f8ce4f.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 10/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/59341089.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 11/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/833dafe3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 12/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed98d772.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 13/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d4b1c2b1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 14/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48131b3c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 15/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0692e18c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 16/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8b28cd80.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 17/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/32e9702f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 18/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8719f442.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 19/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2072aba6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 20/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ea4a07e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 21/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48f8583b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 22/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/695367ec.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 23/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/15696249.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 24/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c92b942c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 25/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27a77e38.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 26/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60c09cac.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 27/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ccd554ac.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 28/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c786b71.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 29/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c1990cce.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 30/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7953d61e.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 31/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66e6c45b.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 32/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5b6cbef5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 33/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bc4146bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 34/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4cd1b7b2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 35/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e133d23d.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 36/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e6de6e8f.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 37/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/be03b35f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 38/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12422b43.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 39/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b15fca0b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 40/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ca8de6ea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 41/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7b06bea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 42/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f0afb749.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 43/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3979b1a8.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 44/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d017b73f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 45/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/17cae0c1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 46/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62b74c02.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 47/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31d5ba1a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 48/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e345f17b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 49/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa18de87.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 50/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73c3b0d8.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 50 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\n",
      "\n",
      "🚀 Running inference 51/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c074846d.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 52/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cad67732.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 53/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fb791726.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 54/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ba14f53.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 55/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5790162.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 56/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bbb1b8b6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 57/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2a5f8217.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 58/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5783df64.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 59/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b1fc8b8e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 60/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a8610ef7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 61/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/770cc55f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 62/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/68b67ca3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 63/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/67c52801.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 64/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c56f360.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 65/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/34b99a2b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 66/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed74f2f2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 67/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/506d28a5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 68/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/22a4bbc2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 69/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d19f7514.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 70/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00dbd492.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 71/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7dd8335.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 72/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c8b7cc0f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 73/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/332efdb3.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 74/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3b4c2228.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 75/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/626c0bcc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 76/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9110e3c5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 77/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6f473927.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 78/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c9aba6e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 79/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5d2a5c43.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 80/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12eac192.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 81/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66f2d22f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 82/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ad5bdfd.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 83/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9bebae7a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 84/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/90347967.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 85/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d2acf2cb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 86/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2697da3f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 87/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d931c21c.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 88/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50a16a69.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 89/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1c0d0a4b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 90/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/195ba7dc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 91/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3d31c5b3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 92/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62ab2642.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 93/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6a11f6da.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 94/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/281123b4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 95/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ef26cbf6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 96/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/42a15761.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 97/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b4a43f3b.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 98/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ae58858e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 99/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e69241bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 100/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/85fa5666.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 100 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\n",
      "\n",
      "🚀 Running inference 101/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8597cfd7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 102/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4852f2fa.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 103/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55783887.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 104/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72207abc.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 105/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d37a1ef5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 106/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/af24b4cc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 107/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c87289bb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 108/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1a2e2828.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 109/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8fbca751.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 110/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5207a7b5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 111/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0722778.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 112/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0a2355a6.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 113/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0f4d537.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 114/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e99362f0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 115/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c35c1b4c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 116/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f45f5ca7.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 117/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/64a7c07e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 118/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac3e2b04.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 119/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c7d4e6ad.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 120/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/84db8fc4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 121/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce039d91.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 122/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/99306f82.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 123/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2685904e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 124/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4acc7107.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 125/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4e469f39.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 126/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bf32578f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 127/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa300dc3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 128/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/137f0df0.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 129/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/03560426.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 130/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/69889d6e.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 131/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e9ac8c9e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 132/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cfb2ce5a.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 133/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/da2b0fe3.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 134/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6df30ad6.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the 200 filtered JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "# ✅ Resume from Datapoint 32\n",
    "num_samples = 200\n",
    "start_from = 0\n",
    "test_files = filtered_files[start_from:num_samples]  # ✅ Skip first 31 files\n",
    "\n",
    "# ✅ Define model & assigned GPUs\n",
    "model_name = \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\"\n",
    "device_map = \"auto\"  # ✅ Auto-distributes across both GPUs\n",
    "\n",
    "# ✅ Function to load ground truth matrix\n",
    "def load_ground_truth_matrix(json_file):\n",
    "    file_path = os.path.join(dataset_folder, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None\n",
    "\n",
    "    return test_examples[0][\"output\"]\n",
    "\n",
    "# ✅ Function to compare matrices\n",
    "def compare_matrices(predicted_matrix, ground_truth):\n",
    "    if predicted_matrix is None:\n",
    "        return \"⚠️ Invalid Output\"\n",
    "\n",
    "    try:\n",
    "        predicted_np = np.array(eval(predicted_matrix), dtype=int)\n",
    "        ground_truth_np = np.array(ground_truth, dtype=int)\n",
    "\n",
    "        if np.array_equal(predicted_np, ground_truth_np):\n",
    "            return \"✅ Correct\"\n",
    "        else:\n",
    "            return \"❌ Incorrect\"\n",
    "    except Exception as e:\n",
    "        return \"⚠️ Error in matrix comparison: \" + str(e)\n",
    "\n",
    "# ✅ Function to run inference for remaining examples across both GPUs\n",
    "def run_inference_on_both_gpus(model_name):\n",
    "    print(f\"\\n🚀 Running Model: {model_name} across both GPUs for {num_samples - start_from} remaining datapoints\")\n",
    "\n",
    "    # ✅ Load Model across both GPUs\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"  # ✅ Distributes model across GPUs\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {start_from + idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")  # ✅ Auto-assigns to available GPU\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with safe parameters\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Compare extracted matrix with ground truth\n",
    "        result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "        # ✅ Store the result\n",
    "        results.append({\n",
    "            \"file\": file,\n",
    "            \"extracted_matrix\": extracted_matrix,\n",
    "            \"ground_truth\": ground_truth_matrix,\n",
    "            \"comparison_result\": result\n",
    "        })\n",
    "\n",
    "        print(f\"\\n📊 **Comparison Result:** {result}\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "        # ✅ Save every 50 datapoints to prevent progress loss\n",
    "        if (start_from + idx + 1) % 50 == 0:\n",
    "            save_path = f\"./{model_name.replace('/', '_')}_results_batch_{start_from + idx + 1}.json\"\n",
    "            with open(save_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            print(f\"\\n💾 Saved batch {start_from + idx + 1} results for {model_name}\")\n",
    "\n",
    "            # ✅ Clear memory\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n✅ Completed inference for {model_name} across both GPUs!\")\n",
    "\n",
    "# ✅ Run inference for remaining 168 datapoints using both GPUs\n",
    "print(\"\\n🚀 Running Model across GPUs for remaining 168 Examples...\\n\")\n",
    "run_inference_on_both_gpus(model_name)\n",
    "\n",
    "print(\"\\n✅ **Completed inference for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c9e6bd8-442d-4446-b7f0-11e7e2e387e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running Model across GPUs for remaining 168 Examples...\n",
      "\n",
      "\n",
      "🚀 Running Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings across both GPUs for 68 remaining datapoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 17:18:29.903067: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-10 17:18:30.667636: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-10 17:18:30.667671: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-10 17:18:30.667701: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-10 17:18:31.098305: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-10 17:18:50.138994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09e60a9cd954fdd82cc42ed600441a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 133/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/da2b0fe3.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 134/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6df30ad6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 135/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3cdc58f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 136/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/58743b76.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 137/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a406ac07.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 138/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/94414823.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 139/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/575b1a71.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 140/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3e62deb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 141/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ea9794b1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 142/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31adaf00.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 143/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c1e755f.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 144/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac605cbb.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 145/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7c8af763.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 146/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7ee1c6ea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 147/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b942fd60.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 148/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/782b5218.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 149/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0becf7df.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 150/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/136b0064.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 150 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\n",
      "\n",
      "🚀 Running inference 151/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dd2401ed.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 152/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50aad11f.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 153/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2b01abd0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 154/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/292dd178.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 155/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce8d95cc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 156/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/423a55dc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 157/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/817e6c09.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 158/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/11e1fe23.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 159/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2c737e39.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 160/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ff72ca3e.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 161/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/93b4f4b3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 162/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fe9372f3.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 163/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ecaa0ec1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 164/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cd3c21df.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 165/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/08573cc6.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 166/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/963f59bc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 167/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dc2aa30b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 168/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9ddd00f0.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 169/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5c44e8f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 170/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b7cb93ac.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 171/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f5aa3634.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 172/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72a961c9.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 173/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/45737921.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 174/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5ffb2104.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 175/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/516b51b7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 176/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/baf41dbf.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 177/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55059096.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 178/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/762cd429.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 179/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e78887d1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 180/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ee62060.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 181/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e872b94a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 182/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/705a3229.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 183/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1acc24af.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 184/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/917bccba.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 185/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7e02026e.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 186/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73182012.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 187/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9f27f097.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 188/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60a26a3e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 189/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3391f8c0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 190/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/505fff84.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (9,) + inhomogeneous part.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 191/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12997ef3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 192/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/642248e4.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 193/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/896d5239.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 194/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0bb8deee.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 195/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/992798f6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 196/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/712bf12e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 197/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9b365c51.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 198/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5af49b42.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 199/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c658a4bd.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 200/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/84f2aca1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 200 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\n",
      "\n",
      "✅ Completed inference for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings across both GPUs!\n",
      "\n",
      "✅ **Completed inference for all 200 examples!** 🚀\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the 200 filtered JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "# ✅ Resume from Datapoint 32\n",
    "num_samples = 200\n",
    "start_from = 132\n",
    "test_files = filtered_files[start_from:num_samples]  # ✅ Skip first 31 files\n",
    "\n",
    "# ✅ Define model & assigned GPUs\n",
    "model_name = \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\"\n",
    "device_map = \"auto\"  # ✅ Auto-distributes across both GPUs\n",
    "\n",
    "# ✅ Function to load ground truth matrix\n",
    "def load_ground_truth_matrix(json_file):\n",
    "    file_path = os.path.join(dataset_folder, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None\n",
    "\n",
    "    return test_examples[0][\"output\"]\n",
    "\n",
    "# ✅ Function to compare matrices\n",
    "def compare_matrices(predicted_matrix, ground_truth):\n",
    "    if predicted_matrix is None:\n",
    "        return \"⚠️ Invalid Output\"\n",
    "\n",
    "    try:\n",
    "        predicted_np = np.array(eval(predicted_matrix), dtype=int)\n",
    "        ground_truth_np = np.array(ground_truth, dtype=int)\n",
    "\n",
    "        if np.array_equal(predicted_np, ground_truth_np):\n",
    "            return \"✅ Correct\"\n",
    "        else:\n",
    "            return \"❌ Incorrect\"\n",
    "    except Exception as e:\n",
    "        return \"⚠️ Error in matrix comparison: \" + str(e)\n",
    "\n",
    "# ✅ Function to run inference for remaining examples across both GPUs\n",
    "def run_inference_on_both_gpus(model_name):\n",
    "    print(f\"\\n🚀 Running Model: {model_name} across both GPUs for {num_samples - start_from} remaining datapoints\")\n",
    "\n",
    "    # ✅ Load Model across both GPUs\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"  # ✅ Distributes model across GPUs\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {start_from + idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")  # ✅ Auto-assigns to available GPU\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with safe parameters\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Compare extracted matrix with ground truth\n",
    "        result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "        # ✅ Store the result\n",
    "        results.append({\n",
    "            \"file\": file,\n",
    "            \"extracted_matrix\": extracted_matrix,\n",
    "            \"ground_truth\": ground_truth_matrix,\n",
    "            \"comparison_result\": result\n",
    "        })\n",
    "\n",
    "        print(f\"\\n📊 **Comparison Result:** {result}\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "        # ✅ Save every 50 datapoints to prevent progress loss\n",
    "        if (start_from + idx + 1) % 50 == 0:\n",
    "            save_path = f\"./{model_name.replace('/', '_')}_results_batch_{start_from + idx + 1}.json\"\n",
    "            with open(save_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            print(f\"\\n💾 Saved batch {start_from + idx + 1} results for {model_name}\")\n",
    "\n",
    "            # ✅ Clear memory\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n✅ Completed inference for {model_name} across both GPUs!\")\n",
    "\n",
    "# ✅ Run inference for remaining 168 datapoints using both GPUs\n",
    "print(\"\\n🚀 Running Model across GPUs for remaining 168 Examples...\\n\")\n",
    "run_inference_on_both_gpus(model_name)\n",
    "\n",
    "print(\"\\n✅ **Completed inference for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "294c0d3b-6f82-4120-bc01-7c1d72bd4387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running Model across GPUs for remaining 168 Examples...\n",
      "\n",
      "\n",
      "🚀 Running Model: phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01 across both GPUs for 200 remaining datapoints\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad90a46a48634a48accc10274102455c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (14,) + inhomogeneous part.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 2/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 3/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 4/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 5/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 6/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8e2edd66.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 7/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ad7e01d0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 8/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fc754716.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 9/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27f8ce4f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 10/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/59341089.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 11/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/833dafe3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 12/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed98d772.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 13/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d4b1c2b1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 14/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48131b3c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 15/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0692e18c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 16/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8b28cd80.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 17/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/32e9702f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 18/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8719f442.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 19/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2072aba6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 20/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ea4a07e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 21/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48f8583b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 22/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/695367ec.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 23/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/15696249.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 24/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c92b942c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 25/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27a77e38.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 26/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60c09cac.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 27/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ccd554ac.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 28/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c786b71.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 29/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c1990cce.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 30/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7953d61e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 31/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66e6c45b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 32/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5b6cbef5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 33/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bc4146bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 34/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4cd1b7b2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 35/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e133d23d.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 36/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e6de6e8f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 37/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/be03b35f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 38/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12422b43.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 39/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b15fca0b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 40/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ca8de6ea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 41/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7b06bea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 42/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f0afb749.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 43/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3979b1a8.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 44/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d017b73f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 45/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/17cae0c1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 46/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62b74c02.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 47/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31d5ba1a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 48/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e345f17b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 49/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa18de87.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 50/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73c3b0d8.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 50 results for phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01\n",
      "\n",
      "🚀 Running inference 51/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c074846d.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 52/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cad67732.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 53/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fb791726.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 54/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ba14f53.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 55/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5790162.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 56/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bbb1b8b6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 57/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2a5f8217.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 58/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5783df64.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 59/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b1fc8b8e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 60/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a8610ef7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 61/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/770cc55f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 62/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/68b67ca3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 63/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/67c52801.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 64/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c56f360.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 65/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/34b99a2b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 66/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed74f2f2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 67/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/506d28a5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 68/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/22a4bbc2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 69/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d19f7514.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 70/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00dbd492.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 71/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7dd8335.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 72/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c8b7cc0f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 73/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/332efdb3.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 74/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3b4c2228.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 75/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/626c0bcc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 76/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9110e3c5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 77/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6f473927.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 78/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c9aba6e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 79/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5d2a5c43.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 80/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12eac192.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 81/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66f2d22f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 82/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ad5bdfd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 83/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9bebae7a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 84/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/90347967.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 85/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d2acf2cb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 86/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2697da3f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 87/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d931c21c.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10,) + inhomogeneous part.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 88/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50a16a69.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 89/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1c0d0a4b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 90/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/195ba7dc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 91/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3d31c5b3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 92/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62ab2642.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 93/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6a11f6da.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 94/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/281123b4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 95/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ef26cbf6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 96/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/42a15761.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 97/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b4a43f3b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 98/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ae58858e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 99/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e69241bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 100/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/85fa5666.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 100 results for phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01\n",
      "\n",
      "🚀 Running inference 101/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8597cfd7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 102/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4852f2fa.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 103/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55783887.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 104/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72207abc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 105/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d37a1ef5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 106/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/af24b4cc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 107/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c87289bb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 108/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1a2e2828.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 109/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8fbca751.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 110/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5207a7b5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 111/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0722778.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 112/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0a2355a6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 113/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0f4d537.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 114/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e99362f0.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 115/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c35c1b4c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 116/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f45f5ca7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 117/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/64a7c07e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 118/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac3e2b04.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 119/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c7d4e6ad.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 120/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/84db8fc4.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 121/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce039d91.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 122/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/99306f82.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 123/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2685904e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 124/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4acc7107.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 125/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4e469f39.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 126/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bf32578f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 127/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa300dc3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 128/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/137f0df0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 129/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/03560426.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 130/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/69889d6e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 131/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e9ac8c9e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 132/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cfb2ce5a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 133/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/da2b0fe3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 134/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6df30ad6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 135/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3cdc58f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 136/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/58743b76.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 137/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a406ac07.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 138/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/94414823.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 139/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/575b1a71.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 140/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3e62deb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 141/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ea9794b1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 142/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31adaf00.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 143/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c1e755f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 144/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac605cbb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 145/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7c8af763.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 146/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7ee1c6ea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 147/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b942fd60.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 148/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/782b5218.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 149/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0becf7df.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 150/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/136b0064.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 150 results for phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01\n",
      "\n",
      "🚀 Running inference 151/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dd2401ed.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 152/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50aad11f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 153/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2b01abd0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 154/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/292dd178.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 155/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce8d95cc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 156/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/423a55dc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 157/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/817e6c09.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 158/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/11e1fe23.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 159/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2c737e39.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 160/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ff72ca3e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 161/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/93b4f4b3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 162/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fe9372f3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 163/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ecaa0ec1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 164/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cd3c21df.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 165/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/08573cc6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 166/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/963f59bc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 167/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dc2aa30b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 168/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9ddd00f0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 169/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5c44e8f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 170/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b7cb93ac.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 171/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f5aa3634.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 172/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72a961c9.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 173/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/45737921.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 174/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5ffb2104.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 175/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/516b51b7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 176/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/baf41dbf.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 177/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55059096.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 178/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/762cd429.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 179/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e78887d1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 180/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ee62060.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 181/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e872b94a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 182/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/705a3229.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 183/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1acc24af.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 184/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/917bccba.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 185/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7e02026e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 186/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73182012.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 187/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9f27f097.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 188/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60a26a3e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 189/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3391f8c0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 190/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/505fff84.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 191/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12997ef3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 192/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/642248e4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 193/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/896d5239.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 194/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0bb8deee.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 195/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/992798f6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 196/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/712bf12e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 197/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9b365c51.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 198/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5af49b42.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 199/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c658a4bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 200/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/84f2aca1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 200 results for phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01\n",
      "\n",
      "✅ Completed inference for phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01 across both GPUs!\n",
      "\n",
      "✅ **Completed inference for all 200 examples!** 🚀\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the 200 filtered JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "# ✅ Resume from Datapoint 32\n",
    "num_samples = 200\n",
    "start_from = 0\n",
    "test_files = filtered_files[start_from:num_samples]  # ✅ Skip first 31 files\n",
    "\n",
    "# ✅ Define model & assigned GPUs\n",
    "model_name = \"phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01\"\n",
    "device_map = \"auto\"  # ✅ Auto-distributes across both GPUs\n",
    "\n",
    "# ✅ Function to load ground truth matrix\n",
    "def load_ground_truth_matrix(json_file):\n",
    "    file_path = os.path.join(dataset_folder, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None\n",
    "\n",
    "    return test_examples[0][\"output\"]\n",
    "\n",
    "# ✅ Function to compare matrices\n",
    "def compare_matrices(predicted_matrix, ground_truth):\n",
    "    if predicted_matrix is None:\n",
    "        return \"⚠️ Invalid Output\"\n",
    "\n",
    "    try:\n",
    "        predicted_np = np.array(eval(predicted_matrix), dtype=int)\n",
    "        ground_truth_np = np.array(ground_truth, dtype=int)\n",
    "\n",
    "        if np.array_equal(predicted_np, ground_truth_np):\n",
    "            return \"✅ Correct\"\n",
    "        else:\n",
    "            return \"❌ Incorrect\"\n",
    "    except Exception as e:\n",
    "        return \"⚠️ Error in matrix comparison: \" + str(e)\n",
    "\n",
    "# ✅ Function to run inference for remaining examples across both GPUs\n",
    "def run_inference_on_both_gpus(model_name):\n",
    "    print(f\"\\n🚀 Running Model: {model_name} across both GPUs for {num_samples - start_from} remaining datapoints\")\n",
    "\n",
    "    # ✅ Load Model across both GPUs\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"  # ✅ Distributes model across GPUs\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {start_from + idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")  # ✅ Auto-assigns to available GPU\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with safe parameters\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Compare extracted matrix with ground truth\n",
    "        result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "        # ✅ Store the result\n",
    "        results.append({\n",
    "            \"file\": file,\n",
    "            \"extracted_matrix\": extracted_matrix,\n",
    "            \"ground_truth\": ground_truth_matrix,\n",
    "            \"comparison_result\": result\n",
    "        })\n",
    "\n",
    "        print(f\"\\n📊 **Comparison Result:** {result}\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "        # ✅ Save every 50 datapoints to prevent progress loss\n",
    "        if (start_from + idx + 1) % 50 == 0:\n",
    "            save_path = f\"./{model_name.replace('/', '_')}_results_batch_{start_from + idx + 1}.json\"\n",
    "            with open(save_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            print(f\"\\n💾 Saved batch {start_from + idx + 1} results for {model_name}\")\n",
    "\n",
    "            # ✅ Clear memory\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n✅ Completed inference for {model_name} across both GPUs!\")\n",
    "\n",
    "# ✅ Run inference for remaining 168 datapoints using both GPUs\n",
    "print(\"\\n🚀 Running Model across GPUs for remaining 168 Examples...\\n\")\n",
    "run_inference_on_both_gpus(model_name)\n",
    "\n",
    "print(\"\\n✅ **Completed inference for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83fbd0-beee-4514-b0f3-155ab1c71462",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running Model across GPUs for remaining 168 Examples...\n",
      "\n",
      "\n",
      "🚀 Running Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings across both GPUs for 200 remaining datapoints\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d24f3b475e4fea9ad9b28faaf862a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 2/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 3/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 4/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 5/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 6/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8e2edd66.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 7/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ad7e01d0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 8/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fc754716.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 9/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27f8ce4f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 10/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/59341089.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 11/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/833dafe3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 12/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed98d772.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 13/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d4b1c2b1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 14/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48131b3c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 15/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0692e18c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 16/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8b28cd80.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 17/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/32e9702f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 18/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8719f442.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 19/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2072aba6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 20/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ea4a07e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 21/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48f8583b.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 22/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/695367ec.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 23/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/15696249.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 24/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c92b942c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 25/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27a77e38.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 26/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60c09cac.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 27/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ccd554ac.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 28/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c786b71.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 29/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c1990cce.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 30/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7953d61e.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the 200 filtered JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "# ✅ Resume from Datapoint 32\n",
    "num_samples = 200\n",
    "start_from = 0\n",
    "test_files = filtered_files[start_from:num_samples]  # ✅ Skip first 31 files\n",
    "\n",
    "# ✅ Define model & assigned GPUs\n",
    "model_name = \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings\"\n",
    "device_map = \"auto\"  # ✅ Auto-distributes across both GPUs\n",
    "\n",
    "# ✅ Function to load ground truth matrix\n",
    "def load_ground_truth_matrix(json_file):\n",
    "    file_path = os.path.join(dataset_folder, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None\n",
    "\n",
    "    return test_examples[0][\"output\"]\n",
    "\n",
    "# ✅ Function to compare matrices\n",
    "def compare_matrices(predicted_matrix, ground_truth):\n",
    "    if predicted_matrix is None:\n",
    "        return \"⚠️ Invalid Output\"\n",
    "\n",
    "    try:\n",
    "        predicted_np = np.array(eval(predicted_matrix), dtype=int)\n",
    "        ground_truth_np = np.array(ground_truth, dtype=int)\n",
    "\n",
    "        if np.array_equal(predicted_np, ground_truth_np):\n",
    "            return \"✅ Correct\"\n",
    "        else:\n",
    "            return \"❌ Incorrect\"\n",
    "    except Exception as e:\n",
    "        return \"⚠️ Error in matrix comparison: \" + str(e)\n",
    "\n",
    "# ✅ Function to run inference for remaining examples across both GPUs\n",
    "def run_inference_on_both_gpus(model_name):\n",
    "    print(f\"\\n🚀 Running Model: {model_name} across both GPUs for {num_samples - start_from} remaining datapoints\")\n",
    "\n",
    "    # ✅ Load Model across both GPUs\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"  # ✅ Distributes model across GPUs\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {start_from + idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")  # ✅ Auto-assigns to available GPU\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with safe parameters\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Compare extracted matrix with ground truth\n",
    "        result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "        # ✅ Store the result\n",
    "        results.append({\n",
    "            \"file\": file,\n",
    "            \"extracted_matrix\": extracted_matrix,\n",
    "            \"ground_truth\": ground_truth_matrix,\n",
    "            \"comparison_result\": result\n",
    "        })\n",
    "\n",
    "        print(f\"\\n📊 **Comparison Result:** {result}\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "        # ✅ Save every 50 datapoints to prevent progress loss\n",
    "        if (start_from + idx + 1) % 50 == 0:\n",
    "            save_path = f\"./{model_name.replace('/', '_')}_results_batch_{start_from + idx + 1}.json\"\n",
    "            with open(save_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            print(f\"\\n💾 Saved batch {start_from + idx + 1} results for {model_name}\")\n",
    "\n",
    "            # ✅ Clear memory\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n✅ Completed inference for {model_name} across both GPUs!\")\n",
    "\n",
    "# ✅ Run inference for remaining 168 datapoints using both GPUs\n",
    "print(\"\\n🚀 Running Model across GPUs for remaining 168 Examples...\\n\")\n",
    "run_inference_on_both_gpus(model_name)\n",
    "\n",
    "print(\"\\n✅ **Completed inference for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a49cc1ee-45fe-4dbd-b9c9-3f6966aa56a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running Model across GPUs for remaining 168 Examples...\n",
      "\n",
      "\n",
      "🚀 Running Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings across both GPUs for 171 remaining datapoints\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb69b1d594194183b5a46887c091b216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 30/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7953d61e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 31/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66e6c45b.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 32/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5b6cbef5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 33/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bc4146bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 34/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4cd1b7b2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 35/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e133d23d.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 36/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e6de6e8f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 37/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/be03b35f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 38/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12422b43.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 39/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b15fca0b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 40/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ca8de6ea.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 41/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7b06bea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 42/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f0afb749.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 43/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3979b1a8.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 44/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d017b73f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 45/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/17cae0c1.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 46/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62b74c02.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 47/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31d5ba1a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 48/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e345f17b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 49/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa18de87.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 50/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73c3b0d8.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 50 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings\n",
      "\n",
      "🚀 Running inference 51/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c074846d.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 52/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cad67732.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 53/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fb791726.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 54/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ba14f53.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 55/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5790162.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 56/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bbb1b8b6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 57/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2a5f8217.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 58/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5783df64.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 59/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b1fc8b8e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 60/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a8610ef7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 61/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/770cc55f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 62/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/68b67ca3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 63/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/67c52801.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 64/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c56f360.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 65/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/34b99a2b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 66/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed74f2f2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 67/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/506d28a5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 68/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/22a4bbc2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 69/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d19f7514.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 70/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00dbd492.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 71/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7dd8335.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 72/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c8b7cc0f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 73/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/332efdb3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 74/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3b4c2228.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 75/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/626c0bcc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 76/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9110e3c5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 77/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6f473927.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 78/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c9aba6e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 79/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5d2a5c43.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 80/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12eac192.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 81/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66f2d22f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 82/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ad5bdfd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 83/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9bebae7a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 84/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/90347967.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 85/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d2acf2cb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 86/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2697da3f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 87/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d931c21c.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 88/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50a16a69.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 89/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1c0d0a4b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 90/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/195ba7dc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 91/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3d31c5b3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 92/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62ab2642.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 93/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6a11f6da.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 94/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/281123b4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 95/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ef26cbf6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 96/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/42a15761.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 97/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b4a43f3b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 98/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ae58858e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 99/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e69241bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 100/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/85fa5666.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 100 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings\n",
      "\n",
      "🚀 Running inference 101/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8597cfd7.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 102/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4852f2fa.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 103/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55783887.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 104/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72207abc.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 105/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d37a1ef5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 106/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/af24b4cc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 107/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c87289bb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 108/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1a2e2828.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 109/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8fbca751.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 110/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5207a7b5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 111/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0722778.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 112/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0a2355a6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 113/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0f4d537.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 114/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e99362f0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 115/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c35c1b4c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 116/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f45f5ca7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 117/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/64a7c07e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 118/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac3e2b04.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 119/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c7d4e6ad.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ Correct\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 120/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/84db8fc4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 121/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce039d91.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 122/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/99306f82.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (16,) + inhomogeneous part.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 123/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2685904e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 124/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4acc7107.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 125/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4e469f39.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 126/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bf32578f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 127/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa300dc3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 128/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/137f0df0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 129/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/03560426.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 130/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/69889d6e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 131/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e9ac8c9e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 132/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cfb2ce5a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 133/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/da2b0fe3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 134/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6df30ad6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 135/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3cdc58f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 136/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/58743b76.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 137/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a406ac07.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 138/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/94414823.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 139/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/575b1a71.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 140/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3e62deb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 141/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ea9794b1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 142/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31adaf00.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 143/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c1e755f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 144/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac605cbb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 145/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7c8af763.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 146/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7ee1c6ea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 147/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b942fd60.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 148/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/782b5218.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 149/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0becf7df.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 150/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/136b0064.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 150 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings\n",
      "\n",
      "🚀 Running inference 151/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dd2401ed.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 152/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50aad11f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 153/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2b01abd0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 154/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/292dd178.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 155/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce8d95cc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 156/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/423a55dc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 157/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/817e6c09.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 158/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/11e1fe23.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 159/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2c737e39.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 160/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ff72ca3e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 161/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/93b4f4b3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 162/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fe9372f3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 163/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ecaa0ec1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 164/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cd3c21df.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 165/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/08573cc6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 166/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/963f59bc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 167/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dc2aa30b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 168/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9ddd00f0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 169/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5c44e8f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 170/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b7cb93ac.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 171/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f5aa3634.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 172/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72a961c9.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 173/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/45737921.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 174/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5ffb2104.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 175/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/516b51b7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 176/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/baf41dbf.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 177/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55059096.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 178/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/762cd429.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Invalid Output\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 179/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e78887d1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 180/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ee62060.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 181/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e872b94a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 182/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/705a3229.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 183/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1acc24af.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 184/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/917bccba.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 185/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7e02026e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 186/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73182012.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 187/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9f27f097.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 188/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60a26a3e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 189/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3391f8c0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 190/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/505fff84.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 191/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12997ef3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 192/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/642248e4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 193/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/896d5239.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 194/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0bb8deee.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 195/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/992798f6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 196/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/712bf12e.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 197/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9b365c51.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 198/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5af49b42.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 199/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c658a4bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 200/200 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/84f2aca1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Incorrect\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 Saved batch 200 results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings\n",
      "\n",
      "✅ Completed inference for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings across both GPUs!\n",
      "\n",
      "✅ **Completed inference for all 200 examples!** 🚀\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the 200 filtered JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "# ✅ Resume from Datapoint 32\n",
    "num_samples = 200\n",
    "start_from = 29\n",
    "test_files = filtered_files[start_from:num_samples]  # ✅ Skip first 31 files\n",
    "\n",
    "# ✅ Define model & assigned GPUs\n",
    "model_name = \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings\"\n",
    "device_map = \"auto\"  # ✅ Auto-distributes across both GPUs\n",
    "\n",
    "# ✅ Function to load ground truth matrix\n",
    "def load_ground_truth_matrix(json_file):\n",
    "    file_path = os.path.join(dataset_folder, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None\n",
    "\n",
    "    return test_examples[0][\"output\"]\n",
    "\n",
    "# ✅ Function to compare matrices\n",
    "def compare_matrices(predicted_matrix, ground_truth):\n",
    "    if predicted_matrix is None:\n",
    "        return \"⚠️ Invalid Output\"\n",
    "\n",
    "    try:\n",
    "        predicted_np = np.array(eval(predicted_matrix), dtype=int)\n",
    "        ground_truth_np = np.array(ground_truth, dtype=int)\n",
    "\n",
    "        if np.array_equal(predicted_np, ground_truth_np):\n",
    "            return \"✅ Correct\"\n",
    "        else:\n",
    "            return \"❌ Incorrect\"\n",
    "    except Exception as e:\n",
    "        return \"⚠️ Error in matrix comparison: \" + str(e)\n",
    "\n",
    "# ✅ Function to run inference for remaining examples across both GPUs\n",
    "def run_inference_on_both_gpus(model_name):\n",
    "    print(f\"\\n🚀 Running Model: {model_name} across both GPUs for {num_samples - start_from} remaining datapoints\")\n",
    "\n",
    "    # ✅ Load Model across both GPUs\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"  # ✅ Distributes model across GPUs\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {start_from + idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")  # ✅ Auto-assigns to available GPU\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with safe parameters\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                top_k=50,\n",
    "                top_p=0.9,\n",
    "                repetition_penalty=1.2,\n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Compare extracted matrix with ground truth\n",
    "        result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "        # ✅ Store the result\n",
    "        results.append({\n",
    "            \"file\": file,\n",
    "            \"extracted_matrix\": extracted_matrix,\n",
    "            \"ground_truth\": ground_truth_matrix,\n",
    "            \"comparison_result\": result\n",
    "        })\n",
    "\n",
    "        print(f\"\\n📊 **Comparison Result:** {result}\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "        # ✅ Save every 50 datapoints to prevent progress loss\n",
    "        if (start_from + idx + 1) % 50 == 0:\n",
    "            save_path = f\"./{model_name.replace('/', '_')}_results_batch_{start_from + idx + 1}.json\"\n",
    "            with open(save_path, \"w\") as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "            print(f\"\\n💾 Saved batch {start_from + idx + 1} results for {model_name}\")\n",
    "\n",
    "            # ✅ Clear memory\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    print(f\"\\n✅ Completed inference for {model_name} across both GPUs!\")\n",
    "\n",
    "# ✅ Run inference for remaining 168 datapoints using both GPUs\n",
    "print(\"\\n🚀 Running Model across GPUs for remaining 168 Examples...\\n\")\n",
    "run_inference_on_both_gpus(model_name)\n",
    "\n",
    "print(\"\\n✅ **Completed inference for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d1e937-6b52-4f6a-bf02-e6a0215e228d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 **Results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings**\n",
      "\n",
      "\n",
      "📊 **Overall Adjusted Accuracy for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings: 0.00%** (excluding invalid cases)\n",
      "📊 **Total Invalid Cases: 0 / 200**\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "🚀 **Results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings**\n",
      "\n",
      "\n",
      "📊 **Overall Adjusted Accuracy for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: 0.00%** (excluding invalid cases)\n",
      "📊 **Total Invalid Cases: 0 / 200**\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "🚀 **Results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings**\n",
      "\n",
      "\n",
      "📊 **Overall Adjusted Accuracy for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: 0.00%** (excluding invalid cases)\n",
      "📊 **Total Invalid Cases: 0 / 200**\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "🚀 **Results for phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.1**\n",
      "\n",
      "\n",
      "📊 **Overall Adjusted Accuracy for phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.1: 0.00%** (excluding invalid cases)\n",
      "📊 **Total Invalid Cases: 0 / 200**\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "🚀 **Results for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1**\n",
      "\n",
      "\n",
      "📊 **Overall Adjusted Accuracy for phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: 0.00%** (excluding invalid cases)\n",
      "📊 **Total Invalid Cases: 0 / 200**\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "🚀 **Results for phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01**\n",
      "\n",
      "\n",
      "📊 **Overall Adjusted Accuracy for phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: 0.00%** (excluding invalid cases)\n",
      "📊 **Total Invalid Cases: 0 / 200**\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ace_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# ✅ Convert to DataFrame for Display\u001b[39;00m\n\u001b[1;32m     64\u001b[0m summary_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(summary_data, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdjusted Accuracy (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Cases\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mace_tools\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\n\u001b[1;32m     66\u001b[0m tools\u001b[38;5;241m.\u001b[39mdisplay_dataframe_to_user(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Performance Summary\u001b[39m\u001b[38;5;124m\"\u001b[39m, dataframe\u001b[38;5;241m=\u001b[39msummary_df)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ace_tools'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# ✅ Define the six models\n",
    "models = [\n",
    "    \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings\",\n",
    "    \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\",\n",
    "    \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings\",\n",
    "    \"phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.1\",\n",
    "    \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\",\n",
    "    \"phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01\"\n",
    "]\n",
    "\n",
    "# ✅ Initialize results dictionary\n",
    "all_model_results = {}\n",
    "\n",
    "# ✅ Load results for each model\n",
    "for model in models:\n",
    "    model_key = model.replace(\"/\", \"_\")  # Replace slashes to match saved file names\n",
    "    result_files = sorted(glob.glob(f\"./{model_key}_results_batch_*.json\"))  # Get all saved batches\n",
    "    \n",
    "    model_results = []\n",
    "    \n",
    "    for file in result_files:\n",
    "        with open(file, \"r\") as f:\n",
    "            batch_results = json.load(f)\n",
    "            model_results.extend(batch_results)  # Append batch results\n",
    "    \n",
    "    # ✅ Store model results\n",
    "    all_model_results[model] = model_results\n",
    "\n",
    "# ✅ Display Results for Each Model\n",
    "for model, results in all_model_results.items():\n",
    "    print(f\"\\n🚀 **Results for {model}**\\n\")\n",
    "    \n",
    "    correct_count = 0\n",
    "    invalid_count = 0\n",
    "    total_count = len(results)\n",
    "\n",
    "    \n",
    "\n",
    "    # ✅ Compute Adjusted Accuracy\n",
    "    valid_cases = 200 - invalid_count  # Ignore invalid cases\n",
    "    accuracy = (correct_count / valid_cases) * 100 if valid_cases > 0 else 0\n",
    "\n",
    "    print(f\"\\n📊 **Overall Adjusted Accuracy for {model}: {accuracy:.2f}%** (excluding invalid cases)\")\n",
    "    print(f\"📊 **Total Invalid Cases: {invalid_count} / 200**\")\n",
    "    print(\"\\n\" + \"=\"*100 + \"\\n\")\n",
    "\n",
    "# ✅ Summary Table of Results\n",
    "summary_data = []\n",
    "for model, results in all_model_results.items():\n",
    "    correct_count = sum(1 for r in results if r[\"comparison_result\"] == \"✅ Correct\")\n",
    "    invalid_count = sum(1 for r in results if r[\"comparison_result\"] == \"⚠️ Invalid Output\")\n",
    "    valid_cases = 200 - invalid_count\n",
    "\n",
    "    accuracy = (correct_count / valid_cases) * 100 if valid_cases > 0 else 0\n",
    "\n",
    "    summary_data.append([model, accuracy, invalid_count])\n",
    "\n",
    "# ✅ Convert to DataFrame for Display\n",
    "summary_df = pd.DataFrame(summary_data, columns=[\"Model\", \"Adjusted Accuracy (%)\", \"Invalid Cases\"])\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Model Performance Summary\", dataframe=summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f08bf1-4721-4057-b589-965408c36839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c740b33-482d-4487-b23e-72a01d9d1e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4319cab-ef52-4d76-9d25-dd4d8c167e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries loaded and GPU management set up.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# ✅ Prevent Memory Fragmentation\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "# ✅ Function to Clear GPU Memory\n",
    "def clear_gpu_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    print(\"\\n✅ GPU memory cleared.\")\n",
    "\n",
    "print(\"✅ Libraries loaded and GPU management set up.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "546b5b9b-c224-477f-af45-e4fdfa7df62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Loaded 200 filtered JSON files for evaluation.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the filtered 200 shortest JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(filtered_files)} filtered JSON files for evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9029a74d-604a-4bee-9723-329b58692b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ GPU memory cleared.\n",
      "\n",
      "🚀 Loading new model: phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10abdccac1dd4a7ca3c5ef3bf25dfdfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f9f233669f4776bbf665deaaf3ee02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9483f8fc3c784e9db61c94c3da25a0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9967bf24aab6488586fefa86ed5a491e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:17:39.269337: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-09 02:17:39.999118: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-09 02:17:39.999156: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-09 02:17:39.999183: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-09 02:17:40.469879: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-09 02:18:05.322957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f9bd78ed3c412ab61b9b08cd956802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737e8da0bf31447abd045fb9da3d15e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9caf6ff7e0b4f15b5efa2084cd578a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cd1502cf2d405498304436340a6353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00ce43550fe49009da84c13fbe1deaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0c451a495a4dfebc2f684f5fdf8f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a03378aa1a14eb192d485ba2df22a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585d640117654bf28d16b4440653c473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Model successfully loaded across both GPUs.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Clear GPU Memory Before Loading Model\n",
    "clear_gpu_memory()\n",
    "\n",
    "# ✅ Define model name\n",
    "model_name = \"phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.1\"\n",
    "\n",
    "print(f\"\\n🚀 Loading new model: {model_name}\")\n",
    "\n",
    "# ✅ Set 4-bit quantization settings for efficient GPU usage\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  \n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# ✅ Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"balanced\"  # ✅ Distributes model across 2 GPUs automatically\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Model successfully loaded across both GPUs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22e95ec-3710-484d-ad7d-8af0314e1ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Function to construct prompt is ready.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Function to construct a well-formatted prompt from JSON files\n",
    "def construct_fixed_prompt(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # ✅ Extract training & test examples\n",
    "    training_examples = data.get(\"train\", [])\n",
    "    test_examples = data.get(\"test\", [])\n",
    "\n",
    "    if not test_examples or not training_examples:\n",
    "        return None  # Skip if missing data\n",
    "\n",
    "    test_input = test_examples[0][\"input\"]\n",
    "    \n",
    "    # ✅ Build an improved prompt that explicitly asks for only the output matrix\n",
    "    prompt = \"Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\\n\\n\"\n",
    "\n",
    "    for ex in training_examples:\n",
    "        prompt += f\"Input: {ex['input']}\\n\"\n",
    "        prompt += f\"Output: {ex['output']}\\n\\n\"\n",
    "\n",
    "    prompt += f\"Test Input Matrix:\\n{test_input}\\n\\n\"\n",
    "    prompt += \"**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "print(\"\\n✅ Function to construct prompt is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575505c6-d3ec-4cd1-ba61-cab9efa53ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Function to extract output matrix is ready.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ✅ Function to extract output matrix after instruction text\n",
    "def extract_final_matrix(generated_text):\n",
    "    instruction_text = \"Provide ONLY the final output matrix for the test input. Do NOT include any other text.\"\n",
    "    \n",
    "    # ✅ Find the position where the instruction appears\n",
    "    start_idx = generated_text.find(instruction_text)\n",
    "    if start_idx == -1:\n",
    "        return \"⚠️ Instruction text not found in output.\"\n",
    "\n",
    "    # ✅ Extract everything after the instruction\n",
    "    output_after_instruction = generated_text[start_idx + len(instruction_text):].strip()\n",
    "\n",
    "    # ✅ Use regex to find the first valid matrix\n",
    "    matrix_match = re.search(r\"\\[\\[.*\\]\\]\", output_after_instruction, re.DOTALL)\n",
    "    \n",
    "    if matrix_match:\n",
    "        return matrix_match.group(0)  # ✅ Return the matrix\n",
    "    else:\n",
    "        return \"⚠️ No valid matrix found in extracted output.\"\n",
    "\n",
    "print(\"\\n✅ Function to extract output matrix is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c728510-7e53-4e31-934c-c9faf5a50ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2], [4, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2], [4, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2], [4, 0, 0, 0, 4, 0, 0, 0, 4, 0, 0, 0]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 2 0 0 0 2 0 0 0 2 0 0]\n",
      " [0 0 4 0 0 0 4 0 0 0 4 0]\n",
      " [0 0 0 2 0 0 0 2 0 0 0 2]\n",
      " [4 0 0 0 4 0 0 0 4 0 0 0]\n",
      " [0 2 0 0 0 2 0 0 0 2 0 0]\n",
      " [0 0 4 0 0 0 4 0 0 0 4 0]\n",
      " [0 0 0 2 0 0 0 2 0 0 0 2]\n",
      " [4 0 0 0 4 0 0 0 4 0 0 0]\n",
      " [0 2 0 0 0 2 0 0 0 2 0 0]\n",
      " [0 0 4 0 0 0 4 0 0 0 4 0]\n",
      " [0 0 0 2 0 0 0 2 0 0 0 2]\n",
      " [4 0 0 0 4 0 0 0 4 0 0 0]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 2/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]) \n",
      "([[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]])\n",
      "([1, 0, 1, 0, 1, 0], [5, 1, 5, 1, 5, 1], [0, 1, 0, 1, 0, 1], [1, 5, 1, 5, 1, 5], [1, 0, 1, 0, 1, 0], [5, 1, 5, 1, 5, 1])\n",
      "([[6, 5], [3, 7]], [4, 3]) is not a correct solution but if you follow the pattern from first two inputs then it can be solved as follows\n",
      "([[6, 5, 6, 5, 6, 5], [3, 7, 3, 7, 3, 7], [5, 6, 5, 6, 5, 6], [7, 3, 7, 3, 7, 3], [6, 5, 6, 5, 6, 5], [3, 7, 3, 7, 3, 7]] \n",
      "([[6, 5, 6, 5, 6, 5], [3, 7, 3, 7, 3, 7], [5, 6, 5, 6, 5, 6], [7, 3, 7, 3, 7, 3], [6, 5, 6, 5, 6, 5], [3, 7, 3, 7, 3, 7]]) \n",
      "([[3, 2], [7, 8], [2, 3], [8, 7], [3, 2], [7, 8]]) \n",
      "([[3, 2], [7, 8], [2, 3], [8, 7], [3, 2], [7, 8]])\n",
      "([[6, 5], [3, 7], [5, 6], [7, 3], [6, 5], [3, 7]])\n",
      "([[6, 5], [3, 7], [5, 6], [7, 3], [6, 5], [3, 7]])\n",
      "([[6, 5], [3, 7], [5, 6], [7, 3], [6, 5], [3, 7]])\n",
      "([[6, 5], [3, 7], [5, 6], [7, 3], [6, 5], [3, 7]]) \n",
      "([[6, 5], [3, 7], [5, 6], [7, 3], [6, 5], [3, 7]]) \n",
      "([[6, 5], [3, 7], [5, 6], [7, 3], [6, 5], [3, 7]]) \n",
      "([[6, 5], [3, 7], [5, 6], [7, 3], [6, 5], [3, 7]]) \n",
      "([[6, 5], [3, 7], [5, 6], [7, 3], [6, 5], [3, 7]]) \n",
      "([[6, 5], [3, 7], [5, 6], [7, 3], [6, 5], [3, 7]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[3 2 3 2 3 2]\n",
      " [7 8 7 8 7 8]\n",
      " [2 3 2 3 2 3]\n",
      " [8 7 8 7 8 7]\n",
      " [3 2 3 2 3 2]\n",
      " [7 8 7 8 7 8]]\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: unmatched ')' (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 3/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[9, 4, 1], [5, 4, 8], [5, 4, 8]]\n",
      "\n",
      "**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\n",
      "\n",
      "[Matrix]\n",
      "[9, 9, 4, 4, 1, 1, 5, 5, 4, 4, 8, 8, 5, 5, 4, 4, 8, 8]\n",
      "[9, 9, 4, 4, 1, 1, 5, 5, 4, 4, 8, 8, 5, 5, 4, 4, 8, 8]\n",
      "[5, 5, 4, 4, 8, 8, 1, 1, 4, 4, 8, 8, 5, 5, 4, 4, 8, 8]\n",
      "[5, 5, 4, 4, 8, 8, 1, 1, 4, 4, 8, 8, 5, 5, 4, 4, 8, 8]\n",
      "[5, 5, 4, 4, 8, 8, 1, 1, 4, 4, 8, 8, 5, 5, 4, 4, 8, 8]\n",
      "[/Matrix]\n",
      "\n",
      "\n",
      "Test Input Matrix:\n",
      "[[1, 2, 6], [8, 1, 4], [7, 4, 7]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[1 1 2 5 5]\n",
      " [1 1 2 5 5]\n",
      " [7 7 3 6 6]\n",
      " [7 7 6 5 5]\n",
      " [7 7 6 5 5]]\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 3)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 4/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[8, 3, 6, 6, 3, 8, 8, 3, 6, 6, 3, 8, 8, 3, 6], [8, 3, 6, 6, 3, 8, 8, 3, 6, 6, 3, 8, 8, 3, 6], [6, 8, 8, 8, 8, 6, 6, 8, 8, 8, 8, 6, 6, 8, 8]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[8 8 6 6 8 8 8 8 6]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [6 8 8 8 8 6 6 8 8]\n",
      " [6 8 8 8 8 6 6 8 8]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [8 8 6 6 8 8 8 8 6]\n",
      " [8 8 6 6 8 8 8 8 6]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [6 8 8 8 8 6 6 8 8]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (3, 15), Ground Truth: (9, 9)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 5/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "⚠️ No valid matrix found in extracted output.\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]\n",
      " [4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]\n",
      " [4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]\n",
      " [4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]]\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 6/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8e2edd66.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "⚠️ No valid matrix found in extracted output.\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 1]\n",
      " [1 0 1 0 0 0 1 0 1]\n",
      " [0 1 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]]\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 7/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ad7e01d0.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[1, 0, 5, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 5, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 0 0 0 0 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 5 0 5 0 5 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 5 0 1 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 1 0 5 0 1]\n",
      " [0 2 2 2 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 2 2 2 0]\n",
      " [5 0 5 0 5 0 0 0 0 0 5 0 5 0 5 0 0 0 0 0 5 0 5 0 5]\n",
      " [0 2 2 2 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 2 2 2 0]\n",
      " [1 0 5 0 1 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 1 0 5 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 5 0 5 0 5 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (13, 20), Ground Truth: (25, 25)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 8/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fc754716.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0]] \n",
      "[[0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0]]\n",
      "[[0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0]]\n",
      "[[0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0]]\n",
      "[[0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0]] \n",
      "[[0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0], [0, 0, 0, 4, 4, 4, 0]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[8 8 8 8 8 8 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 8 8 8 8 8 8]]\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 9/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27f8ce4f.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[9, 6, 7, 9, 6, 7, 0, 0, 0], [8, 7, 7, 8, 7, 7, 0, 0, 0], [2, 8, 7, 2, 8, 7, 0, 0, 0], [9, 6, 7, 0, 0, 0, 0, 0, 0], [8, 7, 7, 0, 0, 0, 0, 0, 0], [2, 8, 7, 0, 0, 0, 0, 0, 0], [0, 0, 0, 9, 6, 7, 0, 0, 0], [0, 0, 0, 8, 7, 7, 0, 0, 0], [0, 0, 0, 2, 8, 7, 0, 0, 0]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 0 0 0 0 0 9 6 7]\n",
      " [0 0 0 0 0 0 8 7 7]\n",
      " [0 0 0 0 0 0 2 8 7]\n",
      " [0 0 0 9 6 7 9 6 7]\n",
      " [0 0 0 8 7 7 8 7 7]\n",
      " [0 0 0 2 8 7 2 8 7]\n",
      " [0 0 0 0 0 0 9 6 7]\n",
      " [0 0 0 0 0 0 8 7 7]\n",
      " [0 0 0 0 0 0 2 8 7]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 10/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/59341089.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[8, 7, 8, 8, 7, 5, 5, 7, 5, 5, 7, 5]] \n",
      "[[5, 5, 8, 7, 7, 5, 5, 7, 5, 5, 7, 5]] \n",
      "[[8, 8, 5, 8, 8, 5, 5, 7, 5, 5, 7, 5]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[7 5 8 8 5 7 7 5 8 8 5 7]\n",
      " [5 7 5 5 7 5 5 7 5 5 7 5]\n",
      " [5 8 8 8 8 5 5 8 8 8 8 5]]\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "📊 **Summary of First 10 Examples:**\n",
      "✅ 0/10 matrices matched the ground truth.\n",
      "❌ 10/10 matrices did NOT match the ground truth.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Select the first 10 files from the filtered shortest files\n",
    "num_samples = 10  # Running on 10 examples first\n",
    "test_files = filtered_files[:num_samples]\n",
    "\n",
    "# ✅ Dictionary to store results\n",
    "comparison_results = {}\n",
    "\n",
    "# ✅ Function to load ground truth matrix from JSON\n",
    "def load_ground_truth_matrix(file):\n",
    "    file_path = os.path.join(dataset_folder, file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None  # No test data found\n",
    "\n",
    "    return test_examples[0].get(\"output\", None)  # Return the first test output matrix\n",
    "\n",
    "# ✅ Function to compare matrices element-wise\n",
    "def compare_matrices(extracted_matrix_text, ground_truth):\n",
    "    if ground_truth is None:\n",
    "        return \"⚠️ No ground truth matrix found in JSON.\"\n",
    "\n",
    "    try:\n",
    "        # ✅ Convert extracted matrix string to a Python list\n",
    "        extracted_matrix = eval(extracted_matrix_text)  # Convert string representation to list\n",
    "\n",
    "        # ✅ Convert to numpy arrays for comparison\n",
    "        extracted_np = np.array(extracted_matrix)\n",
    "        ground_truth_np = np.array(ground_truth)\n",
    "\n",
    "        # ✅ Check if matrices are the same\n",
    "        if extracted_np.shape != ground_truth_np.shape:\n",
    "            return f\"❌ Shape Mismatch! Extracted: {extracted_np.shape}, Ground Truth: {ground_truth_np.shape}\"\n",
    "\n",
    "        # ✅ Check element-wise equality\n",
    "        is_equal = np.array_equal(extracted_np, ground_truth_np)\n",
    "\n",
    "        if is_equal:\n",
    "            return \"✅ The extracted matrix matches the ground truth!\"\n",
    "        else:\n",
    "            return \"❌ The extracted matrix does NOT match the ground truth.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Error in matrix comparison: {e}\"\n",
    "\n",
    "# ✅ Run inference and comparison for each file\n",
    "for idx, file in enumerate(test_files):\n",
    "    print(f\"\\n🚀 Running inference {idx + 1}/{num_samples}: {file}\")\n",
    "\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(dataset_folder, file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1000,  \n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            repetition_penalty=1.2,  \n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Extract output matrix\n",
    "    extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "    # ✅ Load ground truth matrix\n",
    "    ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "    # ✅ Compare matrices\n",
    "    comparison_result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "    # ✅ Store results\n",
    "    comparison_results[file] = {\n",
    "        \"extracted_matrix\": extracted_matrix,\n",
    "        \"ground_truth\": ground_truth_matrix,\n",
    "        \"comparison\": comparison_result\n",
    "    }\n",
    "\n",
    "    # ✅ Print results for verification\n",
    "    print(\"\\n🔍 **Extracted Output Matrix:**\\n\")\n",
    "    print(extracted_matrix)\n",
    "    print(\"\\n🎯 **Ground Truth Matrix:**\\n\")\n",
    "    print(np.array(ground_truth_matrix) if ground_truth_matrix else \"⚠️ No ground truth available\")\n",
    "    print(\"\\n📊 **Comparison Result:**\", comparison_result)\n",
    "    print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ Summary of correct vs incorrect predictions\n",
    "num_correct = sum(1 for r in comparison_results.values() if \"matches\" in r[\"comparison\"])\n",
    "num_incorrect = num_samples - num_correct\n",
    "\n",
    "print(\"\\n📊 **Summary of First 10 Examples:**\")\n",
    "print(f\"✅ {num_correct}/{num_samples} matrices matched the ground truth.\")\n",
    "print(f\"❌ {num_incorrect}/{num_samples} matrices did NOT match the ground truth.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d4833cc-7048-43f6-8f9f-1a44b55874e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 1/200 - Invalid Output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 2/200 - Invalid Output\n",
      "❌ 3/200 - Incorrect\n",
      "⚠️ 4/200 - Invalid Output\n",
      "❌ 5/200 - Incorrect\n",
      "❌ 6/200 - Incorrect\n",
      "❌ 7/200 - Incorrect\n",
      "❌ 8/200 - Incorrect\n",
      "❌ 9/200 - Incorrect\n",
      "⚠️ 10/200 - Invalid Output\n",
      "⚠️ 11/200 - Invalid Output\n",
      "⚠️ 12/200 - Invalid Output\n",
      "⚠️ 13/200 - Invalid Output\n",
      "❌ 14/200 - Incorrect\n",
      "⚠️ 15/200 - Invalid Output\n",
      "⚠️ 16/200 - Invalid Output\n",
      "⚠️ 17/200 - Invalid Output\n",
      "⚠️ 18/200 - Invalid Output\n",
      "⚠️ 19/200 - Invalid Output\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# ✅ Run inference\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 34\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# ✅ Decode full output\u001b[39;00m\n\u001b[1;32m     45\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1190\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:945\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    933\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    934\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    935\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m         position_embeddings,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 945\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:691\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[1;32m    690\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 691\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_attention_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[1;32m    693\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:73\u001b[0m, in \u001b[0;36mLlamaRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     71\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     72\u001b[0m variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 73\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(\u001b[43mvariance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariance_epsilon\u001b[49m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ✅ Set batch save settings\n",
    "num_samples = 200\n",
    "batch_size = 50  # ✅ Save progress every 50 examples\n",
    "\n",
    "# ✅ Dictionary to store all results\n",
    "all_results = {}\n",
    "\n",
    "# ✅ Function to save results periodically\n",
    "def save_results(batch_index):\n",
    "    save_path = f\"./{model_name}_results_batch_{batch_index}.json\"\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "    print(f\"\\n💾 **Saved results for {batch_index} examples at:** {save_path}\")\n",
    "\n",
    "# ✅ Run inference and comparison for each file\n",
    "for idx, file in enumerate(filtered_files[:num_samples]):\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(dataset_folder, file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1000,  \n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            repetition_penalty=1.2,  \n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Extract output matrix\n",
    "    extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "    # ✅ Load ground truth matrix\n",
    "    ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "    # ✅ Compare matrices\n",
    "    comparison_result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "    # ✅ Store results\n",
    "    all_results[file] = {\n",
    "        \"model_name\": model_name,\n",
    "        \"extracted_matrix\": extracted_matrix,\n",
    "        \"ground_truth\": ground_truth_matrix,\n",
    "        \"comparison\": comparison_result\n",
    "    }\n",
    "\n",
    "    # ✅ Display live progress with symbols\n",
    "    if \"matches\" in comparison_result:\n",
    "        print(f\"✅ {idx + 1}/{num_samples} - Correct\")\n",
    "    elif \"❌\" in comparison_result:\n",
    "        print(f\"❌ {idx + 1}/{num_samples} - Incorrect\")\n",
    "    elif \"⚠️\" in comparison_result:\n",
    "        print(f\"⚠️ {idx + 1}/{num_samples} - Invalid Output\")\n",
    "\n",
    "    # ✅ Save results every 50 examples\n",
    "    if (idx + 1) % batch_size == 0:\n",
    "        save_results(idx + 1)\n",
    "\n",
    "# ✅ Final save for remaining results\n",
    "save_results(num_samples)\n",
    "print(\"\\n✅ **Completed inference & comparison for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c306a683-e95d-45c8-8265-4d6af645239e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference for: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "\n",
      "🚀 **Full Generated Output (Unfiltered):**\n",
      "\n",
      "<|begin_of_text|>Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\n",
      "\n",
      "Input: [[6, 5, 5], [5, 1, 7], [4, 5, 2]]\n",
      "Output: [[6, 6, 5, 5, 5], [6, 6, 5, 5, 5], [5, 5, 1, 7, 7], [4, 4, 5, 2, 2], [4, 4, 5, 2, 2]]\n",
      "\n",
      "Input: [[1, 3, 5], [1, 2, 8], [8, 3, 8]]\n",
      "Output: [[1, 1, 3, 5, 5], [1, 1, 3, 5, 5], [1, 1, 2, 8, 8], [8, 8, 3, 8, 8], [8, 8, 3, 8, 8]]\n",
      "\n",
      "Input: [[2, 3, 7], [2, 1, 6], [1, 5, 7]]\n",
      "Output: [[2, 2, 3, 7, 7], [2, 2, 3, 7, 7], [2, 2, 1, 6, 6], [1, 1, 5, 7, 7], [1, 1, 5, 7, 7]]\n",
      "\n",
      "Test Input Matrix:\n",
      "[[1, 2, 5], [7, 3, 6], [7, 6, 5]]\n",
      "\n",
      "**Provide ONLY the final output matrix for the test input. Do NOT include any other text.** \n",
      "[[1, 1, 2, 5, 5], [1, 1, 2, 5, 5], [7, 7, 3, 6, 6], [7, 7, 3, 6, 6]] \n",
      "[/column] [/column] [/row] [/table] [/column] [/columns] [/div] [/problem] [/exercise] [/problems]\n",
      "[/question] [/problem] [/exercise] [/probs] [/quizzes] [/quiz]\n",
      "[/dlizas] [/matrika] [/rusejoj] [/kalkuliuj] [/ekzerciyo] [/lernu] [/scipo] [/rezulto] [/konfirmi] [/rekomendo] [/farienco] [/premiis] [/klarigo] [/informoj] [/aŭtoro] [/teĥnikaj] [/kontakto] [/help] [/malfermo] [/plado] [/retroardorvoja] [/dungo] [/kunordigita] [/alinebla] [/delegito] [/subskribo] [/instala] [/serviso] [/abonanto] [/profesia] [/ebliga] [/esperanta] [/simpligilo] [/naviguo] /[trenu] [/vortaro] [/leksikono] [/lingva] [/interreta] [/historio] [/inventoro] [/edzo] [/donacisto] [/bienulo] [/cenzuracio] [/revizienda] [/difino] [/nomumo] [/praktiko] [/defendinda] [/regalo] [/promenajo] [/duko] [/diagramo] [/detalu] [/disputo] [/diluvo] [/distraha] [/dirige] [/direktora] [/disciplina] [/diserta] [/domanuja] [/digita] [/dimensio] [/dinamika] [/diffuzi] [/demografio] [/deduktiva] [/decidindama] [/debato] [/deklaraco] [/debita] [/delogeo] [/desegno] [/desertula] [/desciplina] [/derivo] [/derecha] [/dentista] [/denuncie] [/densa] [/dependa] [/demostracio] [/demandosistema] [/demando] [/delegitima] [/dejma] [/defektivisma] [/debilgaso] [/debliro] [/degustejo] [/delayso] [/dealokadoreco] [/debutanta] [/declara] [/decepa] [/deceptinta] [/decentema] [/decaza] [/deburta] [/debustro] [/debuto] [/debonaria] [/debiancia] [/debata] [/debuflavorgeno] [/debusta] [/db] [/dc] [/ds] [/dq] [/dt] [/da] [/dn] [/dm] [/do] [/dy] [/dz] [/dr] [/dp] [/dv] [/dw] [/dx] [/dy] [/ea] [/eb] [/ec] [/ed] [/ee] [/ef] [/eh] [/ei] [/ej] [/el] [/em] [/en] [/eo] [/ep] [/eq] [/er] [/es] [/et] [/eu] [/ev] [/ew] [/ex] [/ey] [/ez] [/fa] [/fb] [/fc] [/fd] [/fe] [/ff] [/fg] [/fh] [/fi] [/fj] [/fk] [/fl] [/fm] [/fn] [/fo] [/fp] [/fq] [/fr] [/fs] [/ft] [/fu] [/fv] [/fw] [/fx] [/fy] [/fz] [/ga] [/gb] [/gc] [/gd] [/ge] [/gf] [/gg] [/gh] [/gi] [/gj] [/gl] [/gm] [/gn] [/go] [/gp] [/gq] [/gr] [/gs] [/gt] [/gu] [/gv] [/gw] [/gx] [/gy] [/gz] [/ha] [/hb] [/hc] [/hd] [/he] [/hf] [/hg] [/hh] [/hi] [/hj] [/hk] [/hl] [/hm] [/hn] [/ho] [/hp] [/hq] [/hr] [/hs] [/ht] [/hu] [/hv] [/hw] [/hx] [/hy] [/hz\n"
     ]
    }
   ],
   "source": [
    "# ✅ Select one example to inspect\n",
    "test_file = filtered_files[2]  # Change index if you want a different file\n",
    "file_path = os.path.join(dataset_folder, test_file)\n",
    "\n",
    "print(f\"\\n🚀 Running inference for: {test_file}\")\n",
    "\n",
    "# ✅ Construct prompt\n",
    "test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "# ✅ Tokenize the prompt\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# ✅ Remove `token_type_ids` if present\n",
    "if \"token_type_ids\" in inputs:\n",
    "    inputs.pop(\"token_type_ids\")\n",
    "\n",
    "# ✅ Run inference with NO stopping conditions\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1000,  # ✅ Allow long generation without cutting off\n",
    "        do_sample=True,  \n",
    "        temperature=0.7,  \n",
    "        top_k=50,  \n",
    "        top_p=0.9,  \n",
    "        repetition_penalty=1.2,  # ✅ Reduces repetitive patterns\n",
    "    )\n",
    "\n",
    "# ✅ Decode full output\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "# ✅ Print entire model output exactly as generated\n",
    "print(\"\\n🚀 **Full Generated Output (Unfiltered):**\\n\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aa127f6-8c37-47b3-a186-8fca6d9870fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ **Updated matrix extraction function is ready!**\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ✅ Function to extract matrix after the instruction text and stop at `]]`\n",
    "def extract_final_matrix(generated_text):\n",
    "    instruction_text = \"Provide ONLY the final output matrix for the test input. Do NOT include any other text.\"\n",
    "    \n",
    "    # ✅ Find where the instruction appears\n",
    "    start_idx = generated_text.find(instruction_text)\n",
    "    if start_idx == -1:\n",
    "        return \"⚠️ Instruction text not found in output.\"\n",
    "\n",
    "    # ✅ Extract everything after the instruction\n",
    "    output_after_instruction = generated_text[start_idx + len(instruction_text):].strip()\n",
    "\n",
    "    # ✅ Find first matrix **only after instruction text**\n",
    "    matrix_match = re.search(r\"\\[\\[.*?\\]\\]\", output_after_instruction, re.DOTALL)\n",
    "    \n",
    "    if matrix_match:\n",
    "        return matrix_match.group(0)  # ✅ Return the extracted matrix\n",
    "    else:\n",
    "        return \"⚠️ No valid matrix found after instruction.\"\n",
    "\n",
    "print(\"\\n✅ **Updated matrix extraction function is ready!**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a32f96ef-ed9a-43f4-8836-dc29268fcf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/5: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "⚠️ No valid matrix found after instruction.\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 2 0 0 0 2 0 0 0 2 0 0]\n",
      " [0 0 4 0 0 0 4 0 0 0 4 0]\n",
      " [0 0 0 2 0 0 0 2 0 0 0 2]\n",
      " [4 0 0 0 4 0 0 0 4 0 0 0]\n",
      " [0 2 0 0 0 2 0 0 0 2 0 0]\n",
      " [0 0 4 0 0 0 4 0 0 0 4 0]\n",
      " [0 0 0 2 0 0 0 2 0 0 0 2]\n",
      " [4 0 0 0 4 0 0 0 4 0 0 0]\n",
      " [0 2 0 0 0 2 0 0 0 2 0 0]\n",
      " [0 0 4 0 0 0 4 0 0 0 4 0]\n",
      " [0 0 0 2 0 0 0 2 0 0 0 2]\n",
      " [4 0 0 0 4 0 0 0 4 0 0 0]]\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 2/5: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[3 2 3 2 3 2]\n",
      " [7 8 7 8 7 8]\n",
      " [2 3 2 3 2 3]\n",
      " [8 7 8 7 8 7]\n",
      " [3 2 3 2 3 2]\n",
      " [7 8 7 8 7 8]]\n",
      "\n",
      "📊 **Comparison Result:** ✅ The extracted matrix matches the ground truth!\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 3/5: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[1, 2, 5, 7, 7], [7, 7, 3, 6, 6], [7, 7, 6, 5, 5]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[1 1 2 5 5]\n",
      " [1 1 2 5 5]\n",
      " [7 7 3 6 6]\n",
      " [7 7 6 5 5]\n",
      " [7 7 6 5 5]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (3, 5), Ground Truth: (5, 5)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 4/5: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[8, 8, 6, 6, 3, 6, 6, 8, 8, 6, 6, 8, 8, 6, 6, 3, 6], [6, 3, 6, 6, 3, 6, 6, 3, 6, 6, 3, 6, 6, 3, 6, 6, 3, 6], [8, 8, 6, 6, 8, 8, 6, 6, 8, 8, 6, 6, 8, 8, 6, 6, 8, 8]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[8 8 6 6 8 8 8 8 6]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [6 8 8 8 8 6 6 8 8]\n",
      " [6 8 8 8 8 6 6 8 8]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [8 8 6 6 8 8 8 8 6]\n",
      " [8 8 6 6 8 8 8 8 6]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [6 8 8 8 8 6 6 8 8]]\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 5/5: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2], [2, 1, 4, 2, 1, 4, 2, 1, 4, 2, 1, 4, 2, 1, 4], [3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]\n",
      " [4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]\n",
      " [4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]\n",
      " [4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (3, 15), Ground Truth: (12, 12)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "📊 **Summary of First 5 Examples:**\n",
      "✅ 1/5 matrices matched the ground truth.\n",
      "❌ 4/5 matrices did NOT match the ground truth.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Select the first 5 files from the filtered dataset\n",
    "num_samples = 5  # Running on 5 examples first\n",
    "test_files = filtered_files[:num_samples]\n",
    "\n",
    "# ✅ Dictionary to store results\n",
    "comparison_results = {}\n",
    "\n",
    "# ✅ Run inference and comparison for each file\n",
    "for idx, file in enumerate(test_files):\n",
    "    print(f\"\\n🚀 Running inference {idx + 1}/{num_samples}: {file}\")\n",
    "\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(dataset_folder, file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1000,  \n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            repetition_penalty=1.2,  \n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Extract output matrix using updated method\n",
    "    extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "    # ✅ Load ground truth matrix\n",
    "    ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "    # ✅ Compare matrices\n",
    "    comparison_result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "    # ✅ Store results\n",
    "    comparison_results[file] = {\n",
    "        \"extracted_matrix\": extracted_matrix,\n",
    "        \"ground_truth\": ground_truth_matrix,\n",
    "        \"comparison\": comparison_result\n",
    "    }\n",
    "\n",
    "    # ✅ Print results for verification\n",
    "    print(\"\\n🔍 **Extracted Output Matrix:**\\n\")\n",
    "    print(extracted_matrix)\n",
    "    print(\"\\n🎯 **Ground Truth Matrix:**\\n\")\n",
    "    print(np.array(ground_truth_matrix) if ground_truth_matrix else \"⚠️ No ground truth available\")\n",
    "    print(\"\\n📊 **Comparison Result:**\", comparison_result)\n",
    "    print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ Summary of correct vs incorrect predictions\n",
    "num_correct = sum(1 for r in comparison_results.values() if \"matches\" in r[\"comparison\"])\n",
    "num_incorrect = num_samples - num_correct\n",
    "\n",
    "print(\"\\n📊 **Summary of First 5 Examples:**\")\n",
    "print(f\"✅ {num_correct}/{num_samples} matrices matched the ground truth.\")\n",
    "print(f\"❌ {num_incorrect}/{num_samples} matrices did NOT match the ground truth.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afcd4dfb-9c64-4458-8aef-d2267422ba67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "❌ 1/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 2/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "✅ 2/200 - Correct\n",
      "\n",
      "🚀 Running inference 3/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "❌ 3/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 4/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "⚠️ 4/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 5/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "❌ 5/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 6/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8e2edd66.json\n",
      "❌ 6/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 7/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ad7e01d0.json\n",
      "❌ 7/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 8/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fc754716.json\n",
      "❌ 8/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 9/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27f8ce4f.json\n",
      "⚠️ 9/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 10/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/59341089.json\n",
      "⚠️ 10/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 11/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/833dafe3.json\n",
      "⚠️ 11/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 12/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed98d772.json\n",
      "❌ 12/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 13/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d4b1c2b1.json\n",
      "❌ 13/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 14/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48131b3c.json\n",
      "❌ 14/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 15/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0692e18c.json\n",
      "⚠️ 15/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 16/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8b28cd80.json\n",
      "❌ 16/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 17/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/32e9702f.json\n",
      "⚠️ 17/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 18/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8719f442.json\n",
      "❌ 18/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 19/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2072aba6.json\n",
      "❌ 19/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 20/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ea4a07e.json\n",
      "✅ 20/200 - Correct\n",
      "\n",
      "🚀 Running inference 21/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48f8583b.json\n",
      "⚠️ 21/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 22/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/695367ec.json\n",
      "❌ 22/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 23/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/15696249.json\n",
      "❌ 23/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 24/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c92b942c.json\n",
      "⚠️ 24/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 25/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27a77e38.json\n",
      "❌ 25/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 26/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60c09cac.json\n",
      "❌ 26/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 27/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ccd554ac.json\n",
      "❌ 27/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 28/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c786b71.json\n",
      "⚠️ 28/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 29/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c1990cce.json\n",
      "❌ 29/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 30/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7953d61e.json\n",
      "⚠️ 30/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 31/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66e6c45b.json\n",
      "✅ 31/200 - Correct\n",
      "\n",
      "🚀 Running inference 32/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5b6cbef5.json\n",
      "❌ 32/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 33/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bc4146bd.json\n",
      "❌ 33/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 34/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4cd1b7b2.json\n",
      "❌ 34/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 35/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e133d23d.json\n",
      "⚠️ 35/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 36/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e6de6e8f.json\n",
      "⚠️ 36/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 37/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/be03b35f.json\n",
      "❌ 37/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 38/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12422b43.json\n",
      "❌ 38/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 39/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b15fca0b.json\n",
      "❌ 39/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 40/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ca8de6ea.json\n",
      "✅ 40/200 - Correct\n",
      "\n",
      "🚀 Running inference 41/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7b06bea.json\n",
      "❌ 41/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 42/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f0afb749.json\n",
      "❌ 42/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 43/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3979b1a8.json\n",
      "⚠️ 43/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 44/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d017b73f.json\n",
      "❌ 44/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 45/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/17cae0c1.json\n",
      "❌ 45/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 46/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62b74c02.json\n",
      "❌ 46/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 47/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31d5ba1a.json\n",
      "❌ 47/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 48/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e345f17b.json\n",
      "❌ 48/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 49/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa18de87.json\n",
      "❌ 49/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 50/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73c3b0d8.json\n",
      "❌ 50/200 - Incorrect\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.1_results_batch_50.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 76\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# ✅ Save results every 50 examples\u001b[39;00m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[43msave_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# ✅ Final save for remaining results\u001b[39;00m\n\u001b[1;32m     79\u001b[0m save_results(num_samples)\n",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m, in \u001b[0;36msave_results\u001b[0;34m(batch_index)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_results\u001b[39m(batch_index):\n\u001b[1;32m     12\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_batch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     14\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(all_results, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m💾 **Saved results for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m examples at:** \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.1_results_batch_50.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ✅ Set batch save settings\n",
    "num_samples = 200\n",
    "batch_size = 50  # ✅ Save progress every 50 examples\n",
    "\n",
    "# ✅ Dictionary to store all results\n",
    "all_results = {}\n",
    "\n",
    "# ✅ Function to save results periodically\n",
    "def save_results(batch_index):\n",
    "    save_path = f\"./{model_name}_results_batch_{batch_index}.json\"\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "    print(f\"\\n💾 **Saved results for {batch_index} examples at:** {save_path}\")\n",
    "\n",
    "# ✅ Run inference and comparison for each file\n",
    "for idx, file in enumerate(filtered_files[:num_samples]):\n",
    "    print(f\"\\n🚀 Running inference {idx + 1}/{num_samples}: {file}\")\n",
    "\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(dataset_folder, file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1000,  \n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            repetition_penalty=1.2,  \n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Extract output matrix using updated method\n",
    "    extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "    # ✅ Load ground truth matrix\n",
    "    ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "    # ✅ Compare matrices\n",
    "    comparison_result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "    # ✅ Store results\n",
    "    all_results[file] = {\n",
    "        \"model_name\": model_name,\n",
    "        \"extracted_matrix\": extracted_matrix,\n",
    "        \"ground_truth\": ground_truth_matrix,\n",
    "        \"comparison\": comparison_result\n",
    "    }\n",
    "\n",
    "    # ✅ Display live progress with symbols\n",
    "    if \"matches\" in comparison_result:\n",
    "        print(f\"✅ {idx + 1}/{num_samples} - Correct\")\n",
    "    elif \"❌\" in comparison_result:\n",
    "        print(f\"❌ {idx + 1}/{num_samples} - Incorrect\")\n",
    "    elif \"⚠️\" in comparison_result:\n",
    "        print(f\"⚠️ {idx + 1}/{num_samples} - Invalid Output\")\n",
    "\n",
    "    # ✅ Save results every 50 examples\n",
    "    if (idx + 1) % batch_size == 0:\n",
    "        save_results(idx + 1)\n",
    "\n",
    "# ✅ Final save for remaining results\n",
    "save_results(num_samples)\n",
    "print(\"\\n✅ **Completed inference & comparison for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebab1226-f31a-4a9b-9025-162e2da37107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 51/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c074846d.json\n",
      "❌ 51/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 52/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cad67732.json\n",
      "⚠️ 52/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 53/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fb791726.json\n",
      "❌ 53/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 54/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ba14f53.json\n",
      "⚠️ 54/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 55/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5790162.json\n",
      "❌ 55/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 56/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bbb1b8b6.json\n",
      "❌ 56/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 57/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2a5f8217.json\n",
      "❌ 57/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 58/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5783df64.json\n",
      "❌ 58/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 59/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b1fc8b8e.json\n",
      "❌ 59/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 60/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a8610ef7.json\n",
      "❌ 60/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 61/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/770cc55f.json\n",
      "❌ 61/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 62/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/68b67ca3.json\n",
      "❌ 62/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 63/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/67c52801.json\n",
      "⚠️ 63/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 64/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c56f360.json\n",
      "❌ 64/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 65/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/34b99a2b.json\n",
      "❌ 65/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 66/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed74f2f2.json\n",
      "❌ 66/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 67/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/506d28a5.json\n",
      "❌ 67/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 68/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/22a4bbc2.json\n",
      "❌ 68/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 69/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d19f7514.json\n",
      "❌ 69/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 70/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00dbd492.json\n",
      "❌ 70/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 71/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7dd8335.json\n",
      "⚠️ 71/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 72/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c8b7cc0f.json\n",
      "❌ 72/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 73/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/332efdb3.json\n",
      "❌ 73/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 74/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3b4c2228.json\n",
      "❌ 74/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 75/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/626c0bcc.json\n",
      "⚠️ 75/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 76/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9110e3c5.json\n",
      "❌ 76/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 77/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6f473927.json\n",
      "⚠️ 77/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 78/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c9aba6e.json\n",
      "⚠️ 78/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 79/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5d2a5c43.json\n",
      "❌ 79/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 80/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12eac192.json\n",
      "❌ 80/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 81/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66f2d22f.json\n",
      "❌ 81/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 82/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ad5bdfd.json\n",
      "❌ 82/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 83/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9bebae7a.json\n",
      "❌ 83/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 84/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/90347967.json\n",
      "❌ 84/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 85/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d2acf2cb.json\n",
      "⚠️ 85/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 86/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2697da3f.json\n",
      "❌ 86/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 87/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d931c21c.json\n",
      "⚠️ 87/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 88/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50a16a69.json\n",
      "❌ 88/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 89/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1c0d0a4b.json\n",
      "❌ 89/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 90/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/195ba7dc.json\n",
      "❌ 90/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 91/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3d31c5b3.json\n",
      "⚠️ 91/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 92/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62ab2642.json\n",
      "❌ 92/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 93/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6a11f6da.json\n",
      "❌ 93/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 94/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/281123b4.json\n",
      "❌ 94/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 95/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ef26cbf6.json\n",
      "❌ 95/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 96/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/42a15761.json\n",
      "❌ 96/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 97/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b4a43f3b.json\n",
      "❌ 97/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 98/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ae58858e.json\n",
      "⚠️ 98/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 99/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e69241bd.json\n",
      "❌ 99/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 100/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/85fa5666.json\n",
      "❌ 100/200 - Incorrect\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './model_results/phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.1_results_batch_100.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 83\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# ✅ Save results every 50 examples\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m actual_idx \u001b[38;5;241m%\u001b[39m batch_size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 83\u001b[0m         \u001b[43msave_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# ✅ Final save for remaining results\u001b[39;00m\n\u001b[1;32m     86\u001b[0m save_results(num_samples)\n",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m, in \u001b[0;36msave_results\u001b[0;34m(batch_index)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_results\u001b[39m(batch_index):\n\u001b[1;32m     18\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results_batch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     20\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(all_results, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m💾 **Saved results for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m examples at:** \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './model_results/phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.1_results_batch_100.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# ✅ Ensure save directory exists\n",
    "save_dir = \"./model_results\"\n",
    "os.makedirs(save_dir, exist_ok=True)  # ✅ Creates the directory if it does not exist\n",
    "\n",
    "# ✅ Set batch save settings\n",
    "start_idx = 50  # ✅ Start from 51st example\n",
    "num_samples = 200  # ✅ Total dataset size\n",
    "batch_size = 50  # ✅ Save progress every 50 examples\n",
    "\n",
    "# ✅ Dictionary to store all results\n",
    "all_results = {}\n",
    "\n",
    "# ✅ Function to save results periodically\n",
    "def save_results(batch_index):\n",
    "    save_path = os.path.join(save_dir, f\"{model_name}_results_batch_{batch_index}.json\")\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "    print(f\"\\n💾 **Saved results for {batch_index} examples at:** {save_path}\")\n",
    "\n",
    "# ✅ Run inference and comparison for the remaining 150 files\n",
    "for idx, file in enumerate(filtered_files[start_idx:num_samples]):\n",
    "    actual_idx = start_idx + idx + 1  # ✅ Adjust index to reflect the actual dataset position\n",
    "    print(f\"\\n🚀 Running inference {actual_idx}/{num_samples}: {file}\")\n",
    "\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(dataset_folder, file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1000,  \n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            repetition_penalty=1.2,  \n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Extract output matrix using updated method\n",
    "    extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "    # ✅ Load ground truth matrix\n",
    "    ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "    # ✅ Compare matrices\n",
    "    comparison_result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "    # ✅ Store results\n",
    "    all_results[file] = {\n",
    "        \"model_name\": model_name,\n",
    "        \"extracted_matrix\": extracted_matrix,\n",
    "        \"ground_truth\": ground_truth_matrix,\n",
    "        \"comparison\": comparison_result\n",
    "    }\n",
    "\n",
    "    # ✅ Display live progress with symbols\n",
    "    if \"matches\" in comparison_result:\n",
    "        print(f\"✅ {actual_idx}/{num_samples} - Correct\")\n",
    "    elif \"❌\" in comparison_result:\n",
    "        print(f\"❌ {actual_idx}/{num_samples} - Incorrect\")\n",
    "    elif \"⚠️\" in comparison_result:\n",
    "        print(f\"⚠️ {actual_idx}/{num_samples} - Invalid Output\")\n",
    "\n",
    "    # ✅ Save results every 50 examples\n",
    "    if actual_idx % batch_size == 0:\n",
    "        save_results(actual_idx)\n",
    "\n",
    "# ✅ Final save for remaining results\n",
    "save_results(num_samples)\n",
    "print(\"\\n✅ **Completed inference & comparison for the remaining 150 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ce343-e9d2-4db6-984c-c8422ba5f09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 101/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8597cfd7.json\n",
      "❌ 101/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 102/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4852f2fa.json\n",
      "❌ 102/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 103/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55783887.json\n",
      "❌ 103/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 104/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72207abc.json\n",
      "⚠️ 104/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 105/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d37a1ef5.json\n",
      "❌ 105/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 106/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/af24b4cc.json\n",
      "⚠️ 106/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 107/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c87289bb.json\n",
      "❌ 107/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 108/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1a2e2828.json\n",
      "✅ 108/200 - Correct\n",
      "\n",
      "🚀 Running inference 109/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8fbca751.json\n",
      "❌ 109/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 110/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5207a7b5.json\n",
      "❌ 110/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 111/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0722778.json\n",
      "❌ 111/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 112/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0a2355a6.json\n",
      "❌ 112/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 113/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0f4d537.json\n",
      "❌ 113/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 114/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e99362f0.json\n",
      "❌ 114/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 115/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c35c1b4c.json\n",
      "❌ 115/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 116/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f45f5ca7.json\n",
      "❌ 116/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 117/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/64a7c07e.json\n",
      "⚠️ 117/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 118/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac3e2b04.json\n",
      "❌ 118/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 119/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c7d4e6ad.json\n",
      "❌ 119/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 120/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/84db8fc4.json\n",
      "❌ 120/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 121/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce039d91.json\n",
      "❌ 121/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 122/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/99306f82.json\n",
      "⚠️ 122/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 123/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2685904e.json\n",
      "❌ 123/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 124/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4acc7107.json\n",
      "⚠️ 124/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 125/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4e469f39.json\n",
      "❌ 125/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 126/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bf32578f.json\n",
      "❌ 126/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 127/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa300dc3.json\n",
      "❌ 127/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 128/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/137f0df0.json\n",
      "❌ 128/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 129/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/03560426.json\n",
      "❌ 129/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 130/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/69889d6e.json\n",
      "❌ 130/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 131/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e9ac8c9e.json\n",
      "❌ 131/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 132/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cfb2ce5a.json\n",
      "⚠️ 132/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 133/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/da2b0fe3.json\n",
      "⚠️ 133/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 134/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6df30ad6.json\n",
      "❌ 134/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 135/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3cdc58f.json\n",
      "❌ 135/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 136/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/58743b76.json\n",
      "❌ 136/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 137/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a406ac07.json\n",
      "⚠️ 137/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 138/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/94414823.json\n",
      "✅ 138/200 - Correct\n",
      "\n",
      "🚀 Running inference 139/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/575b1a71.json\n",
      "❌ 139/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 140/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3e62deb.json\n",
      "❌ 140/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 141/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ea9794b1.json\n",
      "⚠️ 141/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 142/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31adaf00.json\n",
      "❌ 142/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 143/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c1e755f.json\n",
      "⚠️ 143/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 144/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac605cbb.json\n",
      "❌ 144/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 145/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7c8af763.json\n",
      "❌ 145/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 146/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7ee1c6ea.json\n",
      "❌ 146/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 147/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b942fd60.json\n",
      "❌ 147/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 148/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/782b5218.json\n",
      "⚠️ 148/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 149/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0becf7df.json\n",
      "❌ 149/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 150/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/136b0064.json\n",
      "❌ 150/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 151/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dd2401ed.json\n",
      "❌ 151/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 152/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50aad11f.json\n",
      "❌ 152/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 153/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2b01abd0.json\n",
      "❌ 153/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 154/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/292dd178.json\n",
      "❌ 154/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 155/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce8d95cc.json\n",
      "❌ 155/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 156/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/423a55dc.json\n",
      "⚠️ 156/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 157/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/817e6c09.json\n",
      "❌ 157/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 158/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/11e1fe23.json\n",
      "❌ 158/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 159/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2c737e39.json\n",
      "❌ 159/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 160/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ff72ca3e.json\n",
      "❌ 160/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 161/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/93b4f4b3.json\n",
      "❌ 161/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 162/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fe9372f3.json\n",
      "⚠️ 162/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 163/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ecaa0ec1.json\n",
      "❌ 163/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 164/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cd3c21df.json\n",
      "❌ 164/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 165/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/08573cc6.json\n",
      "❌ 165/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 166/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/963f59bc.json\n",
      "❌ 166/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 167/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dc2aa30b.json\n",
      "❌ 167/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 168/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9ddd00f0.json\n",
      "❌ 168/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 169/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5c44e8f.json\n",
      "❌ 169/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 170/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b7cb93ac.json\n",
      "❌ 170/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 171/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f5aa3634.json\n",
      "❌ 171/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 172/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72a961c9.json\n",
      "⚠️ 172/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 173/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/45737921.json\n",
      "❌ 173/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 174/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5ffb2104.json\n",
      "❌ 174/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 175/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/516b51b7.json\n",
      "❌ 175/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 176/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/baf41dbf.json\n",
      "❌ 176/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 177/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55059096.json\n",
      "⚠️ 177/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 178/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/762cd429.json\n",
      "⚠️ 178/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 179/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e78887d1.json\n",
      "❌ 179/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 180/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ee62060.json\n",
      "⚠️ 180/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 181/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e872b94a.json\n",
      "❌ 181/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 182/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/705a3229.json\n",
      "❌ 182/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 183/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1acc24af.json\n",
      "❌ 183/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 184/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/917bccba.json\n",
      "⚠️ 184/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 185/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7e02026e.json\n",
      "❌ 185/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 186/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73182012.json\n",
      "❌ 186/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 187/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9f27f097.json\n",
      "❌ 187/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 188/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60a26a3e.json\n",
      "❌ 188/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 189/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3391f8c0.json\n",
      "❌ 189/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 190/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/505fff84.json\n",
      "❌ 190/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 191/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12997ef3.json\n",
      "❌ 191/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 192/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/642248e4.json\n",
      "⚠️ 192/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 193/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/896d5239.json\n",
      "❌ 193/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 194/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0bb8deee.json\n",
      "❌ 194/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 195/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/992798f6.json\n",
      "❌ 195/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 196/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/712bf12e.json\n",
      "⚠️ 196/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 197/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9b365c51.json\n",
      "⚠️ 197/200 - Invalid Output\n",
      "\n",
      "🚀 Running inference 198/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5af49b42.json\n",
      "❌ 198/200 - Incorrect\n",
      "\n",
      "🚀 Running inference 199/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c658a4bd.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# ✅ Set batch processing settings\n",
    "start_idx = 100  # ✅ Start from 101st example\n",
    "num_samples = 200  # ✅ Total dataset size\n",
    "\n",
    "# ✅ Dictionary to store results\n",
    "all_results = {}\n",
    "\n",
    "# ✅ Run inference and comparison for the remaining files\n",
    "for idx, file in enumerate(filtered_files[start_idx:num_samples]):\n",
    "    actual_idx = start_idx + idx + 1  # ✅ Adjust index to reflect actual dataset position\n",
    "    print(f\"\\n🚀 Running inference {actual_idx}/{num_samples}: {file}\")\n",
    "\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(dataset_folder, file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1000,  \n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            repetition_penalty=1.2,  \n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Extract output matrix using updated method\n",
    "    extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "    # ✅ Load ground truth matrix\n",
    "    ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "    # ✅ Compare matrices\n",
    "    comparison_result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "    # ✅ Store results\n",
    "    all_results[file] = {\n",
    "        \"model_name\": model_name,\n",
    "        \"extracted_matrix\": extracted_matrix,\n",
    "        \"ground_truth\": ground_truth_matrix,\n",
    "        \"comparison\": comparison_result\n",
    "    }\n",
    "\n",
    "    # ✅ Display live progress with symbols\n",
    "    if \"matches\" in comparison_result:\n",
    "        print(f\"✅ {actual_idx}/{num_samples} - Correct\")\n",
    "    elif \"❌\" in comparison_result:\n",
    "        print(f\"❌ {actual_idx}/{num_samples} - Incorrect\")\n",
    "    elif \"⚠️\" in comparison_result:\n",
    "        print(f\"⚠️ {actual_idx}/{num_samples} - Invalid Output\")\n",
    "\n",
    "print(\"\\n✅ **Completed inference & comparison for the remaining 100 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fc58aa-46c2-4893-b7fd-bef791a06192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Loaded 200 filtered JSON files for evaluation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# ✅ Clear GPU memory before starting\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Load the filtered 200 shortest JSON files\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(filtered_files)} filtered JSON files for evaluation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33d78592-3ca9-4550-8905-6d0fd7607f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Loading Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings on cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c3c6cbb94f4bd09dd360c8b98ffd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# ✅ Run inference for both models\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43mrun_debug_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m run_debug_inference(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 45\u001b[0m, in \u001b[0;36mrun_debug_inference\u001b[0;34m(model_name, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# ✅ Run inference\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 45\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# ✅ Decode full output\u001b[39;00m\n\u001b[1;32m     56\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:3249\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3247\u001b[0m     probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(next_token_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   3248\u001b[0m     \u001b[38;5;66;03m# TODO (joao): this OP throws \"skipping cudagraphs due to ['incompatible ops']\", find solution\u001b[39;00m\n\u001b[0;32m-> 3249\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3251\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(next_token_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# ✅ Select the first 5 files to inspect raw model outputs\n",
    "num_samples = 5\n",
    "test_files = filtered_files[:num_samples]\n",
    "\n",
    "# ✅ Function to run inference and print raw model output\n",
    "def run_debug_inference(model_name, device):\n",
    "    print(f\"\\n🚀 Loading Model: {model_name} on {device}\")\n",
    "\n",
    "    # ✅ Load Model on Assigned GPU\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map={\"\" : device}  # ✅ Load on assigned GPU\n",
    "    )\n",
    "\n",
    "    # ✅ Run inference for 5 examples\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1000,  \n",
    "                do_sample=True,  \n",
    "                temperature=0.7,  \n",
    "                top_k=50,  \n",
    "                top_p=0.9,  \n",
    "                repetition_penalty=1.2,  \n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Print the full raw output exactly as generated\n",
    "        print(\"\\n🚀 **Full Raw Model Output:**\\n\")\n",
    "        print(generated_text)\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ Run inference for both models\n",
    "run_debug_inference(\"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\", \"cuda:0\")\n",
    "run_debug_inference(\"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\", \"cuda:1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0ad064-1a40-479a-9bb4-1623f4d424fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Function `construct_fixed_prompt` is now defined and ready!\n"
     ]
    }
   ],
   "source": [
    "# ✅ Function to construct a well-formatted prompt from JSON files\n",
    "def construct_fixed_prompt(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # ✅ Extract training & test examples\n",
    "    training_examples = data.get(\"train\", [])\n",
    "    test_examples = data.get(\"test\", [])\n",
    "\n",
    "    if not test_examples or not training_examples:\n",
    "        return None  # Skip if missing data\n",
    "\n",
    "    test_input = test_examples[0][\"input\"]\n",
    "    \n",
    "    # ✅ Build an improved prompt that explicitly asks for only the output matrix\n",
    "    prompt = \"Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\\n\\n\"\n",
    "\n",
    "    for ex in training_examples:\n",
    "        prompt += f\"Input: {ex['input']}\\n\"\n",
    "        prompt += f\"Output: {ex['output']}\\n\\n\"\n",
    "\n",
    "    prompt += f\"Test Input Matrix:\\n{test_input}\\n\\n\"\n",
    "    prompt += \"**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "print(\"\\n✅ Function `construct_fixed_prompt` is now defined and ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18943865-75ea-4fa7-8658-5e7c4a398c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ **Updated matrix extraction function is ready!**\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ✅ Function to extract matrix after instruction text and stop at first `]]`\n",
    "def extract_final_matrix(generated_text):\n",
    "    instruction_text = \"Provide ONLY the final output matrix for the test input. Do NOT include any other text.\"\n",
    "    \n",
    "    # ✅ Find where the instruction appears\n",
    "    start_idx = generated_text.find(instruction_text)\n",
    "    if start_idx == -1:\n",
    "        return \"⚠️ Instruction text not found in output.\"\n",
    "\n",
    "    # ✅ Extract everything after the instruction\n",
    "    output_after_instruction = generated_text[start_idx + len(instruction_text):].strip()\n",
    "\n",
    "    # ✅ Use regex to find the first valid matrix **after the instruction text**\n",
    "    matrix_match = re.search(r\"\\[\\[.*?\\]\\]\", output_after_instruction, re.DOTALL)\n",
    "    \n",
    "    if matrix_match:\n",
    "        return matrix_match.group(0)  # ✅ Return the extracted matrix\n",
    "    else:\n",
    "        return \"⚠️ No valid matrix found in extracted output.\"\n",
    "\n",
    "print(\"\\n✅ **Updated matrix extraction function is ready!**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "778b9322-4ea9-41da-b30a-a3c63507bbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Loading Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings on cuda:0\n",
      "\n",
      "🚀 Loading Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1 on cuda:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d923d5ebe6a426fa0f265ab32114beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87447ac455584a36919f3ca0358c6667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/slurm_tmpdir/job_25372695/ipykernel_539717/429513468.py\", line 57, in run_debug_inference\n",
      "  File \"/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py\", line 2215, in generate\n",
      "    result = self._sample(\n",
      "  File \"/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py\", line 3249, in _sample\n",
      "    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
      "RuntimeError: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/scratch/slurm_tmpdir/job_25372695/ipykernel_539717/429513468.py\", line 57, in run_debug_inference\n",
      "  File \"/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py\", line 2215, in generate\n",
      "    result = self._sample(\n",
      "  File \"/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py\", line 3249, in _sample\n",
      "    next_tokens = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
      "RuntimeError: probability tensor contains either `inf`, `nan` or element < 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ **Completed inference for both models on 5 examples!** 🚀\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# ✅ Select the first 5 files to inspect\n",
    "num_samples = 5\n",
    "test_files = filtered_files[:num_samples]\n",
    "\n",
    "# ✅ Function to run inference, extract matrix, and compare with ground truth\n",
    "def run_debug_inference(model_name, device):\n",
    "    print(f\"\\n🚀 Loading Model: {model_name} on {device}\")\n",
    "\n",
    "    # ✅ Load Model on Assigned GPU\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map={\"\" : device}  # ✅ Load on assigned GPU\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # ✅ Run inference for 5 examples\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt and move to correct data type\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        # ✅ Ensure inputs are in `torch.long` (required for embedding layers)\n",
    "        inputs = {k: v.to(dtype=torch.long) for k, v in inputs.items()}\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with safe parameters\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits[:, -1, :]\n",
    "            \n",
    "            # ✅ Sanitize probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            probs = torch.nan_to_num(probs, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "            probs = probs / probs.sum(dim=-1, keepdim=True)  # ✅ Normalize\n",
    "\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=700,  # ✅ Prevents excessive token generation\n",
    "                do_sample=True,  \n",
    "                temperature=0.8,  # ✅ Balanced randomness\n",
    "                top_k=50,  # ✅ Ensure `top_k` is reasonable\n",
    "                top_p=0.9,  # ✅ Avoid extreme filtering\n",
    "                repetition_penalty=1.1,  # ✅ Reduce excessive repetition\n",
    "            )\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Print Results\n",
    "        print(\"\\n🚀 **Full Raw Model Output:**\\n\")\n",
    "        print(generated_text)\n",
    "\n",
    "        print(\"\\n🔍 **Extracted Output Matrix:**\\n\")\n",
    "        print(extracted_matrix)\n",
    "\n",
    "        print(\"\\n🎯 **Ground Truth Matrix:**\\n\")\n",
    "        print(np.array(ground_truth_matrix) if ground_truth_matrix else \"⚠️ No ground truth available\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ Run inference for both models in parallel\n",
    "from threading import Thread\n",
    "\n",
    "thread_1 = Thread(target=run_debug_inference, args=(\"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\", \"cuda:0\"))\n",
    "thread_2 = Thread(target=run_debug_inference, args=(\"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1\", \"cuda:1\"))\n",
    "\n",
    "# ✅ Start both threads\n",
    "thread_1.start()\n",
    "thread_2.start()\n",
    "\n",
    "# ✅ Wait for both to complete\n",
    "thread_1.join()\n",
    "thread_2.join()\n",
    "\n",
    "print(\"\\n✅ **Completed inference for both models on 5 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ff563fe-cee1-4300-80da-bcf2e70583b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running Model across CUDA:0 and CUDA:1...\n",
      "\n",
      "\n",
      "🚀 Loading Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings across multiple GPUs (Auto-Device Mapping)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b277a0d7c9fd4adbbd7205cfb77dcf87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-8.2266, -4.2539, -6.5312, -8.6641, -6.4062]], device='cuda:1')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[1.1802e-05, 6.2752e-04, 6.4373e-05, 7.6294e-06, 7.2896e-05]],\n",
      "       device='cuda:1')\n",
      "\n",
      "🚀 Running inference 2/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-7.6953, -3.9023, -6.4648, -7.6719, -6.3516]], device='cuda:1')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[1.5676e-05, 6.9523e-04, 5.3585e-05, 1.6034e-05, 6.0022e-05]],\n",
      "       device='cuda:1')\n",
      "\n",
      "🚀 Running inference 3/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-8.2266, -4.3945, -6.5039, -7.8438, -6.5000]], device='cuda:1')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[8.8215e-06, 4.0650e-04, 4.9293e-05, 1.2934e-05, 4.9472e-05]],\n",
      "       device='cuda:1')\n",
      "\n",
      "🚀 Running inference 4/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-8.1719, -4.0508, -5.7188, -7.6484, -5.8711]], device='cuda:1')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[9.8348e-06, 6.0511e-04, 1.1414e-04, 1.6570e-05, 9.7990e-05]],\n",
      "       device='cuda:1')\n",
      "\n",
      "🚀 Running inference 5/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-8.6719, -3.9688, -6.1953, -7.8984, -6.4648]], device='cuda:1')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[7.4506e-06, 8.2207e-04, 8.8692e-05, 1.6153e-05, 6.7770e-05]],\n",
      "       device='cuda:1')\n",
      "\n",
      "✅ **Completed inference for model using multi-GPU!** 🚀\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# ✅ Select the first 5 files to inspect\n",
    "num_samples = 5\n",
    "test_files = filtered_files[:num_samples]\n",
    "\n",
    "# ✅ Function to run inference, extract matrix, and compare with ground truth\n",
    "def run_debug_inference(model_name):\n",
    "    print(f\"\\n🚀 Loading Model: {model_name} across multiple GPUs (Auto-Device Mapping)\")\n",
    "\n",
    "    # ✅ Load Model with Auto GPU Distribution\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"  # ✅ Auto-distributes across GPUs\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # ✅ Run inference for 5 examples\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {idx + 1}/{num_samples} on {model_name}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt and move to correct data type\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        # ✅ Ensure inputs are in `torch.long` (required for embedding layers)\n",
    "        inputs = {k: v.to(dtype=torch.long) for k, v in inputs.items()}\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with logit stabilization\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits[:, -1, :]\n",
    "\n",
    "            # ✅ Clamp logits to prevent extreme values\n",
    "            logits = torch.clamp(logits, min=-10, max=10)\n",
    "\n",
    "            # ✅ Normalize logits before softmax\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True)[0]\n",
    "\n",
    "            # ✅ Apply softmax safely\n",
    "            probs = torch.softmax(logits, dim=-1) + 1e-9\n",
    "\n",
    "            # ✅ Normalize probabilities again to avoid underflow\n",
    "            probs = probs / probs.sum(dim=-1, keepdim=True)\n",
    "\n",
    "            # ✅ Verify if NaN still occurs\n",
    "            if torch.isnan(probs).any():\n",
    "                print(\"❌ ERROR: NaN detected even after normalization.\")\n",
    "                print(f\"⚠️ Logits Dump (First 5 Values): {logits[:, :5]}\")\n",
    "                print(f\"⚠️ Probabilities Dump (First 5 Values): {probs[:, :5]}\")\n",
    "                continue  # Skip this sample\n",
    "\n",
    "            # ✅ Run safe inference with stabilized params\n",
    "            try:\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=600,  # ✅ Reduce generation length to avoid instability\n",
    "                    do_sample=True,  \n",
    "                    temperature=0.6,  # ✅ Lower temperature to prevent extreme token probabilities\n",
    "                    top_k=50,  # ✅ Ensure `top_k` is reasonable\n",
    "                    top_p=0.85,  # ✅ Lower `top_p` to avoid extreme sampling\n",
    "                    repetition_penalty=1.05,  # ✅ Reduce repetition control\n",
    "                )\n",
    "            except RuntimeError as e:\n",
    "                print(\"❌ ERROR: Failed to generate tokens due to NaN values in logits.\")\n",
    "                print(f\"⚠️ Logits Dump (First 5 Values): {logits[:, :5]}\")\n",
    "                print(f\"⚠️ Probabilities Dump (First 5 Values): {probs[:, :5]}\")\n",
    "                continue  # Skip this sample\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Print Results\n",
    "        print(\"\\n🚀 **Full Raw Model Output:**\\n\")\n",
    "        print(generated_text)\n",
    "\n",
    "        print(\"\\n🔍 **Extracted Output Matrix:**\\n\")\n",
    "        print(extracted_matrix)\n",
    "\n",
    "        print(\"\\n🎯 **Ground Truth Matrix:**\\n\")\n",
    "        print(np.array(ground_truth_matrix) if ground_truth_matrix else \"⚠️ No ground truth available\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ Run model inference across both GPUs\n",
    "print(\"\\n🚀 Running Model across CUDA:0 and CUDA:1...\\n\")\n",
    "run_debug_inference(\"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs5_wd0.1_WithoutReasonings\")\n",
    "\n",
    "print(\"\\n✅ **Completed inference for model using multi-GPU!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28e34cb1-d47d-46d7-af30-6683b91e328f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Loading Model: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings on cuda:0\n",
      "🚀 Loading Model: phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01 on cuda:1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c250d588cf4a15b36f3ea18e5114f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387290cd7637411b81528188e7ee916f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd8786e211941e190a8410d8ba8faee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd04cf61d0a8415595cb316b1141001c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e04b7f98814c5db613445cd332525a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb19c1b1605f491dbc9f37deaccf7aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1557ebba48c45b789865cf687495518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bee47c267a4120beeb75302696a27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452963950a5c4eaea65e8323f1e524c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9e71b769df43d0b9335b18b1b67690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a62e4b218744fd942ef3490bcebb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e662d4f0a35b446785a241635bd4ba6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f6f449f64d4258a1bd17614e6917b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35825ad921d7450780f8e74819148ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e686259190741569ebbcc2f5cd860ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232e7c617d9e4fa1b4b0da49c85553af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93ccc27130143a6a216a02ad6aecbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1431370dbca4e4095e9f51e5efff240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-3.9102, -3.4062, -2.3672, -4.8438, -5.3477]], device='cuda:1')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[3.6478e-04, 6.0368e-04, 1.7061e-03, 1.4341e-04, 8.6665e-05]],\n",
      "       device='cuda:1')\n",
      "\n",
      "🚀 Running inference 2/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-5.2930, -3.9609, -3.3086, -5.2617, -5.7031]], device='cuda:1')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[9.8228e-05, 3.7217e-04, 7.1430e-04, 1.0133e-04, 6.5148e-05]],\n",
      "       device='cuda:1')\n",
      "\n",
      "🚀 Running inference 3/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-4.6445, -4.1172, -2.9375, -5.0273, -5.5000]], device='cuda:1')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[1.8954e-04, 3.2115e-04, 1.0452e-03, 1.2922e-04, 8.0585e-05]],\n",
      "       device='cuda:1')\n",
      "\n",
      "🚀 Running inference 4/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-4.3398, -3.7578, -2.6328, -5.2461, -4.9922]], device='cuda:1')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[2.3603e-04, 4.2248e-04, 1.3008e-03, 9.5367e-05, 1.2290e-04]],\n",
      "       device='cuda:1')\n",
      "\n",
      "🚀 Running inference 5/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-3.8281, -3.6328, -2.6055, -4.9414, -5.4297]], device='cuda:1')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[3.8648e-04, 4.6992e-04, 1.3132e-03, 1.2696e-04, 7.7903e-05]],\n",
      "       device='cuda:1')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b904e2493a4def9052b1ff60f4ced3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eda0c14bfe44cd7a6e3a930f3458187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205540b8416f41888222acb7c1cb9f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5db69cc8670475695ee84671c62bdd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80a8d4fadfa4fcead2a717261bb6006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2351b9ff1e4dbab939bb827ee3832b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-5.4883, -3.7539, -3.2852, -6.0078, -4.7617]], device='cuda:0')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[5.6684e-05, 3.2115e-04, 5.1308e-04, 3.3677e-05, 1.1718e-04]],\n",
      "       device='cuda:0')\n",
      "\n",
      "🚀 Running inference 2/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-5.1953, -3.4180, -2.6602, -5.3867, -4.7500]], device='cuda:0')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[7.0214e-05, 4.1533e-04, 8.8596e-04, 5.7995e-05, 1.0961e-04]],\n",
      "       device='cuda:0')\n",
      "\n",
      "🚀 Running inference 3/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-4.4023, -3.0508, -2.9062, -5.5039, -4.4805]], device='cuda:0')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[1.4710e-04, 5.6839e-04, 6.5660e-04, 4.8876e-05, 1.3602e-04]],\n",
      "       device='cuda:0')\n",
      "\n",
      "🚀 Running inference 4/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-5.1406, -3.7734, -2.7422, -6.1641, -4.4062]], device='cuda:0')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[7.5817e-05, 2.9755e-04, 8.3447e-04, 2.7239e-05, 1.5795e-04]],\n",
      "       device='cuda:0')\n",
      "\n",
      "🚀 Running inference 5/5 on phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "❌ ERROR: Failed to generate tokens due to NaN values in logits.\n",
      "⚠️ Logits Dump (First 5 Values): tensor([[-4.9102, -3.5469, -3.0352, -5.9609, -4.5391]], device='cuda:0')\n",
      "⚠️ Probabilities Dump (First 5 Values): tensor([[1.0371e-04, 4.0531e-04, 6.7616e-04, 3.6240e-05, 1.5032e-04]],\n",
      "       device='cuda:0')\n",
      "\n",
      "✅ **Completed inference for both models in parallel!** 🚀\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from threading import Thread\n",
    "\n",
    "# ✅ Select the first 5 files to inspect\n",
    "num_samples = 5\n",
    "test_files = filtered_files[:num_samples]\n",
    "\n",
    "# ✅ Function to run inference for a given model on a specific GPU\n",
    "def run_model_inference(model_name, device):\n",
    "    print(f\"\\n🚀 Loading Model: {model_name} on {device}\")\n",
    "\n",
    "    # ✅ Load Model on Assigned GPU\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map={\"\" : device}  # ✅ Load on assigned GPU\n",
    "    )\n",
    "\n",
    "    # ✅ Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # ✅ Run inference for 5 examples\n",
    "    for idx, file in enumerate(test_files):\n",
    "        print(f\"\\n🚀 Running inference {idx + 1}/{num_samples} on {model_name}: {file}\")\n",
    "\n",
    "        # ✅ Construct file path\n",
    "        file_path = os.path.join(dataset_folder, file)\n",
    "\n",
    "        # ✅ Construct prompt\n",
    "        test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "        # ✅ Tokenize the prompt and move to correct data type\n",
    "        inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # ✅ Ensure inputs are in `torch.long` (required for embedding layers)\n",
    "        inputs = {k: v.to(dtype=torch.long) for k, v in inputs.items()}\n",
    "\n",
    "        # ✅ Remove `token_type_ids` if present\n",
    "        if \"token_type_ids\" in inputs:\n",
    "            inputs.pop(\"token_type_ids\")\n",
    "\n",
    "        # ✅ Run inference with logit stabilization\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits[:, -1, :]\n",
    "\n",
    "            # ✅ Clamp logits to prevent extreme values\n",
    "            logits = torch.clamp(logits, min=-10, max=10)\n",
    "\n",
    "            # ✅ Normalize logits before softmax\n",
    "            logits = logits - logits.max(dim=-1, keepdim=True)[0]\n",
    "\n",
    "            # ✅ Apply softmax safely\n",
    "            probs = torch.softmax(logits, dim=-1) + 1e-9\n",
    "\n",
    "            # ✅ Normalize probabilities again to avoid underflow\n",
    "            probs = probs / probs.sum(dim=-1, keepdim=True)\n",
    "\n",
    "            # ✅ Verify if NaN still occurs\n",
    "            if torch.isnan(probs).any():\n",
    "                print(\"❌ ERROR: NaN detected even after normalization.\")\n",
    "                print(f\"⚠️ Logits Dump (First 5 Values): {logits[:, :5]}\")\n",
    "                print(f\"⚠️ Probabilities Dump (First 5 Values): {probs[:, :5]}\")\n",
    "                continue  # Skip this sample\n",
    "\n",
    "            # ✅ Run safe inference with stabilized params\n",
    "            try:\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=600,  # ✅ Reduce generation length to avoid instability\n",
    "                    do_sample=True,  \n",
    "                    temperature=0.7,  # ✅ Balanced temperature\n",
    "                    top_k=50,  # ✅ Ensure `top_k` is reasonable\n",
    "                    top_p=0.9,  # ✅ Avoid extreme filtering\n",
    "                    repetition_penalty=1.1,  # ✅ Reduce excessive repetition\n",
    "                )\n",
    "            except RuntimeError as e:\n",
    "                print(\"❌ ERROR: Failed to generate tokens due to NaN values in logits.\")\n",
    "                print(f\"⚠️ Logits Dump (First 5 Values): {logits[:, :5]}\")\n",
    "                print(f\"⚠️ Probabilities Dump (First 5 Values): {probs[:, :5]}\")\n",
    "                continue  # Skip this sample\n",
    "\n",
    "        # ✅ Decode full output\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "        # ✅ Extract output matrix\n",
    "        extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "        # ✅ Load ground truth matrix\n",
    "        ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "        # ✅ Print Results\n",
    "        print(\"\\n🚀 **Full Raw Model Output:**\\n\")\n",
    "        print(generated_text)\n",
    "\n",
    "        print(\"\\n🔍 **Extracted Output Matrix:**\\n\")\n",
    "        print(extracted_matrix)\n",
    "\n",
    "        print(\"\\n🎯 **Ground Truth Matrix:**\\n\")\n",
    "        print(np.array(ground_truth_matrix) if ground_truth_matrix else \"⚠️ No ground truth available\")\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ Run two models in parallel on separate GPUs\n",
    "thread_1 = Thread(target=run_model_inference, args=(\"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.01_WithoutReasonings\", \"cuda:0\"))\n",
    "thread_2 = Thread(target=run_model_inference, args=(\"phogen/FineLlama-3.1-8B_instruct_eval_lr5e-05_batch4_epochs1_wd0.01\", \"cuda:1\"))\n",
    "\n",
    "# ✅ Start both threads\n",
    "thread_1.start()\n",
    "thread_2.start()\n",
    "\n",
    "# ✅ Wait for both threads to finish\n",
    "thread_1.join()\n",
    "thread_2.join()\n",
    "\n",
    "print(\"\\n✅ **Completed inference for both models in parallel!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980bd26-5dba-4971-9b5c-1cfafea7dafd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de9e48e-e697-4856-8ac1-707e04d009b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries loaded and GPU management set up.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# ✅ Prevent Memory Fragmentation\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "# ✅ Function to Clear GPU Memory\n",
    "def clear_gpu_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    print(\"\\n✅ GPU memory cleared.\")\n",
    "\n",
    "print(\"✅ Libraries loaded and GPU management set up.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da90f2ff-5094-49fa-a00a-1da52e81813b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Found 400 JSON files in dataset.\n",
      "\n",
      "✅ Selected 200 smallest JSON files. Saved list to /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/filtered_200_files.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Get list of all JSON files\n",
    "json_files = glob(os.path.join(dataset_folder, \"*.json\"))\n",
    "print(f\"\\n✅ Found {len(json_files)} JSON files in dataset.\")\n",
    "\n",
    "# ✅ Function to calculate matrix size from JSON\n",
    "def get_matrix_size(json_path):\n",
    "    try:\n",
    "        with open(json_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        test_examples = data.get(\"test\", [])\n",
    "        if not test_examples:\n",
    "            return float('inf')  # Ignore files with no test data\n",
    "        \n",
    "        test_output = test_examples[0].get(\"output\", [])\n",
    "        return sum(len(row) for row in test_output)  # Total number of elements in matrix\n",
    "    except:\n",
    "        return float('inf')  # Ignore corrupted files\n",
    "\n",
    "# ✅ Scan all files and get their sizes\n",
    "file_sizes = [(file, get_matrix_size(file)) for file in json_files]\n",
    "\n",
    "# ✅ Sort by matrix size (smallest first)\n",
    "file_sizes.sort(key=lambda x: x[1])\n",
    "\n",
    "# ✅ Select the 200 smallest files\n",
    "smallest_files = [file for file, size in file_sizes[:200]]\n",
    "\n",
    "# ✅ Save the filtered list to a file\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "with open(filtered_files_path, \"w\") as f:\n",
    "    json.dump(smallest_files, f)\n",
    "\n",
    "print(f\"\\n✅ Selected 200 smallest JSON files. Saved list to {filtered_files_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e11125-d99a-46f5-8764-5c27187fd767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Loaded 200 filtered JSON files.\n",
      "\n",
      "✅ Displaying 5 sample files:\n",
      "📂 642d658d.json - Matrix Size: 1 elements\n",
      "📂 1a2e2828.json - Matrix Size: 1 elements\n",
      "📂 e872b94a.json - Matrix Size: 3 elements\n",
      "📂 be03b35f.json - Matrix Size: 4 elements\n",
      "📂 8597cfd7.json - Matrix Size: 4 elements\n"
     ]
    }
   ],
   "source": [
    "# ✅ Load the filtered list of files\n",
    "filtered_files_path = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/filtered_200_files.json\"\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(filtered_files)} filtered JSON files.\")\n",
    "\n",
    "# ✅ Function to print matrix size for verification\n",
    "def print_matrix_sizes(files, num_samples=5):\n",
    "    print(f\"\\n✅ Displaying {num_samples} sample files:\")\n",
    "    for file in files[:num_samples]:\n",
    "        with open(file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "        test_examples = data.get(\"test\", [])\n",
    "        test_output = test_examples[0].get(\"output\", []) if test_examples else []\n",
    "        matrix_size = sum(len(row) for row in test_output)\n",
    "        print(f\"📂 {os.path.basename(file)} - Matrix Size: {matrix_size} elements\")\n",
    "\n",
    "# ✅ Print first 5 files for verification\n",
    "print_matrix_sizes(filtered_files, num_samples=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892a5f9a-1632-41c2-a989-0a9e4c55b126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 File: 642d658d.json\n",
      "🔹 Test Input Matrix:\n",
      "[[0 0 9 9 0 9 0 9 0 6 0 9 0 0 9 9 0 9 0 0 9 0]\n",
      " [0 0 9 9 9 9 3 9 9 9 0 9 0 0 9 9 0 6 0 9 9 0]\n",
      " [9 9 2 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 9]\n",
      " [9 2 4 2 9 9 9 0 9 9 0 9 0 3 9 9 9 1 9 9 2 9]\n",
      " [9 9 2 9 9 9 6 9 9 9 6 9 9 9 2 0 9 9 9 9 9 9]\n",
      " [9 9 9 9 9 0 9 9 0 0 9 9 9 9 0 9 9 9 9 9 9 9]\n",
      " [0 0 9 9 9 9 0 9 9 9 0 9 3 0 9 9 0 9 0 9 9 0]\n",
      " [9 9 9 0 9 9 9 3 9 9 9 9 0 9 9 9 9 0 9 9 9 9]\n",
      " [6 9 9 0 9 9 3 4 3 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      " [9 9 9 0 9 9 9 3 9 3 9 9 9 9 9 9 6 9 9 0 0 3]\n",
      " [0 0 0 1 9 9 0 9 9 9 0 9 0 0 9 6 4 6 0 9 9 0]\n",
      " [9 9 9 9 9 9 9 0 9 9 9 0 2 9 9 9 6 9 9 0 9 1]\n",
      " [0 0 9 9 9 9 0 9 9 9 0 9 0 0 9 9 0 9 0 9 0 0]\n",
      " [0 0 9 2 9 9 3 9 0 6 0 9 0 0 9 9 0 9 0 9 9 0]\n",
      " [9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 9 9 9 9]\n",
      " [9 9 9 9 9 9 9 9 9 9 9 9 9 0 0 9 0 9 9 9 2 9]\n",
      " [0 6 3 9 9 9 0 9 9 0 0 9 0 3 9 9 0 2 0 0 9 0]\n",
      " [9 9 9 9 9 9 0 3 9 0 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      " [0 0 9 9 9 9 0 9 9 2 0 9 0 0 9 9 0 9 0 9 9 0]\n",
      " [9 9 9 9 0 9 9 9 9 9 9 6 0 9 9 9 9 9 9 9 6 9]\n",
      " [9 9 9 9 1 9 9 9 9 9 0 9 9 9 9 3 9 9 9 9 9 9]\n",
      " [0 0 0 1 4 1 0 9 9 0 0 9 0 0 0 9 0 9 2 9 0 0]\n",
      " [0 0 9 9 1 9 0 9 9 9 0 9 0 0 9 9 0 9 0 9 9 0]\n",
      " [3 9 9 9 9 0 9 9 0 9 9 9 2 9 0 9 9 9 9 0 0 9]\n",
      " [9 9 9 9 9 9 6 9 9 9 9 2 4 2 9 9 0 9 9 9 9 9]\n",
      " [0 0 9 9 9 9 0 0 9 1 0 9 2 0 9 9 0 9 6 9 9 0]\n",
      " [9 9 0 0 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 9 9]]\n",
      "\n",
      "🔹 Expected Output Matrix:\n",
      "[[2]]\n",
      "--------------------------------------------------\n",
      "\n",
      "📂 File: 1a2e2828.json\n",
      "🔹 Test Input Matrix:\n",
      "[[0 0 0 3 3 0 0 0 0 7 0 0 0]\n",
      " [0 0 0 3 3 0 0 0 0 7 0 0 0]\n",
      " [1 1 1 3 3 1 1 1 1 7 1 1 1]\n",
      " [1 1 1 3 3 1 1 1 1 7 1 1 1]\n",
      " [0 0 0 3 3 0 0 0 0 7 0 0 0]\n",
      " [0 0 0 3 3 0 0 0 0 7 0 0 0]\n",
      " [6 6 6 6 6 6 6 6 6 7 6 6 6]\n",
      " [0 0 0 3 3 0 0 0 0 7 0 0 0]\n",
      " [0 0 0 3 3 0 0 0 0 7 0 0 0]\n",
      " [0 0 0 3 3 0 0 0 0 7 0 0 0]\n",
      " [0 0 0 3 3 0 0 0 0 7 0 0 0]]\n",
      "\n",
      "🔹 Expected Output Matrix:\n",
      "[[7]]\n",
      "--------------------------------------------------\n",
      "\n",
      "📂 File: e872b94a.json\n",
      "🔹 Test Input Matrix:\n",
      "[[0 0 5 0 0 0 5 0 0 0]\n",
      " [0 0 5 0 0 0 5 5 0 0]\n",
      " [0 0 5 5 0 0 0 5 0 0]\n",
      " [0 0 0 5 0 0 0 5 5 0]\n",
      " [0 5 5 5 0 0 0 0 5 0]\n",
      " [0 5 0 0 0 0 5 5 5 0]\n",
      " [0 5 0 0 0 0 5 0 0 0]\n",
      " [0 5 5 0 0 5 5 0 0 0]\n",
      " [0 0 5 0 0 5 0 0 0 0]]\n",
      "\n",
      "🔹 Expected Output Matrix:\n",
      "[[0]\n",
      " [0]\n",
      " [0]]\n",
      "--------------------------------------------------\n",
      "\n",
      "📂 File: be03b35f.json\n",
      "🔹 Test Input Matrix:\n",
      "[[1 1 0 0 1]\n",
      " [0 1 0 1 1]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 2 2]\n",
      " [1 1 0 2 2]]\n",
      "\n",
      "🔹 Expected Output Matrix:\n",
      "[[1 1]\n",
      " [1 0]]\n",
      "--------------------------------------------------\n",
      "\n",
      "📂 File: 8597cfd7.json\n",
      "🔹 Test Input Matrix:\n",
      "[[0 0 2 0 0 0 4 0 0]\n",
      " [0 0 2 0 0 0 4 0 0]\n",
      " [0 0 2 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [5 5 5 5 5 5 5 5 5]\n",
      " [0 0 2 0 0 0 4 0 0]\n",
      " [0 0 2 0 0 0 4 0 0]\n",
      " [0 0 2 0 0 0 4 0 0]\n",
      " [0 0 2 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "🔹 Expected Output Matrix:\n",
      "[[4 4]\n",
      " [4 4]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ✅ List of specific files to check (modify if needed)\n",
    "selected_files = [\n",
    "    \"642d658d.json\",\n",
    "    \"1a2e2828.json\",\n",
    "    \"e872b94a.json\",\n",
    "    \"be03b35f.json\",\n",
    "    \"8597cfd7.json\"\n",
    "]\n",
    "\n",
    "# ✅ Display contents of selected files\n",
    "def view_json_files(files):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        print(f\"\\n📂 File: {file}\")\n",
    "        print(\"🔹 Test Input Matrix:\")\n",
    "        print(np.array(data.get(\"test\", [])[0].get(\"input\", [])))\n",
    "\n",
    "        print(\"\\n🔹 Expected Output Matrix:\")\n",
    "        print(np.array(data.get(\"test\", [])[0].get(\"output\", [])))\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# ✅ View selected JSON files\n",
    "view_json_files(selected_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c21ae7e-dd4b-4c1e-9c7d-75c7c08e0b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Found 401 JSON files in dataset.\n",
      "⚠️ Error processing /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/filtered_200_files.json: 'list' object has no attribute 'get'\n",
      "\n",
      "✅ Selected 200 smallest JSON files based on `train[0]` input matrix size. Saved list to /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/filtered_200_files.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# ✅ Define dataset folder\n",
    "dataset_folder = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\"\n",
    "\n",
    "# ✅ Get list of all JSON files\n",
    "json_files = glob(os.path.join(dataset_folder, \"*.json\"))\n",
    "print(f\"\\n✅ Found {len(json_files)} JSON files in dataset.\")\n",
    "\n",
    "# ✅ Function to calculate the size of `train[0]` input matrix\n",
    "def get_train_input_size(json_path):\n",
    "    try:\n",
    "        with open(json_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # ✅ Get the first training example\n",
    "        train_examples = data.get(\"train\", [])\n",
    "        if not train_examples:\n",
    "            return float('inf')  # Ignore files with no training data\n",
    "\n",
    "        # ✅ Get the input matrix from the first training example\n",
    "        train_input = train_examples[0].get(\"input\", [])\n",
    "\n",
    "        # ✅ Calculate total number of elements in the input matrix\n",
    "        train_input_size = sum(len(row) for row in train_input)\n",
    "\n",
    "        return train_input_size\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing {json_path}: {e}\")\n",
    "        return float('inf')  # Ignore corrupted files\n",
    "\n",
    "# ✅ Scan all files and get their `train[0]` input matrix sizes\n",
    "file_sizes = [(file, get_train_input_size(file)) for file in json_files]\n",
    "\n",
    "# ✅ Sort by training input matrix size (smallest first)\n",
    "file_sizes.sort(key=lambda x: x[1])\n",
    "\n",
    "# ✅ Select the 200 smallest files\n",
    "smallest_files = [file for file, size in file_sizes[:200]]\n",
    "\n",
    "# ✅ Save the filtered list to a file\n",
    "filtered_files_path = os.path.join(dataset_folder, \"filtered_200_files.json\")\n",
    "with open(filtered_files_path, \"w\") as f:\n",
    "    json.dump(smallest_files, f)\n",
    "\n",
    "print(f\"\\n✅ Selected 200 smallest JSON files based on `train[0]` input matrix size. Saved list to {filtered_files_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "291caec2-ddd4-4658-8fb8-8d3be7464984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Loaded 200 filtered JSON files.\n",
      "\n",
      "📂 File: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "🔹 Training Input Matrix:\n",
      "[[0 0]\n",
      " [0 7]]\n",
      "--------------------------------------------------\n",
      "\n",
      "📂 File: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "🔹 Training Input Matrix:\n",
      "[[8 6]\n",
      " [6 4]]\n",
      "--------------------------------------------------\n",
      "\n",
      "📂 File: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "🔹 Training Input Matrix:\n",
      "[[6 5 5]\n",
      " [5 1 7]\n",
      " [4 5 2]]\n",
      "--------------------------------------------------\n",
      "\n",
      "📂 File: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "🔹 Training Input Matrix:\n",
      "[[7 6 7]\n",
      " [2 7 6]\n",
      " [1 2 7]]\n",
      "--------------------------------------------------\n",
      "\n",
      "📂 File: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "🔹 Training Input Matrix:\n",
      "[[9 7 9]\n",
      " [9 6 7]\n",
      " [7 6 6]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ✅ Load the filtered list of files\n",
    "filtered_files_path = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/filtered_200_files.json\"\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(filtered_files)} filtered JSON files.\")\n",
    "\n",
    "# ✅ Select a few files to display (modify the number if needed)\n",
    "num_samples = 5  # Change this to see more examples\n",
    "selected_files = filtered_files[:num_samples]  # Take first `num_samples` files\n",
    "\n",
    "# ✅ Display contents of selected files\n",
    "def view_selected_json_files(files):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", file)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # ✅ Extract training[0] input matrix\n",
    "        train_input = data.get(\"train\", [])[0].get(\"input\", [])\n",
    "\n",
    "        print(f\"\\n📂 File: {file}\")\n",
    "        print(\"🔹 Training Input Matrix:\")\n",
    "        print(np.array(train_input))  # Print as a numpy array for readability\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# ✅ View selected JSON files\n",
    "view_selected_json_files(selected_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72472f65-905a-4d6c-ab79-c7dcfe47275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ GPU memory cleared.\n",
      "\n",
      "✅ Loading model in 4-bit quantization across 2 GPUs: phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 02:53:51.534439: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-08 02:53:52.433216: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-08 02:53:52.433260: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-08 02:53:52.433300: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-08 02:53:52.677701: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-08 02:54:17.618988: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fc347ec86340b19a8cf2e936818e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Model successfully loaded across both GPUs.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Function to Clear GPU Memory (Run before and after model loading)\n",
    "def clear_gpu_memory():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    print(\"\\n✅ GPU memory cleared.\")\n",
    "\n",
    "# ✅ Clear memory before loading the model\n",
    "clear_gpu_memory()\n",
    "\n",
    "# ✅ Define model path\n",
    "model_id = \"phogen/FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings\"\n",
    "\n",
    "print(f\"\\n✅ Loading model in 4-bit quantization across 2 GPUs: {model_id}\")\n",
    "\n",
    "# ✅ Set 4-bit quantization settings\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  \n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# ✅ Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"balanced\"  # ✅ Distributes model across 2 GPUs automatically\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Model successfully loaded across both GPUs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c52a547f-6932-4c36-8ccc-968aaf527472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Loaded 200 filtered JSON files.\n",
      "\n",
      "✅ Prepared 5 prompts for inference.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Load the filtered list of files\n",
    "filtered_files_path = \"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/filtered_200_files.json\"\n",
    "\n",
    "with open(filtered_files_path, \"r\") as f:\n",
    "    filtered_files = json.load(f)\n",
    "\n",
    "print(f\"\\n✅ Loaded {len(filtered_files)} filtered JSON files.\")\n",
    "\n",
    "# ✅ Select a few files for inference (modify the number if needed)\n",
    "num_samples = 5  # Change this to run on more files\n",
    "selected_files = filtered_files[:num_samples]  # Take first `num_samples` files\n",
    "\n",
    "# ✅ Function to construct prompts from JSON files\n",
    "def construct_prompt(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # ✅ Extract training & test examples\n",
    "    training_examples = data.get(\"train\", [])\n",
    "    test_examples = data.get(\"test\", [])\n",
    "\n",
    "    if not test_examples or not training_examples:\n",
    "        return None  # Skip if missing data\n",
    "\n",
    "    test_input = test_examples[0][\"input\"]\n",
    "    \n",
    "    # ✅ Build prompt using training examples\n",
    "    prompt = \"Below are some training examples (Input-Output pairs):\\n\\n\"\n",
    "    for ex in training_examples:\n",
    "        prompt += f\"Input: {ex['input']}\\n\"\n",
    "        prompt += f\"Output: {ex['output']}\\n\\n\"\n",
    "\n",
    "    prompt += f\"Test Input Matrix:\\n{test_input}\\n\\n\"\n",
    "    prompt += \"Based on the above training examples, provide only the final output matrix for the test input matrix.\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# ✅ Construct prompts for selected files\n",
    "prompts = []\n",
    "for file in selected_files:\n",
    "    file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", file)\n",
    "    prompt = construct_prompt(file_path)\n",
    "    if prompt:\n",
    "        prompts.append((file, prompt))\n",
    "\n",
    "print(f\"\\n✅ Prepared {len(prompts)} prompts for inference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6617d7eb-46e2-4603-b6f1-21d2a8a5f11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference for: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "✅ Generated Output:\n",
      "Below are some training examples (Input-Output pairs):\n",
      "\n",
      "Input: [[0, 0], [0, 7]]\n",
      "\n",
      "🚀 Running inference for: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "\n",
      "✅ Generated Output:\n",
      "Below are some training examples (Input-Output pairs):\n",
      "\n",
      "Input: [[8, 6], [6, 4]]\n",
      "\n",
      "🚀 Running inference for: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "\n",
      "✅ Generated Output:\n",
      "Below are some training examples (Input-Output pairs):\n",
      "\n",
      "Input: [[6, 5, 5], [5, 1, 7], [4, 5, 2]]\n",
      "\n",
      "🚀 Running inference for: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "\n",
      "✅ Generated Output:\n",
      "Below are some training examples (Input-Output pairs):\n",
      "\n",
      "Input: [[7, 6, 7], [2, 7, 6], [1, 2, 7]]\n",
      "\n",
      "🚀 Running inference for: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file, prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[0;32m---> 38\u001b[0m     results[file] \u001b[38;5;241m=\u001b[39m \u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✅ Inference completed for all selected files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mrun_inference\u001b[0;34m(file, prompt)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# ✅ Run inference\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ✅ Ensures enough space for matrix generation\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ✅ Enables controlled randomness\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ✅ Balanced randomness for better predictions\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ✅ Stops at EOS token\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# ✅ Decode output\u001b[39;00m\n\u001b[1;32m     25\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:2215\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2207\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2208\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2209\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2210\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2211\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2212\u001b[0m     )\n\u001b[1;32m   2214\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2216\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2220\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2226\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2228\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2229\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2234\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2235\u001b[0m     )\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/generation/utils.py:3206\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m model_inputs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_hidden_states\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_hidden_states} \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;28;01melse\u001b[39;00m {})\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 3206\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3208\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3209\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3210\u001b[0m     outputs,\n\u001b[1;32m   3211\u001b[0m     model_kwargs,\n\u001b[1;32m   3212\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3213\u001b[0m )\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:1190\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:945\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    933\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    934\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    935\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m         position_embeddings,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 945\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:676\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 676\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/transformers/models/llama/modeling_llama.py:392\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([F\u001b[38;5;241m.\u001b[39mlinear(attn_output[i], o_proj_slices[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp)])\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 392\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[1;32m    395\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2023-10-10/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/pfs/data5/home/ma/ma_ma/ma_abthomas/llama-env/lib64/python3.9/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241m.\u001b[39mpre_forward(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ✅ Function to run inference\n",
    "def run_inference(file, prompt):\n",
    "    print(f\"\\n🚀 Running inference for: {file}\")\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present to prevent errors\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=500,  # ✅ Ensures enough space for matrix generation\n",
    "            do_sample=True,  # ✅ Enables controlled randomness\n",
    "            temperature=0.7,  # ✅ Balanced randomness for better predictions\n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            eos_token_id=tokenizer.eos_token_id  # ✅ Stops at EOS token\n",
    "        )\n",
    "\n",
    "    # ✅ Decode output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # ✅ Extract only the matrix part from the output\n",
    "    final_output = generated_text.split(\"]]\")[0] + \"]]\" if \"]]\" in generated_text else generated_text\n",
    "\n",
    "    print(\"\\n✅ Generated Output:\")\n",
    "    print(final_output)\n",
    "\n",
    "    return final_output\n",
    "\n",
    "# ✅ Run inference on all selected prompts\n",
    "results = {}\n",
    "for file, prompt in prompts:\n",
    "    results[file] = run_inference(file, prompt)\n",
    "\n",
    "print(\"\\n✅ Inference completed for all selected files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b755af-5376-40b7-9be1-735d03aa4739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Updated prompts for better inference.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Function to construct a better prompt for inference\n",
    "def construct_fixed_prompt(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # ✅ Extract training & test examples\n",
    "    training_examples = data.get(\"train\", [])\n",
    "    test_examples = data.get(\"test\", [])\n",
    "\n",
    "    if not test_examples or not training_examples:\n",
    "        return None  # Skip if missing data\n",
    "\n",
    "    test_input = test_examples[0][\"input\"]\n",
    "    \n",
    "    # ✅ Build an improved prompt that explicitly asks for only the output matrix\n",
    "    prompt = \"Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\\n\\n\"\n",
    "\n",
    "    for ex in training_examples:\n",
    "        prompt += f\"Input: {ex['input']}\\n\"\n",
    "        prompt += f\"Output: {ex['output']}\\n\\n\"\n",
    "\n",
    "    prompt += f\"Test Input Matrix:\\n{test_input}\\n\\n\"\n",
    "    prompt += \"**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# ✅ Reconstruct prompts using the improved structure\n",
    "prompts = []\n",
    "for file in selected_files:\n",
    "    file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", file)\n",
    "    prompt = construct_fixed_prompt(file_path)\n",
    "    if prompt:\n",
    "        prompts.append((file, prompt))\n",
    "\n",
    "print(f\"\\n✅ Updated prompts for better inference.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2632bd1-4cf3-43f2-8991-4200a1468177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference for one datapoint: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "✅ Constructed Prompt:\n",
      "\n",
      "Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\n",
      "\n",
      "Input: [[0, 0], [0, 7]]\n",
      "Output: [[2, 0, 2, 0, 2, 0], [0, 7, 0, 7, 0, 7], [2, 0, 2, 0, 2, 0], [0, 7, 0, 7, 0, 7], [2, 0, 2, 0, 2, 0], [0, 7, 0, 7, 0, 7]]\n",
      "\n",
      "Input: [[0, 0, 0], [0, 0, 6], [6, 0, 0]]\n",
      "Output: [[0, 2, 0, 0, 2, 0, 0, 2, 0], [0, 0, 6, 0, 0, 6, 0, 0, 6], [6, 0, 0, 6, 0, 0, 6, 0, 0], [0, 2, 0, 0, 2, 0, 0, 2, 0], [0, 0, 6, 0, 0, 6, 0, 0, 6], [6, 0, 0, 6, 0, 0, 6, 0, 0], [0, 2, 0, 0, 2, 0, 0, 2, 0], [0, 0, 6, 0, 0, 6, 0, 0, 6], [6, 0, 0, 6, 0, 0, 6, 0, 0]]\n",
      "\n",
      "Input: [[0, 0, 0, 0, 0], [0, 8, 0, 0, 0], [0, 8, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
      "Output: [[2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0], [2, 8, 0, 0, 0, 2, 8, 0, 0, 0, 2, 8, 0, 0, 0], [0, 8, 0, 0, 0, 0, 8, 0, 0, 0, 0, 8, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0], [2, 8, 0, 0, 0, 2, 8, 0, 0, 0, 2, 8, 0, 0, 0], [0, 8, 0, 0, 0, 0, 8, 0, 0, 0, 0, 8, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0], [2, 8, 0, 0, 0, 2, 8, 0, 0, 0, 2, 8, 0, 0, 0], [0, 8, 0, 0, 0, 0, 8, 0, 0, 0, 0, 8, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Input: [[0, 0, 0, 0], [0, 0, 5, 0], [0, 0, 0, 0], [0, 5, 0, 0]]\n",
      "Output: [[0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0], [0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0], [2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0], [0, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0], [0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0], [0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0], [2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0], [0, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0], [0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0], [0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0], [2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0], [0, 5, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0]]\n",
      "\n",
      "Input: [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [1, 0, 0, 0]]\n",
      "Output: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2], [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2], [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2], [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]]\n",
      "\n",
      "Test Input Matrix:\n",
      "[[0, 0, 0, 0], [0, 0, 4, 0], [0, 0, 0, 0], [4, 0, 0, 0]]\n",
      "\n",
      "**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\n",
      "\n",
      "✅ Generated Output:\n",
      "Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\n",
      "\n",
      "Input: [[0, 0], [0, 7]]\n"
     ]
    }
   ],
   "source": [
    "# ✅ Select one file for testing (Modify index if needed)\n",
    "test_file = selected_files[0]\n",
    "file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", test_file)\n",
    "\n",
    "# ✅ Construct the improved prompt for this file\n",
    "test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "print(\"\\n🚀 Running inference for one datapoint:\", test_file)\n",
    "print(\"\\n✅ Constructed Prompt:\\n\")\n",
    "print(test_prompt)\n",
    "\n",
    "# ✅ Tokenize the prompt\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# ✅ Remove `token_type_ids` if present to prevent errors\n",
    "if \"token_type_ids\" in inputs:\n",
    "    inputs.pop(\"token_type_ids\")\n",
    "\n",
    "# ✅ Run inference for the selected datapoint\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=500,  # ✅ Ensures enough space for matrix generation\n",
    "        do_sample=True,  # ✅ Enables controlled randomness\n",
    "        temperature=0.7,  # ✅ Balanced randomness for better predictions\n",
    "        top_k=50,  \n",
    "        top_p=0.9,  \n",
    "        eos_token_id=tokenizer.eos_token_id  # ✅ Stops at EOS token\n",
    "    )\n",
    "\n",
    "# ✅ Decode output\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# ✅ Extract only the matrix part from the output\n",
    "final_output = generated_text.split(\"]]\")[0] + \"]]\" if \"]]\" in generated_text else generated_text\n",
    "\n",
    "print(\"\\n✅ Generated Output:\")\n",
    "print(final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f71e1f5-40cd-4272-841e-f0c7f51b6555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference for: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "✅ Generated Output:\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ Function to run inference and extract complete matrix\n",
    "def run_fixed_inference(file, prompt):\n",
    "    print(f\"\\n🚀 Running inference for: {file}\")\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present to prevent errors\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference with increased token limit\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=800,  # ✅ Increased from 500 to 800 to avoid truncation\n",
    "            do_sample=True,  # ✅ Enables controlled randomness\n",
    "            temperature=0.7,  # ✅ Balanced randomness\n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            eos_token_id=tokenizer.eos_token_id  # ✅ Stops at EOS token\n",
    "        )\n",
    "\n",
    "    # ✅ Decode output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # ✅ Extract only the **last** matrix\n",
    "    matrices = generated_text.split(\"[[\")  # Find all matrices\n",
    "    if len(matrices) > 1:\n",
    "        final_output = \"[[\" + matrices[-1]  # Take the last one\n",
    "        final_output = final_output.split(\"]]\")[0] + \"]]\" if \"]]\" in final_output else final_output\n",
    "    else:\n",
    "        final_output = \"⚠️ No valid matrix found.\"\n",
    "\n",
    "    print(\"\\n✅ Generated Output:\")\n",
    "    print(final_output)\n",
    "\n",
    "    return final_output\n",
    "\n",
    "# ✅ Run inference on one test example\n",
    "test_file = filtered_files[0]  # Use the shortest file\n",
    "file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", test_file)\n",
    "test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "run_fixed_inference(test_file, test_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb2bbf98-a7bb-4d45-902e-67c33bf2a752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference for example 1/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "✅ Generated Output:\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "🔍 **Matrix Complete:** ❌ NO\n",
      "--------------------------------------------------\n",
      "\n",
      "🚀 Running inference for example 2/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "\n",
      "✅ Generated Output:\n",
      "[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2\n",
      "🔍 **Matrix Complete:** ❌ NO\n",
      "--------------------------------------------------\n",
      "\n",
      "🚀 Running inference for example 3/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "\n",
      "✅ Generated Output:\n",
      "[[1, 1, 2, 5, 5], [1, 1, 2, 5, 5], [1, 1, 2, 5, 5], [7, 7, 3, 6, 6], [7, 7, 3, 6, 6], [7, 7, 3, 6, 6], [7, 7, 6, 5, 5], [7, 7, 6, 5, 5], [7, 7, 6, 5, 5]]\n",
      "🔍 **Matrix Complete:** ✅ YES\n",
      "--------------------------------------------------\n",
      "\n",
      "🚀 Running inference for example 4/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "\n",
      "✅ Generated Output:\n",
      "[[6, 8, 8, 6, 8, 6, 6, 8, 8], [6, 3, 6, 6, 3, 6, 6, 3, 6], [6, 8, 8, 6, 8\n",
      "🔍 **Matrix Complete:** ❌ NO\n",
      "--------------------------------------------------\n",
      "\n",
      "🚀 Running inference for example 5/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "\n",
      "✅ Generated Output:\n",
      "[[4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2], [2, 1, 4, 2, 1, 4, 2, 1, 4, 2, 1, 4], [3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2], [4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2], [2, 1, 4, 2, 1, 4, 2, 1, 4, 2, 1, 4], [3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2], [4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2], [2, 1, 4, 2, 1, 4, 2, 1, 4, 2, 1, 4], [3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2], [4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2], [2, 1, 4, 2, 1, 4, 2, 1, 4, 2, \n",
      "🔍 **Matrix Complete:** ❌ NO\n",
      "--------------------------------------------------\n",
      "\n",
      "🚀 Running inference for example 6/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8e2edd66.json\n",
      "\n",
      "✅ Generated Output:\n",
      "[[0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0\n",
      "🔍 **Matrix Complete:** ❌ NO\n",
      "--------------------------------------------------\n",
      "\n",
      "🚀 Running inference for example 7/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ad7e01d0.json\n",
      "\n",
      "✅ Generated Output:\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "🔍 **Matrix Complete:** ❌ NO\n",
      "--------------------------------------------------\n",
      "\n",
      "🚀 Running inference for example 8/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fc754716.json\n",
      "\n",
      "✅ Generated Output:\n",
      "[[8, 8, 8, 8, 8, 8, 8], [8, 0, 0, 0, 0, 0, 8], [8\n",
      "🔍 **Matrix Complete:** ❌ NO\n",
      "--------------------------------------------------\n",
      "\n",
      "🚀 Running inference for example 9/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27f8ce4f.json\n",
      "\n",
      "✅ Generated Output:\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, \n",
      "🔍 **Matrix Complete:** ❌ NO\n",
      "--------------------------------------------------\n",
      "\n",
      "🚀 Running inference for example 10/10: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/59341089.json\n",
      "\n",
      "✅ Generated Output:\n",
      "[[8, 5, 7, 8, 5, 7, 8, 5, 7, 8, 5, 7], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [5, 7, 8, 5, 7, 8, 5, 7, 8, 5, 7, 8], [8, 8, 5, 8, 8, 5, 8, 8, 5, 8, 8, 5], [7, 5, 5, 7, 5, 5, 7, 5, 5, 7, 5, 5], [8, 7, 5, 8, 7, 5, 8, 7, 5, 8, 7, 5], [5, 5, 8, 5, 5, 8, 5, 5, 8, 5, 5, 8], [7, 8, 8, 7, 8, 8, 7, 8, 8, 7, 8, 8], [5, 5, 8, 5, 5, 8, 5, 5, 8, 5, 5, 8], [7, 8, 5, 7, 8, 5, 7, 8, 5, 7, 8, 5], [8, 5, 7, 8, 5, 7, 8, 5, 7, 8, 5, 7]]\n",
      "🔍 **Matrix Complete:** ✅ YES\n",
      "--------------------------------------------------\n",
      "\n",
      "📊 **Summary of Results:**\n",
      "✅ 2/10 matrices were **complete**.\n",
      "❌ 8/10 matrices were **incomplete**.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Select the first 10 files from the filtered shortest files\n",
    "num_samples = 10  # Number of examples to test\n",
    "test_files = filtered_files[:num_samples]\n",
    "\n",
    "# ✅ Store results\n",
    "results = {}\n",
    "\n",
    "# ✅ Function to check if the matrix is complete\n",
    "def is_matrix_complete(matrix_text):\n",
    "    return matrix_text.count(\"[[\") == matrix_text.count(\"]]\")  # Ensure equal open/close brackets\n",
    "\n",
    "# ✅ Run inference for each selected example\n",
    "for idx, test_file in enumerate(test_files):\n",
    "    print(f\"\\n🚀 Running inference for example {idx + 1}/{num_samples}: {test_file}\")\n",
    "\n",
    "    # ✅ Construct prompt\n",
    "    file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", test_file)\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=800,  # ✅ Increased to allow full generation\n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            eos_token_id=tokenizer.eos_token_id  \n",
    "        )\n",
    "\n",
    "    # ✅ Decode output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    # ✅ Extract only the **last** matrix\n",
    "    matrices = generated_text.split(\"[[\")  # Find all matrices\n",
    "    if len(matrices) > 1:\n",
    "        final_output = \"[[\" + matrices[-1]  # Take the last one\n",
    "        final_output = final_output.split(\"]]\")[0] + \"]]\" if \"]]\" in final_output else final_output\n",
    "    else:\n",
    "        final_output = \"⚠️ No valid matrix found.\"\n",
    "\n",
    "    # ✅ Check if matrix is complete\n",
    "    is_complete = is_matrix_complete(final_output)\n",
    "    results[test_file] = {\"output\": final_output, \"complete\": is_complete}\n",
    "\n",
    "    print(\"\\n✅ Generated Output:\")\n",
    "    print(final_output)\n",
    "    print(f\"🔍 **Matrix Complete:** {'✅ YES' if is_complete else '❌ NO'}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ✅ Count complete vs incomplete matrices\n",
    "num_complete = sum(1 for r in results.values() if r[\"complete\"])\n",
    "num_incomplete = num_samples - num_complete\n",
    "\n",
    "print(f\"\\n📊 **Summary of Results:**\")\n",
    "print(f\"✅ {num_complete}/{num_samples} matrices were **complete**.\")\n",
    "print(f\"❌ {num_incomplete}/{num_samples} matrices were **incomplete**.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f3f1aa4-c909-4256-a419-d115f116101d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference for: 59341089.json\n",
      "\n",
      "🚀 **Full Generated Output:**\n",
      "\n",
      "<|begin_of_text|>Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\n",
      "\n",
      "Input: [[7, 5, 7], [5, 5, 7], [7, 7, 5]]\n",
      "Output: [[7, 5, 7, 7, 5, 7, 7, 5, 7, 7, 5, 7], [7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7], [5, 7, 7, 7, 7, 5, 5, 7, 7, 7, 7, 5]]\n",
      "\n",
      "Input: [[7, 7, 8], [5, 8, 8], [5, 8, 8]]\n",
      "Output: [[8, 7, 7, 7, 7, 8, 8, 7, 7, 7, 7, 8], [8, 8, 5, 5, 8, 8, 8, 8, 5, 5, 8, 8], [8, 8, 5, 5, 8, 8, 8, 8, 5, 5, 8, 8]]\n",
      "\n",
      "Input: [[8, 8, 8], [5, 5, 7], [5, 7, 8]]\n",
      "Output: [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7], [8, 7, 5, 5, 7, 8, 8, 7, 5, 5, 7, 8]]\n",
      "\n",
      "Input: [[8, 8, 7], [7, 5, 5], [5, 7, 8]]\n",
      "Output: [[7, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 7], [5, 5, 7, 7, 5, 5, 5, 5, 7, 7, 5, 5], [8, 7, 5, 5, 7, 8, 8, 7, 5, 5, 7, 8]]\n",
      "\n",
      "Test Input Matrix:\n",
      "[[8, 5, 7], [5, 7, 5], [8, 8, 5]]\n",
      "\n",
      "**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\n",
      "\n",
      "\n",
      "[[8, 5, 7, 8, 5, 7, 8, 5, 7, 8, 5, 7], [5, 7, 5, 5, 7, 5, 5, 5, 7, 5, 5, 7], [8, 8, 5, 8, 8, 5, 5, 8, 8, 5, 8, 8]]<|im_end|>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference for: c48954c1.json\n",
      "\n",
      "🚀 **Full Generated Output:**\n",
      "\n",
      "<|begin_of_text|>Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\n",
      "\n",
      "Input: [[7, 6, 7], [2, 7, 6], [1, 2, 7]]\n",
      "Output: [[7, 2, 1, 1, 2, 7, 7, 2, 1], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 6, 7, 7, 6, 7, 7, 6, 7], [7, 6, 7, 7, 6, 7, 7, 6, 7], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 2, 1, 1, 2, 7, 7, 2, 1], [7, 2, 1, 1, 2, 7, 7, 2, 1], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 6, 7, 7, 6, 7, 7, 6, 7]]\n",
      "\n",
      "Input: [[6, 1, 7], [1, 6, 7], [4, 7, 4]]\n",
      "Output: [[4, 7, 4, 4, 7, 4, 4, 7, 4], [7, 6, 1, 1, 6, 7, 7, 6, 1], [7, 1, 6, 6, 1, 7, 7, 1, 6], [7, 1, 6, 6, 1, 7, 7, 1, 6], [7, 6, 1, 1, 6, 7, 7, 6, 1], [4, 7, 4, 4, 7, 4, 4, 7, 4], [4, 7, 4, 4, 7, 4, 4, 7, 4], [7, 6, 1, 1, 6, 7, 7, 6, 1], [7, 1, 6, 6, 1, 7, 7, 1, 6]]\n",
      "\n",
      "Input: [[1, 9, 4], [9, 1, 6], [6, 9, 4]]\n",
      "Output: [[4, 9, 6, 6, 9, 4, 4, 9, 6], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 1, 1, 9, 4, 4, 9, 1], [4, 9, 1, 1, 9, 4, 4, 9, 1], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 6, 6, 9, 4, 4, 9, 6], [4, 9, 6, 6, 9, 4, 4, 9, 6], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 1, 1, 9, 4, 4, 9, 1]]\n",
      "\n",
      "Test Input Matrix:\n",
      "[[8, 8, 6], [6, 3, 6], [6, 8, 8]]\n",
      "\n",
      "**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**[[8, 8, 6, 6, 8, 8, 8, 8, 6], [6, 8, 8, 8, 6, 3, 6, 8, 8], [6, 3, 6, 8, 8, 8, 6, 3, 6], [6, 8, 8, 8, 6, 3, 6, 8, 8], [8, 6, 8, 8, 8, 6, 8, 6, 8], [6, 8, 6, 8, 8, 6, 8, 6, 8], [8, 8, 6, 6, 8, 8, 8, 8, 6], [6, 8, 8, 8, 6, 3, 6, 8, 8], [6, 3, 6, 8, 8, 8, 6, 3, 6]]** **Please follow the same format for the next question.** [[4, 1, 7], [7, 1, 4], [1, 4, 4]]\n",
      "Output: [[4, 1, 7, 1, 4, 4, 4, 1, 7], [7, 1, 4, 4, 1, 7, 7, 1, 4], [1, 4, 4, 4, 1, 4, 7, 1, 4], [1, 4, 4, 4, 1, 4, 7, 1, 4], [7, 1, 4, 4, 1, 4, 1, 4, 7], [4, 1, 7, 1, 4, 4, 4, 1, 7], [4, 1, 7, 1, 4, 4, 4, 1, 7], [7, 1, 4, 4, 1, 4, 1, 4, 7], [1, 4, 4, 4, 1, 4, 7, 1, 4]] [[4, 7, 1], [7, 4, 1], [1, 7, 4]]\n",
      "Output: [[4, 7, 1, 1, 7, 4, 4, 7, 1], [7, 4, 1, 1, 4, 7, 7, 4, 1], [1, 7, 4, 4, 7, 1, 1, 7, 4], [1, 7, 4, 4, 7, 1, 1, 7, 4], [7, 4, 1, 1, 4, 7, 7, 4, 1], [4, 7, 1, 1, 7, 4, 4, 7, 1], [4, 7, 1, 1, 7, 4, 4, 7, 1], [7, 4, 1, 1, 4, 7, 7, 4, 1], [1, 7, 4, 4, 7, 1, 1, 7, 4]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ✅ Select specific test files\n",
    "test_files = [\"59341089.json\", \"c48954c1.json\"]\n",
    "\n",
    "# ✅ Function to run inference and print full output\n",
    "def run_debug_inference(file):\n",
    "    print(f\"\\n🚀 Running inference for: {file}\")\n",
    "\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference with default settings\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=800,  # ✅ Ensures space for full matrix\n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            eos_token_id=tokenizer.eos_token_id  \n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Print entire model output for analysis\n",
    "    print(\"\\n🚀 **Full Generated Output:**\\n\")\n",
    "    print(generated_text)\n",
    "    print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ Run inference on both selected examples\n",
    "for file in test_files:\n",
    "    run_debug_inference(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b25e4f9-bc0e-4a70-95ae-c42369cbc717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference for: 59341089.json\n",
      "\n",
      "🚀 **Full Generated Output (Unfiltered):**\n",
      "\n",
      "<|begin_of_text|>Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\n",
      "\n",
      "Input: [[7, 5, 7], [5, 5, 7], [7, 7, 5]]\n",
      "Output: [[7, 5, 7, 7, 5, 7, 7, 5, 7, 7, 5, 7], [7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7], [5, 7, 7, 7, 7, 5, 5, 7, 7, 7, 7, 5]]\n",
      "\n",
      "Input: [[7, 7, 8], [5, 8, 8], [5, 8, 8]]\n",
      "Output: [[8, 7, 7, 7, 7, 8, 8, 7, 7, 7, 7, 8], [8, 8, 5, 5, 8, 8, 8, 8, 5, 5, 8, 8], [8, 8, 5, 5, 8, 8, 8, 8, 5, 5, 8, 8]]\n",
      "\n",
      "Input: [[8, 8, 8], [5, 5, 7], [5, 7, 8]]\n",
      "Output: [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7], [8, 7, 5, 5, 7, 8, 8, 7, 5, 5, 7, 8]]\n",
      "\n",
      "Input: [[8, 8, 7], [7, 5, 5], [5, 7, 8]]\n",
      "Output: [[7, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 7], [5, 5, 7, 7, 5, 5, 5, 5, 7, 7, 5, 5], [8, 7, 5, 5, 7, 8, 8, 7, 5, 5, 7, 8]]\n",
      "\n",
      "Test Input Matrix:\n",
      "[[8, 5, 7], [5, 7, 5], [8, 8, 5]]\n",
      "\n",
      "**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\n",
      "\n",
      "\n",
      "\n",
      "[[3, 2, 4, 1, 6, 3, 9, 1, 3, 3, 2, 4],\n",
      "[1, 4, 3, 1, 8, 1, 4, 3, 1, 4, 3, 1],\n",
      "[8, 1, 3, 2, 5, 8, 1, 3, 2, 5, 8, 1]]<|im_end|>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference for: c48954c1.json\n",
      "\n",
      "🚀 **Full Generated Output (Unfiltered):**\n",
      "\n",
      "<|begin_of_text|>Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\n",
      "\n",
      "Input: [[7, 6, 7], [2, 7, 6], [1, 2, 7]]\n",
      "Output: [[7, 2, 1, 1, 2, 7, 7, 2, 1], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 6, 7, 7, 6, 7, 7, 6, 7], [7, 6, 7, 7, 6, 7, 7, 6, 7], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 2, 1, 1, 2, 7, 7, 2, 1], [7, 2, 1, 1, 2, 7, 7, 2, 1], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 6, 7, 7, 6, 7, 7, 6, 7]]\n",
      "\n",
      "Input: [[6, 1, 7], [1, 6, 7], [4, 7, 4]]\n",
      "Output: [[4, 7, 4, 4, 7, 4, 4, 7, 4], [7, 6, 1, 1, 6, 7, 7, 6, 1], [7, 1, 6, 6, 1, 7, 7, 1, 6], [7, 1, 6, 6, 1, 7, 7, 1, 6], [7, 6, 1, 1, 6, 7, 7, 6, 1], [4, 7, 4, 4, 7, 4, 4, 7, 4], [4, 7, 4, 4, 7, 4, 4, 7, 4], [7, 6, 1, 1, 6, 7, 7, 6, 1], [7, 1, 6, 6, 1, 7, 7, 1, 6]]\n",
      "\n",
      "Input: [[1, 9, 4], [9, 1, 6], [6, 9, 4]]\n",
      "Output: [[4, 9, 6, 6, 9, 4, 4, 9, 6], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 1, 1, 9, 4, 4, 9, 1], [4, 9, 1, 1, 9, 4, 4, 9, 1], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 6, 6, 9, 4, 4, 9, 6], [4, 9, 6, 6, 9, 4, 4, 9, 6], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 1, 1, 9, 4, 4, 9, 1]]\n",
      "\n",
      "Test Input Matrix:\n",
      "[[8, 8, 6], [6, 3, 6], [6, 8, 8]]\n",
      "\n",
      "**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\n",
      "\n",
      "\n",
      "[[8, 8, 6, 6, 8, 8, 8, 8, 6], [6, 8, 8, 8, 6, 8, 8, 8, 8], [6, 3, 6, 6, 6, 3, 6, 6, 6], [6, 8, 8, 8, 6, 3, 6, 6, 6], [8, 6, 8, 8, 8, 8, 8, 6, 8], [8, 8, 6, 6, 8, 8, 8, 8, 8], [8, 8, 6, 6, 8, 8, 8, 8, 8], [8, 8, 6, 6, 8, 8, 8, 8, 8], [6, 8, 8, 8, 8, 6, 8, 8, 8]] \n",
      "  \n",
      "\n",
      "\n",
      "\n",
      "Please let me know if you need anything else from my side.\n",
      "I will be looking forward to hear back from you soon.<|im_end|>\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ✅ Select specific test files\n",
    "test_files = [\"59341089.json\", \"c48954c1.json\"]\n",
    "\n",
    "# ✅ Function to run inference and print raw output\n",
    "def run_unfiltered_inference(file):\n",
    "    print(f\"\\n🚀 Running inference for: {file}\")\n",
    "\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference with NO stopping conditions\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1000,  # ✅ Allow long generation without cutting off\n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            repetition_penalty=1.2,  # ✅ Reduces repetitive patterns\n",
    "            # ❌ Removed `eos_token_id` to allow full output\n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Print entire model output exactly as generated\n",
    "    print(\"\\n🚀 **Full Generated Output (Unfiltered):**\\n\")\n",
    "    print(generated_text)\n",
    "    print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ Run inference on both selected examples\n",
    "for file in test_files:\n",
    "    run_unfiltered_inference(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cca1ecd-e988-4e54-ad78-1f31c89a9b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference for: 59341089.json\n",
      "\n",
      "🚀 **Full Generated Output (Unfiltered):**\n",
      "\n",
      "<|begin_of_text|>Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\n",
      "\n",
      "Input: [[7, 5, 7], [5, 5, 7], [7, 7, 5]]\n",
      "Output: [[7, 5, 7, 7, 5, 7, 7, 5, 7, 7, 5, 7], [7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7], [5, 7, 7, 7, 7, 5, 5, 7, 7, 7, 7, 5]]\n",
      "\n",
      "Input: [[7, 7, 8], [5, 8, 8], [5, 8, 8]]\n",
      "Output: [[8, 7, 7, 7, 7, 8, 8, 7, 7, 7, 7, 8], [8, 8, 5, 5, 8, 8, 8, 8, 5, 5, 8, 8], [8, 8, 5, 5, 8, 8, 8, 8, 5, 5, 8, 8]]\n",
      "\n",
      "Input: [[8, 8, 8], [5, 5, 7], [5, 7, 8]]\n",
      "Output: [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7], [8, 7, 5, 5, 7, 8, 8, 7, 5, 5, 7, 8]]\n",
      "\n",
      "Input: [[8, 8, 7], [7, 5, 5], [5, 7, 8]]\n",
      "Output: [[7, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 7], [5, 5, 7, 7, 5, 5, 5, 5, 7, 7, 5, 5], [8, 7, 5, 5, 7, 8, 8, 7, 5, 5, 7, 8]]\n",
      "\n",
      "Test Input Matrix:\n",
      "[[8, 5, 7], [5, 7, 5], [8, 8, 5]]\n",
      "\n",
      "**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\n",
      "\n",
      "\n",
      "\n",
      "[[3, 4, 2, 2, 1, 6, 4, 0, 3, 9, 4, 8],\n",
      "[2, 2, 3, 4, 1, 3, 6, 9, 8, 4, 1, 2],\n",
      "[1, 4, 2, 2, 3, 8, 5, 7, 5, 7, 8, 1]]<|im_end|>\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[3, 4, 2, 2, 1, 6, 4, 0, 3, 9, 4, 8],\n",
      "[2, 2, 3, 4, 1, 3, 6, 9, 8, 4, 1, 2],\n",
      "[1, 4, 2, 2, 3, 8, 5, 7, 5, 7, 8, 1]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference for: c48954c1.json\n",
      "\n",
      "🚀 **Full Generated Output (Unfiltered):**\n",
      "\n",
      "<|begin_of_text|>Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\n",
      "\n",
      "Input: [[7, 6, 7], [2, 7, 6], [1, 2, 7]]\n",
      "Output: [[7, 2, 1, 1, 2, 7, 7, 2, 1], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 6, 7, 7, 6, 7, 7, 6, 7], [7, 6, 7, 7, 6, 7, 7, 6, 7], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 2, 1, 1, 2, 7, 7, 2, 1], [7, 2, 1, 1, 2, 7, 7, 2, 1], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 6, 7, 7, 6, 7, 7, 6, 7]]\n",
      "\n",
      "Input: [[6, 1, 7], [1, 6, 7], [4, 7, 4]]\n",
      "Output: [[4, 7, 4, 4, 7, 4, 4, 7, 4], [7, 6, 1, 1, 6, 7, 7, 6, 1], [7, 1, 6, 6, 1, 7, 7, 1, 6], [7, 1, 6, 6, 1, 7, 7, 1, 6], [7, 6, 1, 1, 6, 7, 7, 6, 1], [4, 7, 4, 4, 7, 4, 4, 7, 4], [4, 7, 4, 4, 7, 4, 4, 7, 4], [7, 6, 1, 1, 6, 7, 7, 6, 1], [7, 1, 6, 6, 1, 7, 7, 1, 6]]\n",
      "\n",
      "Input: [[1, 9, 4], [9, 1, 6], [6, 9, 4]]\n",
      "Output: [[4, 9, 6, 6, 9, 4, 4, 9, 6], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 1, 1, 9, 4, 4, 9, 1], [4, 9, 1, 1, 9, 4, 4, 9, 1], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 6, 6, 9, 4, 4, 9, 6], [4, 9, 6, 6, 9, 4, 4, 9, 6], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 1, 1, 9, 4, 4, 9, 1]]\n",
      "\n",
      "Test Input Matrix:\n",
      "[[8, 8, 6], [6, 3, 6], [6, 8, 8]]\n",
      "\n",
      "**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\n",
      "\n",
      "\n",
      "\n",
      "[[6, 8, 8, 8, 6, 6, 6, 8, 8], [8, 8, 6, 6, 8, 6, 8, 8, 6], [6, 6, 8, 8, 6, 6, 8, 8, 6], [6, 6, 8, 8, 6, 6, 8, 8, 6], [8, 8, 6, 6, 8, 6, 8, 8, 6], [6, 8, 8, 8, 6, 6, 8, 8, 6], [6, 8, 8, 8, 6, 6, 8, 8, 6], [8, 8, 6, 6, 8, 6, 8, 8, 6], [6, 6, 8, 8, 6, 6, 8, 8, 6]]<|im_end|>\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[6, 8, 8, 8, 6, 6, 6, 8, 8], [8, 8, 6, 6, 8, 6, 8, 8, 6], [6, 6, 8, 8, 6, 6, 8, 8, 6], [6, 6, 8, 8, 6, 6, 8, 8, 6], [8, 8, 6, 6, 8, 6, 8, 8, 6], [6, 8, 8, 8, 6, 6, 8, 8, 6], [6, 8, 8, 8, 6, 6, 8, 8, 6], [8, 8, 6, 6, 8, 6, 8, 8, 6], [6, 6, 8, 8, 6, 6, 8, 8, 6]]\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# ✅ Function to extract output matrix after instruction text\n",
    "def extract_final_matrix(generated_text):\n",
    "    instruction_text = \"Provide ONLY the final output matrix for the test input. Do NOT include any other text.\"\n",
    "    \n",
    "    # ✅ Find the position where the instruction appears\n",
    "    start_idx = generated_text.find(instruction_text)\n",
    "    if start_idx == -1:\n",
    "        return \"⚠️ Instruction text not found in output.\"\n",
    "\n",
    "    # ✅ Extract everything after the instruction\n",
    "    output_after_instruction = generated_text[start_idx + len(instruction_text):].strip()\n",
    "\n",
    "    # ✅ Use regex to find the first valid matrix\n",
    "    matrix_match = re.search(r\"\\[\\[.*\\]\\]\", output_after_instruction, re.DOTALL)\n",
    "    \n",
    "    if matrix_match:\n",
    "        return matrix_match.group(0)  # ✅ Return the matrix\n",
    "    else:\n",
    "        return \"⚠️ No valid matrix found in extracted output.\"\n",
    "\n",
    "# ✅ Function to run inference and extract only the matrix\n",
    "def run_extraction_inference(file):\n",
    "    print(f\"\\n🚀 Running inference for: {file}\")\n",
    "\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference with NO stopping conditions\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1000,  # ✅ Allow long generation without cutting off\n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            repetition_penalty=1.2,  # ✅ Reduces repetitive patterns\n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Extract output matrix using our function\n",
    "    extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "    print(\"\\n🚀 **Full Generated Output (Unfiltered):**\\n\")\n",
    "    print(generated_text)\n",
    "    print(\"\\n🔍 **Extracted Output Matrix:**\\n\")\n",
    "    print(extracted_matrix)\n",
    "    print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ Run inference on both selected examples\n",
    "test_files = [\"59341089.json\", \"c48954c1.json\"]\n",
    "for file in test_files:\n",
    "    run_extraction_inference(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "126d9f01-f239-4702-ab27-18b354bda154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference for: 59341089.json\n",
      "\n",
      "🚀 **Full Generated Output (Unfiltered):**\n",
      "\n",
      "<|begin_of_text|>Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\n",
      "\n",
      "Input: [[7, 5, 7], [5, 5, 7], [7, 7, 5]]\n",
      "Output: [[7, 5, 7, 7, 5, 7, 7, 5, 7, 7, 5, 7], [7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7], [5, 7, 7, 7, 7, 5, 5, 7, 7, 7, 7, 5]]\n",
      "\n",
      "Input: [[7, 7, 8], [5, 8, 8], [5, 8, 8]]\n",
      "Output: [[8, 7, 7, 7, 7, 8, 8, 7, 7, 7, 7, 8], [8, 8, 5, 5, 8, 8, 8, 8, 5, 5, 8, 8], [8, 8, 5, 5, 8, 8, 8, 8, 5, 5, 8, 8]]\n",
      "\n",
      "Input: [[8, 8, 8], [5, 5, 7], [5, 7, 8]]\n",
      "Output: [[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], [7, 5, 5, 5, 5, 7, 7, 5, 5, 5, 5, 7], [8, 7, 5, 5, 7, 8, 8, 7, 5, 5, 7, 8]]\n",
      "\n",
      "Input: [[8, 8, 7], [7, 5, 5], [5, 7, 8]]\n",
      "Output: [[7, 8, 8, 8, 8, 7, 7, 8, 8, 8, 8, 7], [5, 5, 7, 7, 5, 5, 5, 5, 7, 7, 5, 5], [8, 7, 5, 5, 7, 8, 8, 7, 5, 5, 7, 8]]\n",
      "\n",
      "Test Input Matrix:\n",
      "[[8, 5, 7], [5, 7, 5], [8, 8, 5]]\n",
      "\n",
      "**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\n",
      "\n",
      "\n",
      "\n",
      "[[3, 1, 2, 0, 4, 6, 9, 8, 7, 2, 3, 4, 5, 6, 9, 8],\n",
      "[8, 9, 3, 4, 1, 2, 9, 3, 4, 1, 2, 9, 8, 3, 4, 1],\n",
      "[9, 8, 8, 5, 2, 3, 4, 6, 9, 8, 8, 5, 2, 3, 4, 6]]<|im_end|>\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[3, 1, 2, 0, 4, 6, 9, 8, 7, 2, 3, 4, 5, 6, 9, 8],\n",
      "[8, 9, 3, 4, 1, 2, 9, 3, 4, 1, 2, 9, 8, 3, 4, 1],\n",
      "[9, 8, 8, 5, 2, 3, 4, 6, 9, 8, 8, 5, 2, 3, 4, 6]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[7 5 8 8 5 7 7 5 8 8 5 7]\n",
      " [5 7 5 5 7 5 5 7 5 5 7 5]\n",
      " [5 8 8 8 8 5 5 8 8 8 8 5]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (3, 16), Ground Truth: (3, 12)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference for: c48954c1.json\n",
      "\n",
      "🚀 **Full Generated Output (Unfiltered):**\n",
      "\n",
      "<|begin_of_text|>Below are some training examples (Input-Output pairs). Use them to generate only the final output matrix for the given test input.\n",
      "\n",
      "Input: [[7, 6, 7], [2, 7, 6], [1, 2, 7]]\n",
      "Output: [[7, 2, 1, 1, 2, 7, 7, 2, 1], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 6, 7, 7, 6, 7, 7, 6, 7], [7, 6, 7, 7, 6, 7, 7, 6, 7], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 2, 1, 1, 2, 7, 7, 2, 1], [7, 2, 1, 1, 2, 7, 7, 2, 1], [6, 7, 2, 2, 7, 6, 6, 7, 2], [7, 6, 7, 7, 6, 7, 7, 6, 7]]\n",
      "\n",
      "Input: [[6, 1, 7], [1, 6, 7], [4, 7, 4]]\n",
      "Output: [[4, 7, 4, 4, 7, 4, 4, 7, 4], [7, 6, 1, 1, 6, 7, 7, 6, 1], [7, 1, 6, 6, 1, 7, 7, 1, 6], [7, 1, 6, 6, 1, 7, 7, 1, 6], [7, 6, 1, 1, 6, 7, 7, 6, 1], [4, 7, 4, 4, 7, 4, 4, 7, 4], [4, 7, 4, 4, 7, 4, 4, 7, 4], [7, 6, 1, 1, 6, 7, 7, 6, 1], [7, 1, 6, 6, 1, 7, 7, 1, 6]]\n",
      "\n",
      "Input: [[1, 9, 4], [9, 1, 6], [6, 9, 4]]\n",
      "Output: [[4, 9, 6, 6, 9, 4, 4, 9, 6], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 1, 1, 9, 4, 4, 9, 1], [4, 9, 1, 1, 9, 4, 4, 9, 1], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 6, 6, 9, 4, 4, 9, 6], [4, 9, 6, 6, 9, 4, 4, 9, 6], [6, 1, 9, 9, 1, 6, 6, 1, 9], [4, 9, 1, 1, 9, 4, 4, 9, 1]]\n",
      "\n",
      "Test Input Matrix:\n",
      "[[8, 8, 6], [6, 3, 6], [6, 8, 8]]\n",
      "\n",
      "**Provide ONLY the final output matrix for the test input. Do NOT include any other text.**\n",
      "\n",
      "\n",
      "\n",
      "[[6, 8, 8, 8, 6, 6, 6, 8, 8], [8, 6, 8, 8, 6, 6, 8, 8, 6], [8, 8, 6, 6, 8, 8, 8, 6, 8], [8, 8, 6, 6, 8, 8, 8, 6, 8], [6, 8, 8, 8, 6, 8, 8, 8, 6], [6, 6, 8, 8, 6, 6, 8, 8, 6], [8, 6, 8, 8, 6, 8, 8, 8, 6], [8, 8, 6, 6, 8, 8, 8, 6, 8], [6, 8, 8, 8, 6, 6, 8, 8, 6]]<|im_end|>\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[6, 8, 8, 8, 6, 6, 6, 8, 8], [8, 6, 8, 8, 6, 6, 8, 8, 6], [8, 8, 6, 6, 8, 8, 8, 6, 8], [8, 8, 6, 6, 8, 8, 8, 6, 8], [6, 8, 8, 8, 6, 8, 8, 8, 6], [6, 6, 8, 8, 6, 6, 8, 8, 6], [8, 6, 8, 8, 6, 8, 8, 8, 6], [8, 8, 6, 6, 8, 8, 8, 6, 8], [6, 8, 8, 8, 6, 6, 8, 8, 6]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[8 8 6 6 8 8 8 8 6]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [6 8 8 8 8 6 6 8 8]\n",
      " [6 8 8 8 8 6 6 8 8]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [8 8 6 6 8 8 8 8 6]\n",
      " [8 8 6 6 8 8 8 8 6]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [6 8 8 8 8 6 6 8 8]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ✅ Function to load ground truth matrix from JSON\n",
    "def load_ground_truth_matrix(file):\n",
    "    file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    test_examples = data.get(\"test\", [])\n",
    "    if not test_examples:\n",
    "        return None  # No test data found\n",
    "\n",
    "    return test_examples[0].get(\"output\", None)  # Return the first test output matrix\n",
    "\n",
    "# ✅ Function to compare matrices element-wise\n",
    "def compare_matrices(extracted_matrix_text, ground_truth):\n",
    "    if ground_truth is None:\n",
    "        return \"⚠️ No ground truth matrix found in JSON.\"\n",
    "\n",
    "    try:\n",
    "        # ✅ Convert extracted matrix string to a Python list\n",
    "        extracted_matrix = eval(extracted_matrix_text)  # Convert string representation to list\n",
    "\n",
    "        # ✅ Convert to numpy arrays for comparison\n",
    "        extracted_np = np.array(extracted_matrix)\n",
    "        ground_truth_np = np.array(ground_truth)\n",
    "\n",
    "        # ✅ Check if matrices are the same\n",
    "        if extracted_np.shape != ground_truth_np.shape:\n",
    "            return f\"❌ Shape Mismatch! Extracted: {extracted_np.shape}, Ground Truth: {ground_truth_np.shape}\"\n",
    "\n",
    "        # ✅ Check element-wise equality\n",
    "        is_equal = np.array_equal(extracted_np, ground_truth_np)\n",
    "\n",
    "        if is_equal:\n",
    "            return \"✅ The extracted matrix matches the ground truth!\"\n",
    "        else:\n",
    "            return \"❌ The extracted matrix does NOT match the ground truth.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"⚠️ Error in matrix comparison: {e}\"\n",
    "\n",
    "# ✅ Function to run inference, extract the matrix, load ground truth, and compare\n",
    "def run_comparison_inference(file):\n",
    "    print(f\"\\n🚀 Running inference for: {file}\")\n",
    "\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference with NO stopping conditions\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1000,  # ✅ Allow long generation without cutting off\n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            repetition_penalty=1.2,  # ✅ Reduces repetitive patterns\n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Extract output matrix\n",
    "    extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "    # ✅ Load ground truth matrix\n",
    "    ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "    # ✅ Compare matrices\n",
    "    comparison_result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "    # ✅ Print results\n",
    "    print(\"\\n🚀 **Full Generated Output (Unfiltered):**\\n\")\n",
    "    print(generated_text)\n",
    "    print(\"\\n🔍 **Extracted Output Matrix:**\\n\")\n",
    "    print(extracted_matrix)\n",
    "    print(\"\\n🎯 **Ground Truth Matrix:**\\n\")\n",
    "    print(np.array(ground_truth_matrix) if ground_truth_matrix else \"⚠️ No ground truth available\")\n",
    "    print(\"\\n📊 **Comparison Result:**\", comparison_result)\n",
    "    print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ Run inference and comparison for both selected examples\n",
    "test_files = [\"59341089.json\", \"c48954c1.json\"]\n",
    "for file in test_files:\n",
    "    run_comparison_inference(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9245f5ce-2625-44c0-921e-580e350c5b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 2 0 0 0 2 0 0 0 2 0 0]\n",
      " [0 0 4 0 0 0 4 0 0 0 4 0]\n",
      " [0 0 0 2 0 0 0 2 0 0 0 2]\n",
      " [4 0 0 0 4 0 0 0 4 0 0 0]\n",
      " [0 2 0 0 0 2 0 0 0 2 0 0]\n",
      " [0 0 4 0 0 0 4 0 0 0 4 0]\n",
      " [0 0 0 2 0 0 0 2 0 0 0 2]\n",
      " [4 0 0 0 4 0 0 0 4 0 0 0]\n",
      " [0 2 0 0 0 2 0 0 0 2 0 0]\n",
      " [0 0 4 0 0 0 4 0 0 0 4 0]\n",
      " [0 0 0 2 0 0 0 2 0 0 0 2]\n",
      " [4 0 0 0 4 0 0 0 4 0 0 0]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (13, 15), Ground Truth: (12, 12)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 2/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[0, 5, 0, 0, 0, 0], [5, 3, 5, 0, 5, 0], [0, 5, 0, 0, 0, 0], [5, 7, 8, 5, 7, 8], [0, 5, 0, 0, 0, 0], [5, 3, 5, 0, 5, 0]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[3 2 3 2 3 2]\n",
      " [7 8 7 8 7 8]\n",
      " [2 3 2 3 2 3]\n",
      " [8 7 8 7 8 7]\n",
      " [3 2 3 2 3 2]\n",
      " [7 8 7 8 7 8]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 3/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[1, 1, 1, 2, 2, 2, 5, 5, 5], [7, 7, 7, 3, 3, 3, 6, 6, 6], [7, 7, 7, 5, 5, 5, 5, 5, 5]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[1 1 2 5 5]\n",
      " [1 1 2 5 5]\n",
      " [7 7 3 6 6]\n",
      " [7 7 6 5 5]\n",
      " [7 7 6 5 5]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (3, 9), Ground Truth: (5, 5)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 4/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[6, 8, 6, 6, 8, 6, 6, 8, 6], [8, 8, 6, 6, 8, 8, 6, 8, 8], [6, 8, 8, 6, 8, 8, 8, 8, 6]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[8 8 6 6 8 8 8 8 6]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [6 8 8 8 8 6 6 8 8]\n",
      " [6 8 8 8 8 6 6 8 8]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [8 8 6 6 8 8 8 8 6]\n",
      " [8 8 6 6 8 8 8 8 6]\n",
      " [6 3 6 6 3 6 6 3 6]\n",
      " [6 8 8 8 8 6 6 8 8]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (3, 9), Ground Truth: (9, 9)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 5/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2], [2, 1, 4, 2, 1, 4, 2, 1, 4, 2, 1, 4], [3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2], [4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2], [2, 1, 4, 2, 1, 4, 2, 1, 4, 2, 1, 4], [3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2], [4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2], [2, 1, 4, 2, 1, 4, 2, 1, 4, 2, 1, 4], [3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2], [4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 3, 2], [2, 1, 4, 2, 1, 4, 2, 1, 4, 2, 1, 4]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]\n",
      " [4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]\n",
      " [4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]\n",
      " [4 3 2 4 3 2 4 3 2 4 3 2]\n",
      " [2 1 4 2 1 4 2 1 4 2 1 4]\n",
      " [3 1 2 3 1 2 3 1 2 3 1 2]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (11, 12), Ground Truth: (12, 12)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 6/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8e2edd66.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[0, 0, 0, 0, 0, 2, 4, 0, 1], [0, 0, 3, 0, 5, 6, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 0 0 0 1]\n",
      " [1 0 1 0 0 0 1 0 1]\n",
      " [0 1 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 7/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ad7e01d0.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "⚠️ No valid matrix found in extracted output.\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 0 0 0 0 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 5 0 5 0 5 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 5 0 1 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 1 0 5 0 1]\n",
      " [0 2 2 2 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 2 2 2 0]\n",
      " [5 0 5 0 5 0 0 0 0 0 5 0 5 0 5 0 0 0 0 0 5 0 5 0 5]\n",
      " [0 2 2 2 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 2 2 2 0]\n",
      " [1 0 5 0 1 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 1 0 5 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 5 0 5 0 5 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 5 0 1 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 8/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fc754716.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[8, 8, 8, 8, 8, 8, 8], [8, 0, 0, 0, 0, 0, 8], [8, 0, 0, 0, 0, 0, 8], [8, 0, 0, 0, 0, 0, 8], [8, 0, 0, 0, 0, 0, 8], [8, 0, 0, 0, 0, 0, 8], [8, 0, 0, 0, 0, 0, 8], [8, 0, 0, 0, 0, 0, 8], [8, 8, 8, 8, 8, 8, 8]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[8 8 8 8 8 8 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 0 0 0 0 0 8]\n",
      " [8 8 8 8 8 8 8]]\n",
      "\n",
      "📊 **Comparison Result:** ✅ The extracted matrix matches the ground truth!\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 9/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27f8ce4f.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[0, 0, 0, 9, 6, 7, 0, 0, 0], [0, 0, 0, 8, 7, 7, 0, 0, 0], [0, 0, 0, 2, 8, 7, 0, 0, 0], [0, 0, 0, 0, 0, 0, 9, 6, 7], [0, 0, 0, 0, 0, 0, 8, 7, 7], [0, 0, 0, 0, 0, 0, 2, 8, 7]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 0 0 0 0 0 9 6 7]\n",
      " [0 0 0 0 0 0 8 7 7]\n",
      " [0 0 0 0 0 0 2 8 7]\n",
      " [0 0 0 9 6 7 9 6 7]\n",
      " [0 0 0 8 7 7 8 7 7]\n",
      " [0 0 0 2 8 7 2 8 7]\n",
      " [0 0 0 0 0 0 9 6 7]\n",
      " [0 0 0 0 0 0 8 7 7]\n",
      " [0 0 0 0 0 0 2 8 7]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (6, 9), Ground Truth: (9, 9)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 10/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/59341089.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[5, 8, 8, 8, 5, 7, 7, 5, 8, 8, 8, 5], [5, 7, 5, 5, 5, 5, 8, 8, 5, 7, 5, 8], [5, 8, 8, 8, 5, 5, 8, 8, 5, 7, 5, 8]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[7 5 8 8 5 7 7 5 8 8 5 7]\n",
      " [5 7 5 5 7 5 5 7 5 5 7 5]\n",
      " [5 8 8 8 8 5 5 8 8 8 8 5]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 11/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/833dafe3.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[8, 5, 7, 7, 7, 7, 7, 8], [0, 7, 7, 8, 5, 0, 0, 7], [0, 7, 8, 7, 0, 0, 0, 7], [0, 5, 7, 7, 7, 7, 7, 8], [7, 0, 0, 5, 7, 0, 0, 7], [7, 0, 0, 7, 0, 0, 0, 7], [7, 8, 0, 7, 0, 0, 0, 7], [7, 7, 7, 7, 8, 5, 7, 8]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[9 0 0 9 0 0 9 9 9 9 0 0 9 0 0 9]\n",
      " [9 0 0 9 0 0 2 1 1 2 0 0 9 0 0 9]\n",
      " [9 0 0 9 0 0 2 9 9 2 0 0 9 0 0 9]\n",
      " [0 0 0 9 0 0 2 9 9 2 0 0 9 0 0 0]\n",
      " [1 1 1 9 0 1 2 0 0 2 1 0 9 1 1 1]\n",
      " [0 0 0 9 0 1 2 0 0 2 1 0 9 0 0 0]\n",
      " [0 0 0 9 0 1 2 0 0 2 1 0 9 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 9 0 1 2 0 0 2 1 0 9 0 0 0]\n",
      " [0 0 0 9 0 1 2 0 0 2 1 0 9 0 0 0]\n",
      " [1 1 1 9 0 1 2 0 0 2 1 0 9 1 1 1]\n",
      " [0 0 0 9 0 0 2 9 9 2 0 0 9 0 0 0]\n",
      " [9 0 0 9 0 0 2 9 9 2 0 0 9 0 0 9]\n",
      " [9 0 0 9 0 0 2 1 1 2 0 0 9 0 0 9]\n",
      " [9 0 0 9 0 0 9 9 9 9 0 0 9 0 0 9]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (8, 8), Ground Truth: (16, 16)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 12/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed98d772.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[6, 6, 0, 6, 0, 0], [6, 6, 0, 6, 0, 6], [0, 0, 6, 6, 0, 0], [0, 6, 6, 6, 6, 0], [6, 0, 6, 6, 0, 0], [0, 6, 6, 0, 0, 6]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[6 6 0 0 0 6]\n",
      " [6 6 0 6 6 0]\n",
      " [0 0 6 6 6 0]\n",
      " [6 0 0 0 6 6]\n",
      " [0 6 6 0 6 6]\n",
      " [0 6 6 6 0 0]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 13/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d4b1c2b1.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[7, 7, 7, 7, 1, 1, 1, 1, 7, 7, 7, 7], [7, 7, 7, 7, 1, 1, 1, 1, 7, 7, 7, 7], [7, 7, 7, 7, 1, 1, 1, 1, 7, 7, 7, 7], [7, 7, 7, 7, 1, 1, 1, 1, 7, 7, 7, 7], [3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6], [3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6], [3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6], [3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6], [8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6], [8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6], [8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6], [8, 8, 8, 8, 8, 8, 8, 8, 6, 6, 6, 6]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[7 7 7 7 7 1 1 1 1 1 7 7 7 7 7]\n",
      " [7 7 7 7 7 1 1 1 1 1 7 7 7 7 7]\n",
      " [7 7 7 7 7 1 1 1 1 1 7 7 7 7 7]\n",
      " [7 7 7 7 7 1 1 1 1 1 7 7 7 7 7]\n",
      " [7 7 7 7 7 1 1 1 1 1 7 7 7 7 7]\n",
      " [3 3 3 3 3 3 3 3 3 3 6 6 6 6 6]\n",
      " [3 3 3 3 3 3 3 3 3 3 6 6 6 6 6]\n",
      " [3 3 3 3 3 3 3 3 3 3 6 6 6 6 6]\n",
      " [3 3 3 3 3 3 3 3 3 3 6 6 6 6 6]\n",
      " [3 3 3 3 3 3 3 3 3 3 6 6 6 6 6]\n",
      " [8 8 8 8 8 8 8 8 8 8 6 6 6 6 6]\n",
      " [8 8 8 8 8 8 8 8 8 8 6 6 6 6 6]\n",
      " [8 8 8 8 8 8 8 8 8 8 6 6 6 6 6]\n",
      " [8 8 8 8 8 8 8 8 8 8 6 6 6 6 6]\n",
      " [8 8 8 8 8 8 8 8 8 8 6 6 6 6 6]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (12, 12), Ground Truth: (15, 15)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 14/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48131b3c.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[0, 1, 0, 1], [1, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0]] will produce the expected outcome which should follow established patterns seen earlier during analysis phase when comparing different samples together side by side against one another so lets move ahead carefully executing these next steps described down below precisely\n",
      "\n",
      "\n",
      "     Step 4: To obtain the resulting array based off previously noted methodology let’s execute following instructions sequentially – First duplicate each row once horizontally followed immediately thereafter add additional row having values swapped left-right inside individual cells then bring forth another duplicated version swapping vertically lastly append yet again unique copy doing vice versa operation thus applying all transformations mentioned prior at end get resultant structure matching outputs demonstrated through various illustrative cases showcased early on \n",
      "\n",
      "\n",
      "\n",
      "The final answer is:\n",
      "\n",
      "\n",
      "\n",
      "[[0, 1, 0, 1, 0, 1, 0, 1], [1, 0, 0, 1, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 1, 0, 1, 0, 1], [1, 0, 0, 1, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 1]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[1 0 1 0 1 0 1 0]\n",
      " [0 1 1 0 0 1 1 0]\n",
      " [1 1 0 1 1 1 0 1]\n",
      " [0 1 1 1 0 1 1 1]\n",
      " [1 0 1 0 1 0 1 0]\n",
      " [0 1 1 0 0 1 1 0]\n",
      " [1 1 0 1 1 1 0 1]\n",
      " [0 1 1 1 0 1 1 1]]\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 15/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0692e18c.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[0, 0, 0, 3, 0, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 3], [0, 0, 0, 3, 0, 3, 0, 0, 0], [0, 3, 0, 3, 3, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0, 0, 3, 0], [0, 0, 3, 0, 0, 0, 3, 0, 0], [0, 0, 3, 0, 3, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 3], [0, 0, 0, 3, 0, 3, 0, 0, 0]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 0 0 0 0 0 3 3 0]\n",
      " [0 0 0 0 0 0 0 0 3]\n",
      " [0 0 0 0 0 0 3 0 3]\n",
      " [3 3 0 3 3 0 0 0 0]\n",
      " [0 0 3 0 0 3 0 0 0]\n",
      " [3 0 3 3 0 3 0 0 0]\n",
      " [0 0 0 3 3 0 0 0 0]\n",
      " [0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 3 0 3 0 0 0]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 16/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8b28cd80.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[6, 0, 6, 0, 6, 0, 6, 6, 6], [6, 0, 6, 0, 6, 0, 0, 0, 6], [6, 0, 6, 6, 6, 6, 6, 6, 6]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[6 0 6 6 6 6 6 6 6]\n",
      " [6 0 6 0 0 0 0 0 0]\n",
      " [6 0 6 0 6 6 6 6 6]\n",
      " [6 0 6 0 6 0 0 0 0]\n",
      " [6 0 6 0 6 0 6 6 6]\n",
      " [6 0 6 0 6 0 6 0 0]\n",
      " [6 0 6 0 6 0 6 0 6]\n",
      " [6 0 6 0 6 0 6 0 6]\n",
      " [6 0 6 0 6 0 6 0 6]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (3, 9), Ground Truth: (9, 9)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 17/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/32e9702f.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[0, 0, 6, 5, 6, 5, 6, 5, 6, 5], [5, 5, 5, 5, 5, 5, 6, 5, 6, 5], [5, 5, 5, 5, 5, 5, 5, 5, 6, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [6, 6, 6, 6, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [6, 6, 6, 6, 6, 6, 6, 6, 6, 6]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[5 6 6 6 6 6 5 5 5 5]\n",
      " [5 5 5 5 5 5 5 5 5 5]\n",
      " [5 5 5 5 5 6 6 5 5 5]\n",
      " [5 5 5 5 5 5 5 5 5 5]\n",
      " [6 6 6 5 5 5 5 5 5 5]\n",
      " [5 5 5 5 5 5 5 5 5 5]\n",
      " [5 5 5 5 5 5 5 5 5 5]\n",
      " [5 5 5 6 6 6 6 6 6 5]\n",
      " [5 5 5 5 5 5 5 5 5 5]\n",
      " [5 5 5 5 5 5 5 5 5 5]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (8, 10), Ground Truth: (10, 10)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 18/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8719f442.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0], [0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0], [0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0], [0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0], [0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0], [0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 5, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 0 0 0 0 0 0 5 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 5 0 5 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 5 5 5 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 5 5 5 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 5 5 5 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 5 5 5 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 5 5 5 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 5 5 5 0 0 0 0 0 0]\n",
      " [0 5 0 5 5 5 0 0 0 5 5 5 0 5 0]\n",
      " [0 5 0 5 5 5 0 0 0 5 5 5 0 5 0]\n",
      " [5 0 5 5 5 5 0 0 0 5 5 5 5 0 5]\n",
      " [0 0 0 0 5 0 0 0 0 0 5 0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0 5 0 0 0 0]\n",
      " [0 0 0 5 0 5 0 0 0 5 0 5 0 0 0]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 19/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2072aba6.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[0, 3, 6, 7, 8, 0], [3, 4, 6, 7, 8, 3], [6, 4, 1, 2, 9, 6], [7, 7, 2, 1, 9, 7], [8, 3, 9, 6, 4, 8]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 1 2 0 0]\n",
      " [0 0 2 1 0 0]\n",
      " [1 2 1 2 1 2]\n",
      " [2 1 2 1 2 1]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (5, 6), Ground Truth: (6, 6)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 20/20: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ea4a07e.json\n",
      "\n",
      "🔍 **Extracted Output Matrix:**\n",
      "\n",
      "[[6, 4, 7], [0, 0, 0], [0, 0, 0]]\n",
      "\n",
      "🎯 **Ground Truth Matrix:**\n",
      "\n",
      "[[0 1 1]\n",
      " [0 0 0]\n",
      " [1 1 0]]\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "📊 **Summary of First 20 Examples:**\n",
      "✅ 1/20 matrices matched the ground truth.\n",
      "❌ 19/20 matrices did NOT match the ground truth.\n"
     ]
    }
   ],
   "source": [
    "# ✅ Select the first 20 files from the filtered shortest files\n",
    "num_samples = 20  # First batch to test\n",
    "test_files = filtered_files[:num_samples]\n",
    "\n",
    "# ✅ Dictionary to store results\n",
    "comparison_results = {}\n",
    "\n",
    "# ✅ Run inference and comparison for each file\n",
    "for idx, file in enumerate(test_files):\n",
    "    print(f\"\\n🚀 Running inference {idx + 1}/{num_samples}: {file}\")\n",
    "\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference with NO stopping conditions\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1000,  # ✅ Allow long generation without cutting off\n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            repetition_penalty=1.2,  # ✅ Reduces repetitive patterns\n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Extract output matrix\n",
    "    extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "    # ✅ Load ground truth matrix\n",
    "    ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "    # ✅ Compare matrices\n",
    "    comparison_result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "    # ✅ Store results\n",
    "    comparison_results[file] = {\n",
    "        \"extracted_matrix\": extracted_matrix,\n",
    "        \"ground_truth\": ground_truth_matrix,\n",
    "        \"comparison\": comparison_result\n",
    "    }\n",
    "\n",
    "    # ✅ Print results\n",
    "    print(\"\\n🔍 **Extracted Output Matrix:**\\n\")\n",
    "    print(extracted_matrix)\n",
    "    print(\"\\n🎯 **Ground Truth Matrix:**\\n\")\n",
    "    print(np.array(ground_truth_matrix) if ground_truth_matrix else \"⚠️ No ground truth available\")\n",
    "    print(\"\\n📊 **Comparison Result:**\", comparison_result)\n",
    "    print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ Summary of correct vs incorrect predictions\n",
    "num_correct = sum(1 for r in comparison_results.values() if \"matches\" in r[\"comparison\"])\n",
    "num_incorrect = num_samples - num_correct\n",
    "\n",
    "print(\"\\n📊 **Summary of First 20 Examples:**\")\n",
    "print(f\"✅ {num_correct}/{num_samples} matrices matched the ground truth.\")\n",
    "print(f\"❌ {num_incorrect}/{num_samples} matrices did NOT match the ground truth.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aaf0c34-fc6a-4725-b580-987ac0022170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Running inference 1/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/310f3251.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 2/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00576224.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (4, 4), Ground Truth: (6, 6)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 3/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e633a9e5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 4/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c48954c1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (3, 9), Ground Truth: (9, 9)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 5/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a59b95c0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (9, 12), Ground Truth: (12, 12)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 6/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8e2edd66.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 7/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ad7e01d0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (5, 16), Ground Truth: (25, 25)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 8/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fc754716.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 9/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27f8ce4f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 10/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/59341089.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 11/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/833dafe3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (8, 8), Ground Truth: (16, 16)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 12/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed98d772.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (6, 8), Ground Truth: (6, 6)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 13/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d4b1c2b1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (12, 12), Ground Truth: (15, 15)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 14/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48131b3c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (4, 8), Ground Truth: (8, 8)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 15/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0692e18c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 16/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8b28cd80.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 17/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/32e9702f.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (8,) + inhomogeneous part.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 18/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8719f442.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (14, 15), Ground Truth: (15, 15)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 19/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2072aba6.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: unexpected indent (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 20/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ea4a07e.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 21/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/48f8583b.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 22/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/695367ec.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 23/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/15696249.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 24/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c92b942c.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 25/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/27a77e38.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 5)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 26/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60c09cac.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 27/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ccd554ac.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (12, 16), Ground Truth: (25, 25)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 28/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c786b71.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (6, 10), Ground Truth: (6, 8)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 29/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c1990cce.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (13, 17), Ground Truth: (17, 17)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 30/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7953d61e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (4, 8), Ground Truth: (8, 8)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 31/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66e6c45b.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 32/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5b6cbef5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (4, 4), Ground Truth: (16, 16)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 33/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bc4146bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 34/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4cd1b7b2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 35/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e133d23d.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 36/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e6de6e8f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (2, 12), Ground Truth: (8, 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 37/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/be03b35f.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: unexpected indent (<string>, line 3)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 38/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12422b43.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 39/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b15fca0b.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 40/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ca8de6ea.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 5)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 41/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7b06bea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 42/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f0afb749.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (13, 18), Ground Truth: (6, 6)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 43/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3979b1a8.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 44/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d017b73f.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 45/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/17cae0c1.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 46/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62b74c02.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 47/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31d5ba1a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 48/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e345f17b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 49/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa18de87.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 4)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 50/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73c3b0d8.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 **Saved results for 50 examples at:** ./FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings_results_batch_50.json\n",
      "\n",
      "🚀 Running inference 51/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c074846d.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 52/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cad67732.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 8)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 53/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fb791726.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 54/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ba14f53.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 55/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5790162.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 56/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bbb1b8b6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 57/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2a5f8217.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (11, 13), Ground Truth: (13, 13)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 58/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5783df64.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 59/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b1fc8b8e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 60/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a8610ef7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 61/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/770cc55f.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 3)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 62/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/68b67ca3.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 63/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/67c52801.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 64/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c56f360.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 65/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/34b99a2b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 66/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ed74f2f2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 67/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/506d28a5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 68/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/22a4bbc2.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 69/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d19f7514.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 70/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/00dbd492.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (16, 20), Ground Truth: (20, 20)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 71/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e7dd8335.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 72/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c8b7cc0f.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ The extracted matrix matches the ground truth!\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 73/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/332efdb3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (7, 11), Ground Truth: (11, 11)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 74/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3b4c2228.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 75/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/626c0bcc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 76/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9110e3c5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 77/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6f473927.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (12, 13), Ground Truth: (12, 12)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 78/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0c9aba6e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 79/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5d2a5c43.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 80/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12eac192.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 81/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/66f2d22f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 82/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6ad5bdfd.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 83/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9bebae7a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (10, 12), Ground Truth: (11, 12)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 84/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/90347967.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 85/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d2acf2cb.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 5)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 86/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2697da3f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (8, 10), Ground Truth: (17, 17)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 87/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d931c21c.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 88/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50a16a69.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 89/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1c0d0a4b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (12, 13), Ground Truth: (13, 13)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 90/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/195ba7dc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 91/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3d31c5b3.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 5)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 92/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/62ab2642.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 93/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6a11f6da.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 94/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/281123b4.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: unexpected indent (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 95/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ef26cbf6.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 96/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/42a15761.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 97/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b4a43f3b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (16, 18), Ground Truth: (18, 18)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 98/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ae58858e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 99/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e69241bd.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 100/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/85fa5666.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 6)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 **Saved results for 100 examples at:** ./FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings_results_batch_100.json\n",
      "\n",
      "🚀 Running inference 101/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8597cfd7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 102/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4852f2fa.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 103/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55783887.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 104/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72207abc.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: unmatched ')' (<string>, line 3)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 105/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/d37a1ef5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 106/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/af24b4cc.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 107/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c87289bb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 108/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1a2e2828.json\n",
      "\n",
      "📊 **Comparison Result:** ✅ The extracted matrix matches the ground truth!\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 109/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8fbca751.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (7, 8), Ground Truth: (8, 12)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 110/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5207a7b5.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (14, 7), Ground Truth: (15, 9)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 111/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0722778.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 112/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0a2355a6.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 113/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b0f4d537.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (11, 15), Ground Truth: (12, 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 114/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e99362f0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (4, 4), Ground Truth: (5, 4)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 115/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c35c1b4c.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 116/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f45f5ca7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 117/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/64a7c07e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 118/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac3e2b04.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 119/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c7d4e6ad.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 120/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/84db8fc4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 121/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce039d91.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 122/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/99306f82.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 123/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2685904e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 124/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4acc7107.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 125/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/4e469f39.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 126/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/bf32578f.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 127/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/aa300dc3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 128/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/137f0df0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 129/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/03560426.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 130/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/69889d6e.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 131/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e9ac8c9e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (14, 15), Ground Truth: (15, 15)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 132/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cfb2ce5a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 133/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/da2b0fe3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 134/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/6df30ad6.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 135/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3cdc58f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 136/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/58743b76.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (13, 14), Ground Truth: (14, 14)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 137/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/a406ac07.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 138/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/94414823.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 139/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/575b1a71.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 140/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f3e62deb.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 141/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ea9794b1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 142/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/31adaf00.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 6)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 143/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9c1e755f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 144/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ac605cbb.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 145/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7c8af763.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 4)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 146/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7ee1c6ea.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 147/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b942fd60.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 148/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/782b5218.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 149/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0becf7df.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 16)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 150/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/136b0064.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (13, 15), Ground Truth: (19, 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 **Saved results for 150 examples at:** ./FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings_results_batch_150.json\n",
      "\n",
      "🚀 Running inference 151/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dd2401ed.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 5)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 152/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/50aad11f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (5, 6), Ground Truth: (12, 4)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 153/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2b01abd0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (13, 16), Ground Truth: (14, 16)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 154/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/292dd178.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (10, 15), Ground Truth: (11, 15)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 155/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ce8d95cc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (10, 13), Ground Truth: (7, 9)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 156/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/423a55dc.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 157/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/817e6c09.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 158/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/11e1fe23.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 159/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/2c737e39.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 160/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ff72ca3e.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 161/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/93b4f4b3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (8, 5), Ground Truth: (17, 5)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 162/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/fe9372f3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (12, 17), Ground Truth: (30, 17)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 163/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/ecaa0ec1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 164/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/cd3c21df.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: unexpected indent (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 165/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/08573cc6.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 166/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/963f59bc.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: unexpected indent (<string>, line 4)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 167/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/dc2aa30b.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 168/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9ddd00f0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (12, 19), Ground Truth: (19, 19)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 169/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e5c44e8f.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 170/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/b7cb93ac.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 171/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/f5aa3634.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (3, 3), Ground Truth: (4, 3)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 172/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/72a961c9.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 173/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/45737921.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 174/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5ffb2104.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (6, 10), Ground Truth: (10, 10)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 175/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/516b51b7.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (14, 17), Ground Truth: (15, 17)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 176/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/baf41dbf.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (13, 17), Ground Truth: (16, 17)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 177/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/55059096.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (15, 10), Ground Truth: (17, 13)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 178/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/762cd429.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 179/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e78887d1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (8, 15), Ground Truth: (3, 15)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 180/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/8ee62060.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 181/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/e872b94a.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (2, 1), Ground Truth: (3, 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 182/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/705a3229.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 183/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/1acc24af.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 184/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/917bccba.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (11, 12), Ground Truth: (12, 12)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 185/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/7e02026e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 186/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/73182012.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (3, 3), Ground Truth: (4, 4)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 187/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9f27f097.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 188/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/60a26a3e.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 189/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/3391f8c0.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ The extracted matrix does NOT match the ground truth.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 190/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/505fff84.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 2)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 191/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/12997ef3.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (3, 6), Ground Truth: (3, 12)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 192/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/642248e4.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (15, 18), Ground Truth: (16, 18)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 193/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/896d5239.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (12, 12), Ground Truth: (15, 18)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 194/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/0bb8deee.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (13, 13), Ground Truth: (6, 6)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 195/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/992798f6.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (16,) + inhomogeneous part.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 196/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/712bf12e.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid syntax (<string>, line 7)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 197/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/9b365c51.json\n",
      "\n",
      "📊 **Comparison Result:** ⚠️ Error in matrix comparison: invalid character '⚠' (U+26A0) (<string>, line 1)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 198/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/5af49b42.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (14, 18), Ground Truth: (17, 18)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 199/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/c658a4bd.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (14, 19), Ground Truth: (10, 10)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "🚀 Running inference 200/200: /pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/84f2aca1.json\n",
      "\n",
      "📊 **Comparison Result:** ❌ Shape Mismatch! Extracted: (12, 12), Ground Truth: (13, 12)\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "💾 **Saved results for 200 examples at:** ./FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings_results_batch_200.json\n",
      "\n",
      "💾 **Saved results for 200 examples at:** ./FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings_results_batch_200.json\n",
      "\n",
      "✅ **Completed inference & comparison for all 200 examples!** 🚀\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ✅ Model name (for saving results)\n",
    "model_name = \"FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings\"\n",
    "\n",
    "# ✅ Select all 200 filtered examples\n",
    "num_samples = 200\n",
    "batch_size = 50  # ✅ Save progress every 50 examples\n",
    "test_files = filtered_files[:num_samples]\n",
    "\n",
    "# ✅ Dictionary to store all results\n",
    "all_results = {}\n",
    "\n",
    "# ✅ Function to save results periodically\n",
    "def save_results(batch_index):\n",
    "    save_path = f\"./{model_name}_results_batch_{batch_index}.json\"\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "    print(f\"\\n💾 **Saved results for {batch_index} examples at:** {save_path}\")\n",
    "\n",
    "# ✅ Run inference and comparison for each file\n",
    "for idx, file in enumerate(test_files):\n",
    "    print(f\"\\n🚀 Running inference {idx + 1}/{num_samples}: {file}\")\n",
    "\n",
    "    # ✅ Construct file path\n",
    "    file_path = os.path.join(\"/pfs/data5/home/ma/ma_ma/ma_abthomas/json_files/training/evaluation_dataset/\", file)\n",
    "    \n",
    "    # ✅ Construct prompt\n",
    "    test_prompt = construct_fixed_prompt(file_path)\n",
    "\n",
    "    # ✅ Tokenize the prompt\n",
    "    inputs = tokenizer(test_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # ✅ Remove `token_type_ids` if present\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "\n",
    "    # ✅ Run inference with NO stopping conditions\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=1000,  # ✅ Allow long generation without cutting off\n",
    "            do_sample=True,  \n",
    "            temperature=0.7,  \n",
    "            top_k=50,  \n",
    "            top_p=0.9,  \n",
    "            repetition_penalty=1.2,  # ✅ Reduces repetitive patterns\n",
    "        )\n",
    "\n",
    "    # ✅ Decode full output\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # ✅ Extract output matrix\n",
    "    extracted_matrix = extract_final_matrix(generated_text)\n",
    "\n",
    "    # ✅ Load ground truth matrix\n",
    "    ground_truth_matrix = load_ground_truth_matrix(file)\n",
    "\n",
    "    # ✅ Compare matrices\n",
    "    comparison_result = compare_matrices(extracted_matrix, ground_truth_matrix)\n",
    "\n",
    "    # ✅ Store results\n",
    "    all_results[file] = {\n",
    "        \"model_name\": model_name,\n",
    "        \"extracted_matrix\": extracted_matrix,\n",
    "        \"ground_truth\": ground_truth_matrix,\n",
    "        \"comparison\": comparison_result\n",
    "    }\n",
    "\n",
    "    # ✅ Print progress summary\n",
    "    print(\"\\n📊 **Comparison Result:**\", comparison_result)\n",
    "    print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "    # ✅ Save results every 50 examples\n",
    "    if (idx + 1) % batch_size == 0:\n",
    "        save_results(idx + 1)\n",
    "\n",
    "# ✅ Final save for remaining results\n",
    "save_results(num_samples)\n",
    "print(\"\\n✅ **Completed inference & comparison for all 200 examples!** 🚀\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "813e6393-76d1-4ff2-81b8-5accf774f743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded results from: ./FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings_results_batch_50.json\n",
      "✅ Loaded results from: ./FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings_results_batch_100.json\n",
      "✅ Loaded results from: ./FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings_results_batch_150.json\n",
      "✅ Loaded results from: ./FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings_results_batch_200.json\n",
      "\n",
      "📊 **Summary of Model Performance:**\n",
      "✅ 2/200 matrices matched the ground truth.\n",
      "❌ 198/200 matrices did NOT match the ground truth.\n",
      "⚠️ Example not found in saved results.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# ✅ Model name used for saving results\n",
    "model_name = \"FineLlama-3.1-8B_instruct_eval_lr0.0005_batch4_epochs1_wd0.1_WithoutReasonings\"\n",
    "\n",
    "# ✅ Paths to saved result files\n",
    "result_files = [\n",
    "    f\"./{model_name}_results_batch_50.json\",\n",
    "    f\"./{model_name}_results_batch_100.json\",\n",
    "    f\"./{model_name}_results_batch_150.json\",\n",
    "    f\"./{model_name}_results_batch_200.json\"\n",
    "]\n",
    "\n",
    "# ✅ Load all results into one dictionary\n",
    "all_results = {}\n",
    "for file in result_files:\n",
    "    try:\n",
    "        with open(file, \"r\") as f:\n",
    "            batch_results = json.load(f)\n",
    "            all_results.update(batch_results)\n",
    "        print(f\"✅ Loaded results from: {file}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠️ Warning: Could not find {file}. Skipping...\")\n",
    "\n",
    "# ✅ Summary of Correct vs Incorrect Predictions\n",
    "num_correct = sum(1 for r in all_results.values() if \"matches\" in r[\"comparison\"])\n",
    "num_incorrect = len(all_results) - num_correct\n",
    "\n",
    "print(\"\\n📊 **Summary of Model Performance:**\")\n",
    "print(f\"✅ {num_correct}/{len(all_results)} matrices matched the ground truth.\")\n",
    "print(f\"❌ {num_incorrect}/{len(all_results)} matrices did NOT match the ground truth.\")\n",
    "\n",
    "# ✅ Function to display detailed results for specific examples\n",
    "def view_result(example_file):\n",
    "    if example_file not in all_results:\n",
    "        print(\"⚠️ Example not found in saved results.\")\n",
    "        return\n",
    "\n",
    "    result = all_results[example_file]\n",
    "    \n",
    "    print(f\"\\n📂 **Example: {example_file}**\")\n",
    "    print(f\"\\n🎯 **Ground Truth Matrix:**\")\n",
    "    print(np.array(result[\"ground_truth\"]) if result[\"ground_truth\"] else \"⚠️ No ground truth available\")\n",
    "\n",
    "    print(\"\\n🔍 **Extracted Output Matrix:**\")\n",
    "    print(result[\"extracted_matrix\"])\n",
    "\n",
    "    print(\"\\n📊 **Comparison Result:**\", result[\"comparison\"])\n",
    "    print(\"\\n\" + \"-\" * 100 + \"\\n\")\n",
    "\n",
    "# ✅ View random example from results (modify filename as needed)\n",
    "example_file = \"59341089.json\"  # Change this to any filename you want to inspect\n",
    "view_result(example_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3988ebb6-8bd3-4b4b-8e83-c77c65ed01d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 **Updated Model Performance (Excluding Invalid Cases):**\n",
      "✅ 2/86 valid matrices matched the ground truth.\n",
      "❌ 84/86 valid matrices did NOT match the ground truth.\n",
      "⚠️ 114 cases were excluded due to syntax errors.\n",
      "\n",
      "🎯 **Final Accuracy:** 2.33%\n"
     ]
    }
   ],
   "source": [
    "# ✅ Filter valid results (exclude errors)\n",
    "valid_results = {\n",
    "    file: result\n",
    "    for file, result in all_results.items()\n",
    "    if \"matches\" in result[\"comparison\"] or \"does NOT match\" in result[\"comparison\"]\n",
    "}\n",
    "\n",
    "# ✅ Count correct vs incorrect results\n",
    "num_correct = sum(1 for r in valid_results.values() if \"matches\" in r[\"comparison\"])\n",
    "num_invalid = len(all_results) - len(valid_results)\n",
    "num_total_valid = len(valid_results)\n",
    "\n",
    "# ✅ Compute accuracy percentage\n",
    "accuracy = (num_correct / num_total_valid) * 100 if num_total_valid > 0 else 0\n",
    "\n",
    "# ✅ Print Updated Summary\n",
    "print(\"\\n📊 **Updated Model Performance (Excluding Invalid Cases):**\")\n",
    "print(f\"✅ {num_correct}/{num_total_valid} valid matrices matched the ground truth.\")\n",
    "print(f\"❌ {num_total_valid - num_correct}/{num_total_valid} valid matrices did NOT match the ground truth.\")\n",
    "print(f\"⚠️ {num_invalid} cases were excluded due to syntax errors.\")\n",
    "print(f\"\\n🎯 **Final Accuracy:** {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4e7b79c-49b8-4550-bbad-db6863696352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 **Updated Model Performance (Categorized Correctly):**\n",
      "✅ 2/140 valid matrices matched the ground truth.\n",
      "❌ 138/140 valid matrices did NOT match the ground truth.\n",
      "⚠️ 60/200 cases had invalid matrix comparisons.\n",
      "\n",
      "🎯 **Final Accuracy (Excluding Invalid Cases):** 1.43%\n"
     ]
    }
   ],
   "source": [
    "# ✅ Counters for each category\n",
    "num_correct = 0\n",
    "num_incorrect = 0\n",
    "num_invalid = 0\n",
    "\n",
    "# ✅ Filter valid and invalid results based on symbols\n",
    "valid_results = {}\n",
    "\n",
    "for file, result in all_results.items():\n",
    "    comparison_text = result[\"comparison\"]\n",
    "\n",
    "    if \"⚠️\" in comparison_text:  # If comparison contains an error symbol\n",
    "        num_invalid += 1\n",
    "    elif \"❌\" in comparison_text:  # If prediction was incorrect but valid\n",
    "        num_incorrect += 1\n",
    "        valid_results[file] = result  # Still a valid case\n",
    "    elif \"✅\" in comparison_text:  # If prediction was correct\n",
    "        num_correct += 1\n",
    "        valid_results[file] = result  # Still a valid case\n",
    "\n",
    "# ✅ Compute valid case count\n",
    "num_total_valid = num_correct + num_incorrect\n",
    "\n",
    "# ✅ Compute accuracy percentage\n",
    "accuracy = (num_correct / num_total_valid) * 100 if num_total_valid > 0 else 0\n",
    "\n",
    "# ✅ Print Updated Summary\n",
    "print(\"\\n📊 **Updated Model Performance (Categorized Correctly):**\")\n",
    "print(f\"✅ {num_correct}/{num_total_valid} valid matrices matched the ground truth.\")\n",
    "print(f\"❌ {num_incorrect}/{num_total_valid} valid matrices did NOT match the ground truth.\")\n",
    "print(f\"⚠️ {num_invalid}/{len(all_results)} cases had invalid matrix comparisons.\")\n",
    "print(f\"\\n🎯 **Final Accuracy (Excluding Invalid Cases):** {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ca368-cc29-4c6a-bfff-8d5178690541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
